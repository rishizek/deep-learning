<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_image_classification</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Image-Classification">Image Classification<a class="anchor-link" href="#Image-Classification">&#182;</a></h1><p>In this project, you'll classify images from the <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a>.  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Run the following cell to download the <a href="https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz">CIFAR-10 dataset for python</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="k">import</span> <span class="n">urlretrieve</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="k">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">isdir</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">tarfile</span>

<span class="n">cifar10_dataset_folder_path</span> <span class="o">=</span> <span class="s1">&#39;cifar-10-batches-py&#39;</span>

<span class="c1"># Use Floyd&#39;s cifar-10 dataset if present</span>
<span class="n">floyd_cifar10_location</span> <span class="o">=</span> <span class="s1">&#39;/input/cifar-10/python.tar.gz&#39;</span>
<span class="k">if</span> <span class="n">isfile</span><span class="p">(</span><span class="n">floyd_cifar10_location</span><span class="p">):</span>
    <span class="n">tar_gz_path</span> <span class="o">=</span> <span class="n">floyd_cifar10_location</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">tar_gz_path</span> <span class="o">=</span> <span class="s1">&#39;cifar-10-python.tar.gz&#39;</span>

<span class="k">class</span> <span class="nc">DLProgress</span><span class="p">(</span><span class="n">tqdm</span><span class="p">):</span>
    <span class="n">last_block</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">block_num</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span> <span class="o">=</span> <span class="n">block_num</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isfile</span><span class="p">(</span><span class="n">tar_gz_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;CIFAR-10 Dataset&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="s1">&#39;https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz&#39;</span><span class="p">,</span>
            <span class="n">tar_gz_path</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isdir</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">tar_gz_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
        <span class="n">tar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>


<span class="n">tests</span><span class="o">.</span><span class="n">test_folder_path</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>CIFAR-10 Dataset: 171MB [01:08, 2.50MB/s]                              
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>All files found!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named <code>data_batch_1</code>, <code>data_batch_2</code>, etc.. Each batch contains the labels and images that are one of the following:</p>
<ul>
<li>airplane</li>
<li>automobile</li>
<li>bird</li>
<li>cat</li>
<li>deer</li>
<li>dog</li>
<li>frog</li>
<li>horse</li>
<li>ship</li>
<li>truck</li>
</ul>
<p>Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the <code>batch_id</code> and <code>sample_id</code>. The <code>batch_id</code> is the id for a batch (1-5). The <code>sample_id</code> is the id for a image and label pair in the batch.</p>
<p>Ask yourself "What are all possible labels?", "What is the range of values for the image data?", "Are the labels in order or random?".  Answers to questions like these will help you preprocess the data and end up with better predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Explore the dataset</span>
<span class="n">batch_id</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sample_id</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">helper</span><span class="o">.</span><span class="n">display_stats</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">,</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">sample_id</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Stats of batch 1:
Samples: 10000
Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}
First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]

Example of Image 5:
Image - Min Value: 0 Max Value: 252
Image - Shape: (32, 32, 3)
Label - Label Id: 1 Name: automobile
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
width=253
height=250
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocess-Functions">Implement Preprocess Functions<a class="anchor-link" href="#Implement-Preprocess-Functions">&#182;</a></h2><h3 id="Normalize">Normalize<a class="anchor-link" href="#Normalize">&#182;</a></h3><p>In the cell below, implement the <code>normalize</code> function to take in image data, <code>x</code>, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as <code>x</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize a list of sample image data in the range of 0 to 1</span>
<span class="sd">    : x: List of image data.  The image shape is (32, 32, 3)</span>
<span class="sd">    : return: Numpy array of normalize data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">image_min</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">image_max</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">image_min</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">image_max</span> <span class="o">-</span> <span class="n">image_min</span> <span class="p">)</span> 


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_normalize</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="One-hot-encode">One-hot encode<a class="anchor-link" href="#One-hot-encode">&#182;</a></h3><p>Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the <code>one_hot_encode</code> function. The input, <code>x</code>, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to <code>one_hot_encode</code>.  Make sure to save the map of encodings outside the function.</p>
<p>Hint: Don't reinvent the wheel.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">one_hot_encode</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.</span>
<span class="sd">    : x: List of sample Labels</span>
<span class="sd">    : return: Numpy array of one-hot encoded labels</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">nb_classes</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">one_hot_targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nb_classes</span><span class="p">)[</span><span class="n">x</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">one_hot_targets</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_one_hot_encode</span><span class="p">(</span><span class="n">one_hot_encode</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Randomize-Data">Randomize Data<a class="anchor-link" href="#Randomize-Data">&#182;</a></h3><p>As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h2><p>Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Preprocess Training, Validation, and Testing Data</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">cifar10_dataset_folder_path</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">one_hot_encode</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="c1"># Load the Preprocessed Validation data</span>
<span class="n">valid_features</span><span class="p">,</span> <span class="n">valid_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;preprocess_validation.p&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-network">Build the network<a class="anchor-link" href="#Build-the-network">&#182;</a></h2><p>For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.</p>
<blockquote><p><strong>Note:</strong> If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages to build each layer, except the layers you build in the "Convolutional and Max Pooling Layer" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.</p>
<p>However, if you would like to get the most out of this course, try to solve all the problems <em>without</em> using anything from the TF Layers packages. You <strong>can</strong> still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the <code>conv2d</code> class, <a href="https://www.tensorflow.org/api_docs/python/tf/layers/conv2d">tf.layers.conv2d</a>, you would want to use the TF Neural Network version of <code>conv2d</code>, <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d">tf.nn.conv2d</a>.</p>
</blockquote>
<p>Let's begin!</p>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions</p>
<ul>
<li>Implement <code>neural_net_image_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a></li>
<li>Set the shape using <code>image_shape</code> with batch size set to <code>None</code>.</li>
<li>Name the TensorFlow placeholder "x" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
<li>Implement <code>neural_net_label_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a></li>
<li>Set the shape using <code>n_classes</code> with batch size set to <code>None</code>.</li>
<li>Name the TensorFlow placeholder "y" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
<li>Implement <code>neural_net_keep_prob_input</code><ul>
<li>Return a <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a> for dropout keep probability.</li>
<li>Name the TensorFlow placeholder "keep_prob" using the TensorFlow <code>name</code> parameter in the <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF Placeholder</a>.</li>
</ul>
</li>
</ul>
<p>These names will be used at the end of the project to load your saved model.</p>
<p>Note: <code>None</code> for shapes in TensorFlow allow for a dynamic size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">def</span> <span class="nf">neural_net_image_input</span><span class="p">(</span><span class="n">image_shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for a batch of image input</span>
<span class="sd">    : image_shape: Shape of the images</span>
<span class="sd">    : return: Tensor for image input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">image_shape</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">neural_net_label_input</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for a batch of label input</span>
<span class="sd">    : n_classes: Number of classes</span>
<span class="sd">    : return: Tensor for label input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">neural_net_keep_prob_input</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a Tensor for keep probability</span>
<span class="sd">    : return: Tensor for keep probability.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;keep_prob&quot;</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_image_inputs</span><span class="p">(</span><span class="n">neural_net_image_input</span><span class="p">)</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_label_inputs</span><span class="p">(</span><span class="n">neural_net_label_input</span><span class="p">)</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_nn_keep_prob_inputs</span><span class="p">(</span><span class="n">neural_net_keep_prob_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Image Input Tests Passed.
Label Input Tests Passed.
Keep Prob Tests Passed.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Convolution-and-Max-Pooling-Layer">Convolution and Max Pooling Layer<a class="anchor-link" href="#Convolution-and-Max-Pooling-Layer">&#182;</a></h3><p>Convolution layers have a lot of success with images. For this code cell, you should implement the function <code>conv2d_maxpool</code> to apply convolution then max pooling:</p>
<ul>
<li>Create the weight and bias using <code>conv_ksize</code>, <code>conv_num_outputs</code> and the shape of <code>x_tensor</code>.</li>
<li>Apply a convolution to <code>x_tensor</code> using weight and <code>conv_strides</code>.<ul>
<li>We recommend you use same padding, but you're welcome to use any padding.</li>
</ul>
</li>
<li>Add bias</li>
<li>Add a nonlinear activation to the convolution.</li>
<li>Apply Max Pooling using <code>pool_ksize</code> and <code>pool_strides</code>.<ul>
<li>We recommend you use same padding, but you're welcome to use any padding.</li>
</ul>
</li>
</ul>
<p><strong>Note:</strong> You <strong>can't</strong> use <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> for <strong>this</strong> layer, but you can still use TensorFlow's <a href="https://www.tensorflow.org/api_docs/python/tf/nn">Neural Network</a> package. You may still use the shortcut option for all the <strong>other</strong> layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv2d_maxpool</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">conv_num_outputs</span><span class="p">,</span> <span class="n">conv_ksize</span><span class="p">,</span> <span class="n">conv_strides</span><span class="p">,</span> <span class="n">pool_ksize</span><span class="p">,</span> <span class="n">pool_strides</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply convolution then max pooling to x_tensor</span>
<span class="sd">    :param x_tensor: TensorFlow Tensor</span>
<span class="sd">    :param conv_num_outputs: Number of outputs for the convolutional layer</span>
<span class="sd">    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer</span>
<span class="sd">    :param conv_strides: Stride 2-D Tuple for convolution</span>
<span class="sd">    :param pool_ksize: kernal size 2-D Tuple for pool</span>
<span class="sd">    :param pool_strides: Stride 2-D Tuple for pool</span>
<span class="sd">    : return: A tensor that represents convolution and max pooling of x_tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># Filter (weights and bias)</span>
    <span class="n">W_conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="o">*</span><span class="n">conv_ksize</span><span class="p">,</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">3</span><span class="p">],</span> <span class="n">conv_num_outputs</span><span class="p">),</span>
                                            <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    <span class="n">b_conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">conv_num_outputs</span><span class="p">))</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;SAME&#39;</span>
    <span class="n">h_conv2d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">W_conv</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">conv_strides</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_conv</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">h_conv2d</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">pool_ksize</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">pool_strides</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="p">)</span> 


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_con_pool</span><span class="p">(</span><span class="n">conv2d_maxpool</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Flatten-Layer">Flatten Layer<a class="anchor-link" href="#Flatten-Layer">&#182;</a></h3><p>Implement the <code>flatten</code> function to change the dimension of <code>x_tensor</code> from a 4-D tensor to a 2-D tensor.  The output should be the shape (<em>Batch Size</em>, <em>Flattened Image Size</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Flatten x_tensor to (Batch Size, Flattened Image Size)</span>
<span class="sd">    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.</span>
<span class="sd">    : return: A tensor of size (Batch Size, Flattened Image Size).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">image_shape</span> <span class="o">=</span> <span class="n">x_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_flatten</span><span class="p">(</span><span class="n">flatten</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fully-Connected-Layer">Fully-Connected Layer<a class="anchor-link" href="#Fully-Connected-Layer">&#182;</a></h3><p>Implement the <code>fully_conn</code> function to apply a fully connected layer to <code>x_tensor</code> with the shape (<em>Batch Size</em>, <em>num_outputs</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fully_conn</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a fully connected layer to x_tensor using weight and bias</span>
<span class="sd">    : x_tensor: A 2-D tensor where the first dimension is batch size.</span>
<span class="sd">    : num_outputs: The number of output that the new tensor should be.</span>
<span class="sd">    : return: A 2-D tensor where the second dimension is num_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">W_fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">x_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_outputs</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    <span class="n">b_fc1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_outputs</span><span class="p">]))</span>

    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">W_fc1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_fc1</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_fully_conn</span><span class="p">(</span><span class="n">fully_conn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Output-Layer">Output Layer<a class="anchor-link" href="#Output-Layer">&#182;</a></h3><p>Implement the <code>output</code> function to apply a fully connected layer to <code>x_tensor</code> with the shape (<em>Batch Size</em>, <em>num_outputs</em>). Shortcut option: you can use classes from the <a href="https://www.tensorflow.org/api_docs/python/tf/layers">TensorFlow Layers</a> or <a href="https://www.tensorflow.org/api_guides/python/contrib.layers">TensorFlow Layers (contrib)</a> packages for this layer. For more of a challenge, only use other TensorFlow packages.</p>
<p><strong>Note:</strong> Activation, softmax, or cross entropy should <strong>not</strong> be applied to this.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[88]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply a output layer to x_tensor using weight and bias</span>
<span class="sd">    : x_tensor: A 2-D tensor where the first dimension is batch size.</span>
<span class="sd">    : num_outputs: The number of output that the new tensor should be.</span>
<span class="sd">    : return: A 2-D tensor where the second dimension is num_outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">W_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">([</span><span class="n">x_tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_outputs</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    <span class="n">b_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_outputs</span><span class="p">]))</span>

    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x_tensor</span><span class="p">,</span> <span class="n">W_output</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_output</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-Convolutional-Model">Create Convolutional Model<a class="anchor-link" href="#Create-Convolutional-Model">&#182;</a></h3><p>Implement the function <code>conv_net</code> to create a convolutional neural network model. The function takes in a batch of images, <code>x</code>, and outputs logits.  Use the layers you created above to create this model:</p>
<ul>
<li>Apply 1, 2, or 3 Convolution and Max Pool layers</li>
<li>Apply a Flatten Layer</li>
<li>Apply 1, 2, or 3 Fully Connected Layers</li>
<li>Apply an Output Layer</li>
<li>Return the output</li>
<li>Apply <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dropout">TensorFlow's Dropout</a> to one or more layers in the model using <code>keep_prob</code>. </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[134]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a convolutional neural network model</span>
<span class="sd">    : x: Placeholder tensor that holds image data.</span>
<span class="sd">    : keep_prob: Placeholder tensor that hold dropout keep probability.</span>
<span class="sd">    : return: Tensor that represents logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Apply 1, 2, or 3 Convolution and Max Pool layers</span>
    <span class="c1">#    Play around with different number of outputs, kernel size and stride</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)</span>
    <span class="n">h_conv_maxpool1</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">h_conv_drop1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h_conv_maxpool1</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">h_conv_maxpool2</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">h_conv_drop1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">h_conv_drop2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h_conv_maxpool2</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">h_conv_maxpool3</span> <span class="o">=</span> <span class="n">conv2d_maxpool</span><span class="p">(</span><span class="n">h_conv_drop2</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">h_conv_drop3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h_conv_maxpool3</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

    <span class="c1"># TODO: Apply a Flatten Layer</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#   flatten(x_tensor)</span>
    <span class="n">h_flatten</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">h_conv_drop3</span><span class="p">)</span>
    

    <span class="c1"># TODO: Apply 1, 2, or 3 Fully Connected Layers</span>
    <span class="c1">#    Play around with different number of outputs</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#   fully_conn(x_tensor, num_outputs)</span>
    <span class="n">h_fc1</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">h_flatten</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
    <span class="n">h_fc1_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h_fc1</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">h_fc2</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">h_fc1_drop</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
    <span class="n">h_fc2_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h_fc2</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="n">h_fc3</span> <span class="o">=</span> <span class="n">fully_conn</span><span class="p">(</span><span class="n">h_fc2_drop</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
    <span class="n">h_fc3_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h_fc3</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

    
    <span class="c1"># TODO: Apply an Output Layer</span>
    <span class="c1">#    Set this to the number of classes</span>
    <span class="c1"># Function Definition from Above:</span>
    <span class="c1">#   output(x_tensor, num_outputs)</span>
    <span class="n">y_conv</span> <span class="o">=</span> <span class="n">output</span><span class="p">(</span><span class="n">h_fc3_drop</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># TODO: return output</span>
    <span class="k">return</span> <span class="n">y_conv</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">##############################</span>
<span class="c1">## Build the Neural Network ##</span>
<span class="c1">##############################</span>

<span class="c1"># Remove previous weights, bias, inputs, etc..</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="c1"># Inputs</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">neural_net_image_input</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">neural_net_label_input</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">neural_net_keep_prob_input</span><span class="p">()</span>

<span class="c1"># Model</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">conv_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

<span class="c1"># Name logits Tensor, so that is can be loaded from disk after training</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>

<span class="c1"># Loss and Optimizer</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">))</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

<span class="c1"># Accuracy</span>
<span class="n">correct_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_conv_net</span><span class="p">(</span><span class="n">conv_net</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Neural Network Built!
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-the-Neural-Network">Train the Neural Network<a class="anchor-link" href="#Train-the-Neural-Network">&#182;</a></h2><h3 id="Single-Optimization">Single Optimization<a class="anchor-link" href="#Single-Optimization">&#182;</a></h3><p>Implement the function <code>train_neural_network</code> to do a single optimization.  The optimization should use <code>optimizer</code> to optimize in <code>session</code> with a <code>feed_dict</code> of the following:</p>
<ul>
<li><code>x</code> for image input</li>
<li><code>y</code> for labels</li>
<li><code>keep_prob</code> for keep probability for dropout</li>
</ul>
<p>This function will be called for each batch, so <code>tf.global_variables_initializer()</code> has already been called.</p>
<p>Note: Nothing needs to be returned. This function is only optimizing the neural network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[135]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train_neural_network</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Optimize the session on a batch of images and labels</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : optimizer: TensorFlow optimizer function</span>
<span class="sd">    : keep_probability: keep probability</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_train_nn</span><span class="p">(</span><span class="n">train_neural_network</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Show-Stats">Show Stats<a class="anchor-link" href="#Show-Stats">&#182;</a></h3><p>Implement the function <code>print_stats</code> to print loss and validation accuracy.  Use the global variables <code>valid_features</code> and <code>valid_labels</code> to calculate validation accuracy.  Use a keep probability of <code>1.0</code> to calculate the loss and validation accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[136]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_stats</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Print information about loss and validation accuracy</span>
<span class="sd">    : session: Current TensorFlow session</span>
<span class="sd">    : feature_batch: Batch of Numpy image data</span>
<span class="sd">    : label_batch: Batch of Numpy label data</span>
<span class="sd">    : cost: TensorFlow cost function</span>
<span class="sd">    : accuracy: TensorFlow accuracy function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">l</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">feature_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">label_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="n">valid_accuracy</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">valid_features</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">valid_labels</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loss </span><span class="si">%f</span><span class="s1">, train_accuracy </span><span class="si">%g</span><span class="s1">, valid accuracy </span><span class="si">%g</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="p">,</span> <span class="n">valid_accuracy</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of iterations until the network stops learning or start overfitting</li>
<li>Set <code>batch_size</code> to the highest number that your machine has memory for.  Most people set them to common sizes of memory:<ul>
<li>64</li>
<li>128</li>
<li>256</li>
<li>...</li>
</ul>
</li>
<li>Set <code>keep_probability</code> to the probability of keeping a node using dropout</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[159]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># TODO: Tune Parameters</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">600</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.6</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-on-a-Single-CIFAR-10-Batch">Train on a Single CIFAR-10 Batch<a class="anchor-link" href="#Train-on-a-Single-CIFAR-10-Batch">&#182;</a></h3><p>Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[160]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Checking the Training on a Single Batch...&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess_training_batch</span><span class="p">(</span><span class="n">batch_i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;2}</span><span class="s1">, CIFAR-10 Batch </span><span class="si">{}</span><span class="s1">:  &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Checking the Training on a Single Batch...
Epoch  1, CIFAR-10 Batch 1:  loss 2.312561, train_accuracy 0.15, valid accuracy 0.125
Epoch  2, CIFAR-10 Batch 1:  loss 2.300617, train_accuracy 0.075, valid accuracy 0.112
Epoch  3, CIFAR-10 Batch 1:  loss 2.305267, train_accuracy 0.05, valid accuracy 0.103
Epoch  4, CIFAR-10 Batch 1:  loss 2.314233, train_accuracy 0.1, valid accuracy 0.1016
Epoch  5, CIFAR-10 Batch 1:  loss 2.311855, train_accuracy 0.1, valid accuracy 0.097
Epoch  6, CIFAR-10 Batch 1:  loss 2.311517, train_accuracy 0.1, valid accuracy 0.095
Epoch  7, CIFAR-10 Batch 1:  loss 2.315464, train_accuracy 0.1, valid accuracy 0.0948
Epoch  8, CIFAR-10 Batch 1:  loss 2.324066, train_accuracy 0.1, valid accuracy 0.0946
Epoch  9, CIFAR-10 Batch 1:  loss 2.343038, train_accuracy 0.1, valid accuracy 0.0946
Epoch 10, CIFAR-10 Batch 1:  loss 2.362362, train_accuracy 0.1, valid accuracy 0.0946
Epoch 11, CIFAR-10 Batch 1:  loss 2.381929, train_accuracy 0.1, valid accuracy 0.0946
Epoch 12, CIFAR-10 Batch 1:  loss 2.403596, train_accuracy 0.1, valid accuracy 0.0946
Epoch 13, CIFAR-10 Batch 1:  loss 2.424383, train_accuracy 0.1, valid accuracy 0.0946
Epoch 14, CIFAR-10 Batch 1:  loss 2.456482, train_accuracy 0.1, valid accuracy 0.0946
Epoch 15, CIFAR-10 Batch 1:  loss 2.483245, train_accuracy 0.1, valid accuracy 0.0946
Epoch 16, CIFAR-10 Batch 1:  loss 2.512489, train_accuracy 0.1, valid accuracy 0.0946
Epoch 17, CIFAR-10 Batch 1:  loss 2.539088, train_accuracy 0.1, valid accuracy 0.0946
Epoch 18, CIFAR-10 Batch 1:  loss 2.561691, train_accuracy 0.1, valid accuracy 0.0946
Epoch 19, CIFAR-10 Batch 1:  loss 2.587651, train_accuracy 0.1, valid accuracy 0.0946
Epoch 20, CIFAR-10 Batch 1:  loss 2.635099, train_accuracy 0.1, valid accuracy 0.0944
Epoch 21, CIFAR-10 Batch 1:  loss 2.608403, train_accuracy 0.1, valid accuracy 0.0942
Epoch 22, CIFAR-10 Batch 1:  loss 2.586698, train_accuracy 0.1, valid accuracy 0.0944
Epoch 23, CIFAR-10 Batch 1:  loss 2.548783, train_accuracy 0.125, valid accuracy 0.0944
Epoch 24, CIFAR-10 Batch 1:  loss 2.535705, train_accuracy 0.125, valid accuracy 0.0966
Epoch 25, CIFAR-10 Batch 1:  loss 2.514002, train_accuracy 0.125, valid accuracy 0.102
Epoch 26, CIFAR-10 Batch 1:  loss 2.444414, train_accuracy 0.1, valid accuracy 0.115
Epoch 27, CIFAR-10 Batch 1:  loss 2.394633, train_accuracy 0.15, valid accuracy 0.1268
Epoch 28, CIFAR-10 Batch 1:  loss 2.354872, train_accuracy 0.2, valid accuracy 0.1436
Epoch 29, CIFAR-10 Batch 1:  loss 2.302407, train_accuracy 0.175, valid accuracy 0.1604
Epoch 30, CIFAR-10 Batch 1:  loss 2.360500, train_accuracy 0.125, valid accuracy 0.1602
Epoch 31, CIFAR-10 Batch 1:  loss 2.402143, train_accuracy 0.125, valid accuracy 0.157
Epoch 32, CIFAR-10 Batch 1:  loss 2.281110, train_accuracy 0.15, valid accuracy 0.1898
Epoch 33, CIFAR-10 Batch 1:  loss 2.357641, train_accuracy 0.125, valid accuracy 0.1666
Epoch 34, CIFAR-10 Batch 1:  loss 2.256577, train_accuracy 0.125, valid accuracy 0.1896
Epoch 35, CIFAR-10 Batch 1:  loss 2.271103, train_accuracy 0.15, valid accuracy 0.1962
Epoch 36, CIFAR-10 Batch 1:  loss 2.216105, train_accuracy 0.175, valid accuracy 0.202
Epoch 37, CIFAR-10 Batch 1:  loss 2.119258, train_accuracy 0.175, valid accuracy 0.2238
Epoch 38, CIFAR-10 Batch 1:  loss 2.158032, train_accuracy 0.175, valid accuracy 0.2308
Epoch 39, CIFAR-10 Batch 1:  loss 2.230690, train_accuracy 0.125, valid accuracy 0.2118
Epoch 40, CIFAR-10 Batch 1:  loss 2.182487, train_accuracy 0.15, valid accuracy 0.2202
Epoch 41, CIFAR-10 Batch 1:  loss 2.072435, train_accuracy 0.15, valid accuracy 0.2398
Epoch 42, CIFAR-10 Batch 1:  loss 2.213862, train_accuracy 0.175, valid accuracy 0.2126
Epoch 43, CIFAR-10 Batch 1:  loss 2.135815, train_accuracy 0.15, valid accuracy 0.2322
Epoch 44, CIFAR-10 Batch 1:  loss 2.212153, train_accuracy 0.15, valid accuracy 0.218
Epoch 45, CIFAR-10 Batch 1:  loss 2.156616, train_accuracy 0.175, valid accuracy 0.226
Epoch 46, CIFAR-10 Batch 1:  loss 2.055180, train_accuracy 0.25, valid accuracy 0.2406
Epoch 47, CIFAR-10 Batch 1:  loss 2.059034, train_accuracy 0.175, valid accuracy 0.2544
Epoch 48, CIFAR-10 Batch 1:  loss 2.059647, train_accuracy 0.175, valid accuracy 0.2496
Epoch 49, CIFAR-10 Batch 1:  loss 1.996524, train_accuracy 0.225, valid accuracy 0.246
Epoch 50, CIFAR-10 Batch 1:  loss 2.008526, train_accuracy 0.25, valid accuracy 0.262
Epoch 51, CIFAR-10 Batch 1:  loss 2.070482, train_accuracy 0.2, valid accuracy 0.2504
Epoch 52, CIFAR-10 Batch 1:  loss 1.996046, train_accuracy 0.225, valid accuracy 0.265
Epoch 53, CIFAR-10 Batch 1:  loss 2.090189, train_accuracy 0.3, valid accuracy 0.2542
Epoch 54, CIFAR-10 Batch 1:  loss 1.980262, train_accuracy 0.275, valid accuracy 0.2674
Epoch 55, CIFAR-10 Batch 1:  loss 1.993598, train_accuracy 0.3, valid accuracy 0.2688
Epoch 56, CIFAR-10 Batch 1:  loss 1.937981, train_accuracy 0.3, valid accuracy 0.2878
Epoch 57, CIFAR-10 Batch 1:  loss 1.902350, train_accuracy 0.35, valid accuracy 0.2764
Epoch 58, CIFAR-10 Batch 1:  loss 1.929422, train_accuracy 0.325, valid accuracy 0.2812
Epoch 59, CIFAR-10 Batch 1:  loss 1.971360, train_accuracy 0.325, valid accuracy 0.2722
Epoch 60, CIFAR-10 Batch 1:  loss 1.918163, train_accuracy 0.325, valid accuracy 0.2914
Epoch 61, CIFAR-10 Batch 1:  loss 2.035899, train_accuracy 0.3, valid accuracy 0.266
Epoch 62, CIFAR-10 Batch 1:  loss 2.055534, train_accuracy 0.3, valid accuracy 0.275
Epoch 63, CIFAR-10 Batch 1:  loss 2.031682, train_accuracy 0.325, valid accuracy 0.2848
Epoch 64, CIFAR-10 Batch 1:  loss 2.032642, train_accuracy 0.3, valid accuracy 0.272
Epoch 65, CIFAR-10 Batch 1:  loss 2.044261, train_accuracy 0.325, valid accuracy 0.282
Epoch 66, CIFAR-10 Batch 1:  loss 2.035256, train_accuracy 0.275, valid accuracy 0.2762
Epoch 67, CIFAR-10 Batch 1:  loss 1.957087, train_accuracy 0.375, valid accuracy 0.291
Epoch 68, CIFAR-10 Batch 1:  loss 1.952211, train_accuracy 0.35, valid accuracy 0.2852
Epoch 69, CIFAR-10 Batch 1:  loss 1.915447, train_accuracy 0.275, valid accuracy 0.3016
Epoch 70, CIFAR-10 Batch 1:  loss 1.894190, train_accuracy 0.325, valid accuracy 0.2924
Epoch 71, CIFAR-10 Batch 1:  loss 1.853135, train_accuracy 0.375, valid accuracy 0.3066
Epoch 72, CIFAR-10 Batch 1:  loss 1.772229, train_accuracy 0.35, valid accuracy 0.3194
Epoch 73, CIFAR-10 Batch 1:  loss 1.839634, train_accuracy 0.325, valid accuracy 0.2994
Epoch 74, CIFAR-10 Batch 1:  loss 1.939697, train_accuracy 0.325, valid accuracy 0.2812
Epoch 75, CIFAR-10 Batch 1:  loss 1.871938, train_accuracy 0.375, valid accuracy 0.3064
Epoch 76, CIFAR-10 Batch 1:  loss 1.717269, train_accuracy 0.4, valid accuracy 0.3288
Epoch 77, CIFAR-10 Batch 1:  loss 1.712000, train_accuracy 0.425, valid accuracy 0.3332
Epoch 78, CIFAR-10 Batch 1:  loss 1.740502, train_accuracy 0.45, valid accuracy 0.3074
Epoch 79, CIFAR-10 Batch 1:  loss 1.653355, train_accuracy 0.375, valid accuracy 0.3494
Epoch 80, CIFAR-10 Batch 1:  loss 1.693317, train_accuracy 0.4, valid accuracy 0.3446
Epoch 81, CIFAR-10 Batch 1:  loss 1.732082, train_accuracy 0.425, valid accuracy 0.3252
Epoch 82, CIFAR-10 Batch 1:  loss 1.738801, train_accuracy 0.4, valid accuracy 0.3128
Epoch 83, CIFAR-10 Batch 1:  loss 1.634805, train_accuracy 0.425, valid accuracy 0.3442
Epoch 84, CIFAR-10 Batch 1:  loss 1.644272, train_accuracy 0.475, valid accuracy 0.348
Epoch 85, CIFAR-10 Batch 1:  loss 1.598599, train_accuracy 0.4, valid accuracy 0.3438
Epoch 86, CIFAR-10 Batch 1:  loss 1.643878, train_accuracy 0.425, valid accuracy 0.3568
Epoch 87, CIFAR-10 Batch 1:  loss 1.554946, train_accuracy 0.425, valid accuracy 0.3548
Epoch 88, CIFAR-10 Batch 1:  loss 1.503479, train_accuracy 0.45, valid accuracy 0.3868
Epoch 89, CIFAR-10 Batch 1:  loss 1.608453, train_accuracy 0.375, valid accuracy 0.3598
Epoch 90, CIFAR-10 Batch 1:  loss 1.644360, train_accuracy 0.425, valid accuracy 0.3522
Epoch 91, CIFAR-10 Batch 1:  loss 1.506720, train_accuracy 0.45, valid accuracy 0.3856
Epoch 92, CIFAR-10 Batch 1:  loss 1.543811, train_accuracy 0.425, valid accuracy 0.3904
Epoch 93, CIFAR-10 Batch 1:  loss 1.456621, train_accuracy 0.45, valid accuracy 0.3842
Epoch 94, CIFAR-10 Batch 1:  loss 1.439984, train_accuracy 0.425, valid accuracy 0.3992
Epoch 95, CIFAR-10 Batch 1:  loss 1.479715, train_accuracy 0.4, valid accuracy 0.3972
Epoch 96, CIFAR-10 Batch 1:  loss 1.451247, train_accuracy 0.4, valid accuracy 0.4004
Epoch 97, CIFAR-10 Batch 1:  loss 1.491055, train_accuracy 0.45, valid accuracy 0.3944
Epoch 98, CIFAR-10 Batch 1:  loss 1.391663, train_accuracy 0.45, valid accuracy 0.4282
Epoch 99, CIFAR-10 Batch 1:  loss 1.477727, train_accuracy 0.4, valid accuracy 0.393
Epoch 100, CIFAR-10 Batch 1:  loss 1.366663, train_accuracy 0.475, valid accuracy 0.415
Epoch 101, CIFAR-10 Batch 1:  loss 1.347913, train_accuracy 0.5, valid accuracy 0.4298
Epoch 102, CIFAR-10 Batch 1:  loss 1.325369, train_accuracy 0.5, valid accuracy 0.431
Epoch 103, CIFAR-10 Batch 1:  loss 1.271630, train_accuracy 0.55, valid accuracy 0.4328
Epoch 104, CIFAR-10 Batch 1:  loss 1.309869, train_accuracy 0.5, valid accuracy 0.434
Epoch 105, CIFAR-10 Batch 1:  loss 1.348710, train_accuracy 0.5, valid accuracy 0.4072
Epoch 106, CIFAR-10 Batch 1:  loss 1.253899, train_accuracy 0.575, valid accuracy 0.434
Epoch 107, CIFAR-10 Batch 1:  loss 1.362493, train_accuracy 0.475, valid accuracy 0.4096
Epoch 108, CIFAR-10 Batch 1:  loss 1.330299, train_accuracy 0.525, valid accuracy 0.4208
Epoch 109, CIFAR-10 Batch 1:  loss 1.313998, train_accuracy 0.575, valid accuracy 0.4184
Epoch 110, CIFAR-10 Batch 1:  loss 1.316847, train_accuracy 0.6, valid accuracy 0.4362
Epoch 111, CIFAR-10 Batch 1:  loss 1.347208, train_accuracy 0.5, valid accuracy 0.419
Epoch 112, CIFAR-10 Batch 1:  loss 1.228617, train_accuracy 0.6, valid accuracy 0.4464
Epoch 113, CIFAR-10 Batch 1:  loss 1.273110, train_accuracy 0.525, valid accuracy 0.434
Epoch 114, CIFAR-10 Batch 1:  loss 1.264521, train_accuracy 0.525, valid accuracy 0.4444
Epoch 115, CIFAR-10 Batch 1:  loss 1.237081, train_accuracy 0.55, valid accuracy 0.4474
Epoch 116, CIFAR-10 Batch 1:  loss 1.232516, train_accuracy 0.6, valid accuracy 0.4626
Epoch 117, CIFAR-10 Batch 1:  loss 1.187383, train_accuracy 0.6, valid accuracy 0.4572
Epoch 118, CIFAR-10 Batch 1:  loss 1.237448, train_accuracy 0.55, valid accuracy 0.4374
Epoch 119, CIFAR-10 Batch 1:  loss 1.193815, train_accuracy 0.55, valid accuracy 0.463
Epoch 120, CIFAR-10 Batch 1:  loss 1.109348, train_accuracy 0.6, valid accuracy 0.4656
Epoch 121, CIFAR-10 Batch 1:  loss 1.212321, train_accuracy 0.5, valid accuracy 0.4562
Epoch 122, CIFAR-10 Batch 1:  loss 1.125972, train_accuracy 0.6, valid accuracy 0.4746
Epoch 123, CIFAR-10 Batch 1:  loss 1.154700, train_accuracy 0.575, valid accuracy 0.4812
Epoch 124, CIFAR-10 Batch 1:  loss 1.085715, train_accuracy 0.65, valid accuracy 0.4928
Epoch 125, CIFAR-10 Batch 1:  loss 1.078615, train_accuracy 0.65, valid accuracy 0.4956
Epoch 126, CIFAR-10 Batch 1:  loss 1.057190, train_accuracy 0.675, valid accuracy 0.4918
Epoch 127, CIFAR-10 Batch 1:  loss 1.123332, train_accuracy 0.6, valid accuracy 0.4744
Epoch 128, CIFAR-10 Batch 1:  loss 1.116494, train_accuracy 0.65, valid accuracy 0.4774
Epoch 129, CIFAR-10 Batch 1:  loss 1.083166, train_accuracy 0.65, valid accuracy 0.478
Epoch 130, CIFAR-10 Batch 1:  loss 1.116404, train_accuracy 0.6, valid accuracy 0.4724
Epoch 131, CIFAR-10 Batch 1:  loss 1.115869, train_accuracy 0.6, valid accuracy 0.4644
Epoch 132, CIFAR-10 Batch 1:  loss 1.127482, train_accuracy 0.575, valid accuracy 0.474
Epoch 133, CIFAR-10 Batch 1:  loss 1.029274, train_accuracy 0.625, valid accuracy 0.4826
Epoch 134, CIFAR-10 Batch 1:  loss 1.018227, train_accuracy 0.65, valid accuracy 0.486
Epoch 135, CIFAR-10 Batch 1:  loss 1.030870, train_accuracy 0.65, valid accuracy 0.492
Epoch 136, CIFAR-10 Batch 1:  loss 0.982496, train_accuracy 0.675, valid accuracy 0.502
Epoch 137, CIFAR-10 Batch 1:  loss 0.978893, train_accuracy 0.7, valid accuracy 0.4864
Epoch 138, CIFAR-10 Batch 1:  loss 1.041295, train_accuracy 0.65, valid accuracy 0.4914
Epoch 139, CIFAR-10 Batch 1:  loss 0.992990, train_accuracy 0.675, valid accuracy 0.4994
Epoch 140, CIFAR-10 Batch 1:  loss 0.956903, train_accuracy 0.725, valid accuracy 0.4886
Epoch 141, CIFAR-10 Batch 1:  loss 0.935323, train_accuracy 0.675, valid accuracy 0.5074
Epoch 142, CIFAR-10 Batch 1:  loss 0.949833, train_accuracy 0.725, valid accuracy 0.4856
Epoch 143, CIFAR-10 Batch 1:  loss 0.904306, train_accuracy 0.675, valid accuracy 0.5166
Epoch 144, CIFAR-10 Batch 1:  loss 0.926509, train_accuracy 0.7, valid accuracy 0.5168
Epoch 145, CIFAR-10 Batch 1:  loss 0.866621, train_accuracy 0.7, valid accuracy 0.5324
Epoch 146, CIFAR-10 Batch 1:  loss 0.935732, train_accuracy 0.675, valid accuracy 0.517
Epoch 147, CIFAR-10 Batch 1:  loss 0.866222, train_accuracy 0.75, valid accuracy 0.5268
Epoch 148, CIFAR-10 Batch 1:  loss 0.902047, train_accuracy 0.75, valid accuracy 0.512
Epoch 149, CIFAR-10 Batch 1:  loss 0.932491, train_accuracy 0.7, valid accuracy 0.5246
Epoch 150, CIFAR-10 Batch 1:  loss 0.850661, train_accuracy 0.725, valid accuracy 0.52
Epoch 151, CIFAR-10 Batch 1:  loss 0.933424, train_accuracy 0.675, valid accuracy 0.4962
Epoch 152, CIFAR-10 Batch 1:  loss 0.805882, train_accuracy 0.8, valid accuracy 0.5168
Epoch 153, CIFAR-10 Batch 1:  loss 0.889112, train_accuracy 0.75, valid accuracy 0.5034
Epoch 154, CIFAR-10 Batch 1:  loss 0.814018, train_accuracy 0.8, valid accuracy 0.5298
Epoch 155, CIFAR-10 Batch 1:  loss 0.828970, train_accuracy 0.775, valid accuracy 0.532
Epoch 156, CIFAR-10 Batch 1:  loss 0.785511, train_accuracy 0.75, valid accuracy 0.5274
Epoch 157, CIFAR-10 Batch 1:  loss 0.810792, train_accuracy 0.775, valid accuracy 0.5198
Epoch 158, CIFAR-10 Batch 1:  loss 0.770692, train_accuracy 0.725, valid accuracy 0.5426
Epoch 159, CIFAR-10 Batch 1:  loss 0.846093, train_accuracy 0.75, valid accuracy 0.5334
Epoch 160, CIFAR-10 Batch 1:  loss 0.800865, train_accuracy 0.75, valid accuracy 0.5174
Epoch 161, CIFAR-10 Batch 1:  loss 0.777110, train_accuracy 0.75, valid accuracy 0.5366
Epoch 162, CIFAR-10 Batch 1:  loss 0.839331, train_accuracy 0.725, valid accuracy 0.5336
Epoch 163, CIFAR-10 Batch 1:  loss 0.722487, train_accuracy 0.825, valid accuracy 0.5502
Epoch 164, CIFAR-10 Batch 1:  loss 0.732012, train_accuracy 0.8, valid accuracy 0.5364
Epoch 165, CIFAR-10 Batch 1:  loss 0.726750, train_accuracy 0.8, valid accuracy 0.5394
Epoch 166, CIFAR-10 Batch 1:  loss 0.731616, train_accuracy 0.85, valid accuracy 0.5494
Epoch 167, CIFAR-10 Batch 1:  loss 0.707911, train_accuracy 0.9, valid accuracy 0.5516
Epoch 168, CIFAR-10 Batch 1:  loss 0.692947, train_accuracy 0.85, valid accuracy 0.5398
Epoch 169, CIFAR-10 Batch 1:  loss 0.673117, train_accuracy 0.85, valid accuracy 0.5628
Epoch 170, CIFAR-10 Batch 1:  loss 0.682221, train_accuracy 0.85, valid accuracy 0.5602
Epoch 171, CIFAR-10 Batch 1:  loss 0.685058, train_accuracy 0.8, valid accuracy 0.5598
Epoch 172, CIFAR-10 Batch 1:  loss 0.693073, train_accuracy 0.825, valid accuracy 0.5422
Epoch 173, CIFAR-10 Batch 1:  loss 0.667445, train_accuracy 0.825, valid accuracy 0.5612
Epoch 174, CIFAR-10 Batch 1:  loss 0.680469, train_accuracy 0.85, valid accuracy 0.539
Epoch 175, CIFAR-10 Batch 1:  loss 0.645765, train_accuracy 0.9, valid accuracy 0.5506
Epoch 176, CIFAR-10 Batch 1:  loss 0.639620, train_accuracy 0.875, valid accuracy 0.5444
Epoch 177, CIFAR-10 Batch 1:  loss 0.649764, train_accuracy 0.8, valid accuracy 0.5534
Epoch 178, CIFAR-10 Batch 1:  loss 0.617328, train_accuracy 0.875, valid accuracy 0.5544
Epoch 179, CIFAR-10 Batch 1:  loss 0.587419, train_accuracy 0.875, valid accuracy 0.5702
Epoch 180, CIFAR-10 Batch 1:  loss 0.557072, train_accuracy 0.875, valid accuracy 0.5804
Epoch 181, CIFAR-10 Batch 1:  loss 0.544673, train_accuracy 0.9, valid accuracy 0.5742
Epoch 182, CIFAR-10 Batch 1:  loss 0.535526, train_accuracy 0.9, valid accuracy 0.5636
Epoch 183, CIFAR-10 Batch 1:  loss 0.555479, train_accuracy 0.875, valid accuracy 0.5768
Epoch 184, CIFAR-10 Batch 1:  loss 0.530559, train_accuracy 0.875, valid accuracy 0.5798
Epoch 185, CIFAR-10 Batch 1:  loss 0.517625, train_accuracy 0.925, valid accuracy 0.5896
Epoch 186, CIFAR-10 Batch 1:  loss 0.535573, train_accuracy 0.925, valid accuracy 0.576
Epoch 187, CIFAR-10 Batch 1:  loss 0.515925, train_accuracy 0.9, valid accuracy 0.5748
Epoch 188, CIFAR-10 Batch 1:  loss 0.604528, train_accuracy 0.875, valid accuracy 0.5462
Epoch 189, CIFAR-10 Batch 1:  loss 0.525599, train_accuracy 0.925, valid accuracy 0.5584
Epoch 190, CIFAR-10 Batch 1:  loss 0.495244, train_accuracy 0.9, valid accuracy 0.5684
Epoch 191, CIFAR-10 Batch 1:  loss 0.476542, train_accuracy 0.9, valid accuracy 0.585
Epoch 192, CIFAR-10 Batch 1:  loss 0.518196, train_accuracy 0.9, valid accuracy 0.5574
Epoch 193, CIFAR-10 Batch 1:  loss 0.449511, train_accuracy 0.925, valid accuracy 0.5768
Epoch 194, CIFAR-10 Batch 1:  loss 0.473994, train_accuracy 0.9, valid accuracy 0.5756
Epoch 195, CIFAR-10 Batch 1:  loss 0.537782, train_accuracy 0.875, valid accuracy 0.5438
Epoch 196, CIFAR-10 Batch 1:  loss 0.436037, train_accuracy 0.925, valid accuracy 0.5852
Epoch 197, CIFAR-10 Batch 1:  loss 0.446965, train_accuracy 0.925, valid accuracy 0.576
Epoch 198, CIFAR-10 Batch 1:  loss 0.454484, train_accuracy 0.9, valid accuracy 0.5624
Epoch 199, CIFAR-10 Batch 1:  loss 0.444205, train_accuracy 0.9, valid accuracy 0.5456
Epoch 200, CIFAR-10 Batch 1:  loss 0.434274, train_accuracy 0.95, valid accuracy 0.5624
Epoch 201, CIFAR-10 Batch 1:  loss 0.439374, train_accuracy 0.9, valid accuracy 0.5732
Epoch 202, CIFAR-10 Batch 1:  loss 0.447145, train_accuracy 0.875, valid accuracy 0.5904
Epoch 203, CIFAR-10 Batch 1:  loss 0.348606, train_accuracy 0.95, valid accuracy 0.5858
Epoch 204, CIFAR-10 Batch 1:  loss 0.391458, train_accuracy 0.925, valid accuracy 0.5612
Epoch 205, CIFAR-10 Batch 1:  loss 0.354685, train_accuracy 0.925, valid accuracy 0.5918
Epoch 206, CIFAR-10 Batch 1:  loss 0.363725, train_accuracy 0.95, valid accuracy 0.5938
Epoch 207, CIFAR-10 Batch 1:  loss 0.355905, train_accuracy 0.925, valid accuracy 0.5896
Epoch 208, CIFAR-10 Batch 1:  loss 0.356753, train_accuracy 0.925, valid accuracy 0.6008
Epoch 209, CIFAR-10 Batch 1:  loss 0.347290, train_accuracy 0.95, valid accuracy 0.6054
Epoch 210, CIFAR-10 Batch 1:  loss 0.357455, train_accuracy 0.95, valid accuracy 0.5888
Epoch 211, CIFAR-10 Batch 1:  loss 0.322762, train_accuracy 0.95, valid accuracy 0.5958
Epoch 212, CIFAR-10 Batch 1:  loss 0.321825, train_accuracy 0.95, valid accuracy 0.5922
Epoch 213, CIFAR-10 Batch 1:  loss 0.304644, train_accuracy 0.95, valid accuracy 0.6046
Epoch 214, CIFAR-10 Batch 1:  loss 0.268853, train_accuracy 0.95, valid accuracy 0.6068
Epoch 215, CIFAR-10 Batch 1:  loss 0.309829, train_accuracy 0.925, valid accuracy 0.5764
Epoch 216, CIFAR-10 Batch 1:  loss 0.254380, train_accuracy 0.975, valid accuracy 0.6034
Epoch 217, CIFAR-10 Batch 1:  loss 0.291961, train_accuracy 0.975, valid accuracy 0.5878
Epoch 218, CIFAR-10 Batch 1:  loss 0.263717, train_accuracy 0.975, valid accuracy 0.5872
Epoch 219, CIFAR-10 Batch 1:  loss 0.273017, train_accuracy 0.95, valid accuracy 0.5836
Epoch 220, CIFAR-10 Batch 1:  loss 0.278778, train_accuracy 0.95, valid accuracy 0.6134
Epoch 221, CIFAR-10 Batch 1:  loss 0.275739, train_accuracy 0.975, valid accuracy 0.59
Epoch 222, CIFAR-10 Batch 1:  loss 0.281888, train_accuracy 0.975, valid accuracy 0.5874
Epoch 223, CIFAR-10 Batch 1:  loss 0.258191, train_accuracy 0.975, valid accuracy 0.6016
Epoch 224, CIFAR-10 Batch 1:  loss 0.206432, train_accuracy 1, valid accuracy 0.6092
Epoch 225, CIFAR-10 Batch 1:  loss 0.228918, train_accuracy 1, valid accuracy 0.6106
Epoch 226, CIFAR-10 Batch 1:  loss 0.228459, train_accuracy 0.95, valid accuracy 0.607
Epoch 227, CIFAR-10 Batch 1:  loss 0.242706, train_accuracy 0.975, valid accuracy 0.5928
Epoch 228, CIFAR-10 Batch 1:  loss 0.211163, train_accuracy 1, valid accuracy 0.597
Epoch 229, CIFAR-10 Batch 1:  loss 0.213235, train_accuracy 1, valid accuracy 0.5856
Epoch 230, CIFAR-10 Batch 1:  loss 0.193634, train_accuracy 1, valid accuracy 0.6062
Epoch 231, CIFAR-10 Batch 1:  loss 0.184538, train_accuracy 1, valid accuracy 0.6116
Epoch 232, CIFAR-10 Batch 1:  loss 0.192917, train_accuracy 0.975, valid accuracy 0.6144
Epoch 233, CIFAR-10 Batch 1:  loss 0.190167, train_accuracy 0.975, valid accuracy 0.6086
Epoch 234, CIFAR-10 Batch 1:  loss 0.146949, train_accuracy 1, valid accuracy 0.6034
Epoch 235, CIFAR-10 Batch 1:  loss 0.136713, train_accuracy 1, valid accuracy 0.6238
Epoch 236, CIFAR-10 Batch 1:  loss 0.136979, train_accuracy 1, valid accuracy 0.6178
Epoch 237, CIFAR-10 Batch 1:  loss 0.161897, train_accuracy 1, valid accuracy 0.6104
Epoch 238, CIFAR-10 Batch 1:  loss 0.140757, train_accuracy 1, valid accuracy 0.6134
Epoch 239, CIFAR-10 Batch 1:  loss 0.157645, train_accuracy 1, valid accuracy 0.6116
Epoch 240, CIFAR-10 Batch 1:  loss 0.160723, train_accuracy 1, valid accuracy 0.5898
Epoch 241, CIFAR-10 Batch 1:  loss 0.122534, train_accuracy 1, valid accuracy 0.6186
Epoch 242, CIFAR-10 Batch 1:  loss 0.144422, train_accuracy 1, valid accuracy 0.5904
Epoch 243, CIFAR-10 Batch 1:  loss 0.144948, train_accuracy 0.975, valid accuracy 0.5992
Epoch 244, CIFAR-10 Batch 1:  loss 0.135945, train_accuracy 1, valid accuracy 0.6094
Epoch 245, CIFAR-10 Batch 1:  loss 0.115611, train_accuracy 1, valid accuracy 0.6212
Epoch 246, CIFAR-10 Batch 1:  loss 0.109809, train_accuracy 1, valid accuracy 0.6188
Epoch 247, CIFAR-10 Batch 1:  loss 0.130898, train_accuracy 1, valid accuracy 0.6116
Epoch 248, CIFAR-10 Batch 1:  loss 0.119019, train_accuracy 1, valid accuracy 0.6224
Epoch 249, CIFAR-10 Batch 1:  loss 0.095728, train_accuracy 1, valid accuracy 0.6334
Epoch 250, CIFAR-10 Batch 1:  loss 0.121556, train_accuracy 1, valid accuracy 0.614
Epoch 251, CIFAR-10 Batch 1:  loss 0.101990, train_accuracy 1, valid accuracy 0.6122
Epoch 252, CIFAR-10 Batch 1:  loss 0.122306, train_accuracy 1, valid accuracy 0.5924
Epoch 253, CIFAR-10 Batch 1:  loss 0.092119, train_accuracy 1, valid accuracy 0.6136
Epoch 254, CIFAR-10 Batch 1:  loss 0.101799, train_accuracy 1, valid accuracy 0.6172
Epoch 255, CIFAR-10 Batch 1:  loss 0.103523, train_accuracy 1, valid accuracy 0.6154
Epoch 256, CIFAR-10 Batch 1:  loss 0.082929, train_accuracy 1, valid accuracy 0.635
Epoch 257, CIFAR-10 Batch 1:  loss 0.072520, train_accuracy 1, valid accuracy 0.6168
Epoch 258, CIFAR-10 Batch 1:  loss 0.075378, train_accuracy 1, valid accuracy 0.6242
Epoch 259, CIFAR-10 Batch 1:  loss 0.070907, train_accuracy 1, valid accuracy 0.6164
Epoch 260, CIFAR-10 Batch 1:  loss 0.060429, train_accuracy 1, valid accuracy 0.6372
Epoch 261, CIFAR-10 Batch 1:  loss 0.072498, train_accuracy 1, valid accuracy 0.6298
Epoch 262, CIFAR-10 Batch 1:  loss 0.069513, train_accuracy 1, valid accuracy 0.6246
Epoch 263, CIFAR-10 Batch 1:  loss 0.059295, train_accuracy 1, valid accuracy 0.6358
Epoch 264, CIFAR-10 Batch 1:  loss 0.051020, train_accuracy 1, valid accuracy 0.626
Epoch 265, CIFAR-10 Batch 1:  loss 0.058887, train_accuracy 1, valid accuracy 0.6352
Epoch 266, CIFAR-10 Batch 1:  loss 0.069514, train_accuracy 1, valid accuracy 0.6072
Epoch 267, CIFAR-10 Batch 1:  loss 0.056659, train_accuracy 1, valid accuracy 0.6138
Epoch 268, CIFAR-10 Batch 1:  loss 0.054898, train_accuracy 1, valid accuracy 0.6366
Epoch 269, CIFAR-10 Batch 1:  loss 0.059951, train_accuracy 1, valid accuracy 0.634
Epoch 270, CIFAR-10 Batch 1:  loss 0.060350, train_accuracy 1, valid accuracy 0.6254
Epoch 271, CIFAR-10 Batch 1:  loss 0.049077, train_accuracy 1, valid accuracy 0.625
Epoch 272, CIFAR-10 Batch 1:  loss 0.048326, train_accuracy 1, valid accuracy 0.6376
Epoch 273, CIFAR-10 Batch 1:  loss 0.059308, train_accuracy 1, valid accuracy 0.6344
Epoch 274, CIFAR-10 Batch 1:  loss 0.040095, train_accuracy 1, valid accuracy 0.6428
Epoch 275, CIFAR-10 Batch 1:  loss 0.044424, train_accuracy 1, valid accuracy 0.6216
Epoch 276, CIFAR-10 Batch 1:  loss 0.045277, train_accuracy 1, valid accuracy 0.642
Epoch 277, CIFAR-10 Batch 1:  loss 0.037222, train_accuracy 1, valid accuracy 0.6424
Epoch 278, CIFAR-10 Batch 1:  loss 0.031479, train_accuracy 1, valid accuracy 0.6418
Epoch 279, CIFAR-10 Batch 1:  loss 0.027053, train_accuracy 1, valid accuracy 0.6422
Epoch 280, CIFAR-10 Batch 1:  loss 0.026720, train_accuracy 1, valid accuracy 0.6368
Epoch 281, CIFAR-10 Batch 1:  loss 0.026677, train_accuracy 1, valid accuracy 0.6446
Epoch 282, CIFAR-10 Batch 1:  loss 0.028722, train_accuracy 1, valid accuracy 0.6458
Epoch 283, CIFAR-10 Batch 1:  loss 0.029608, train_accuracy 1, valid accuracy 0.6388
Epoch 284, CIFAR-10 Batch 1:  loss 0.043596, train_accuracy 1, valid accuracy 0.6086
Epoch 285, CIFAR-10 Batch 1:  loss 0.028550, train_accuracy 1, valid accuracy 0.6426
Epoch 286, CIFAR-10 Batch 1:  loss 0.024009, train_accuracy 1, valid accuracy 0.6424
Epoch 287, CIFAR-10 Batch 1:  loss 0.036036, train_accuracy 1, valid accuracy 0.642
Epoch 288, CIFAR-10 Batch 1:  loss 0.037624, train_accuracy 1, valid accuracy 0.628
Epoch 289, CIFAR-10 Batch 1:  loss 0.035466, train_accuracy 1, valid accuracy 0.633
Epoch 290, CIFAR-10 Batch 1:  loss 0.032957, train_accuracy 1, valid accuracy 0.647
Epoch 291, CIFAR-10 Batch 1:  loss 0.035134, train_accuracy 1, valid accuracy 0.6428
Epoch 292, CIFAR-10 Batch 1:  loss 0.042568, train_accuracy 1, valid accuracy 0.6504
Epoch 293, CIFAR-10 Batch 1:  loss 0.036961, train_accuracy 1, valid accuracy 0.6412
Epoch 294, CIFAR-10 Batch 1:  loss 0.037030, train_accuracy 1, valid accuracy 0.6494
Epoch 295, CIFAR-10 Batch 1:  loss 0.031398, train_accuracy 1, valid accuracy 0.645
Epoch 296, CIFAR-10 Batch 1:  loss 0.033353, train_accuracy 1, valid accuracy 0.6286
Epoch 297, CIFAR-10 Batch 1:  loss 0.023536, train_accuracy 1, valid accuracy 0.6442
Epoch 298, CIFAR-10 Batch 1:  loss 0.026580, train_accuracy 1, valid accuracy 0.649
Epoch 299, CIFAR-10 Batch 1:  loss 0.026225, train_accuracy 1, valid accuracy 0.6362
Epoch 300, CIFAR-10 Batch 1:  loss 0.019279, train_accuracy 1, valid accuracy 0.6376
Epoch 301, CIFAR-10 Batch 1:  loss 0.029785, train_accuracy 1, valid accuracy 0.6522
Epoch 302, CIFAR-10 Batch 1:  loss 0.037614, train_accuracy 1, valid accuracy 0.6528
Epoch 303, CIFAR-10 Batch 1:  loss 0.023230, train_accuracy 1, valid accuracy 0.6568
Epoch 304, CIFAR-10 Batch 1:  loss 0.028250, train_accuracy 1, valid accuracy 0.6284
Epoch 305, CIFAR-10 Batch 1:  loss 0.025673, train_accuracy 1, valid accuracy 0.6522
Epoch 306, CIFAR-10 Batch 1:  loss 0.023065, train_accuracy 1, valid accuracy 0.6482
Epoch 307, CIFAR-10 Batch 1:  loss 0.028744, train_accuracy 1, valid accuracy 0.6436
Epoch 308, CIFAR-10 Batch 1:  loss 0.019150, train_accuracy 1, valid accuracy 0.647
Epoch 309, CIFAR-10 Batch 1:  loss 0.018525, train_accuracy 1, valid accuracy 0.6322
Epoch 310, CIFAR-10 Batch 1:  loss 0.018114, train_accuracy 1, valid accuracy 0.639
Epoch 311, CIFAR-10 Batch 1:  loss 0.032869, train_accuracy 1, valid accuracy 0.633
Epoch 312, CIFAR-10 Batch 1:  loss 0.018099, train_accuracy 1, valid accuracy 0.618
Epoch 313, CIFAR-10 Batch 1:  loss 0.020043, train_accuracy 1, valid accuracy 0.6404
Epoch 314, CIFAR-10 Batch 1:  loss 0.011243, train_accuracy 1, valid accuracy 0.6408
Epoch 315, CIFAR-10 Batch 1:  loss 0.020375, train_accuracy 1, valid accuracy 0.6554
Epoch 316, CIFAR-10 Batch 1:  loss 0.016493, train_accuracy 1, valid accuracy 0.6426
Epoch 317, CIFAR-10 Batch 1:  loss 0.011665, train_accuracy 1, valid accuracy 0.6456
Epoch 318, CIFAR-10 Batch 1:  loss 0.011098, train_accuracy 1, valid accuracy 0.643
Epoch 319, CIFAR-10 Batch 1:  loss 0.012649, train_accuracy 1, valid accuracy 0.6296
Epoch 320, CIFAR-10 Batch 1:  loss 0.024615, train_accuracy 1, valid accuracy 0.6384
Epoch 321, CIFAR-10 Batch 1:  loss 0.011446, train_accuracy 1, valid accuracy 0.6336
Epoch 322, CIFAR-10 Batch 1:  loss 0.007576, train_accuracy 1, valid accuracy 0.6386
Epoch 323, CIFAR-10 Batch 1:  loss 0.010586, train_accuracy 1, valid accuracy 0.6348
Epoch 324, CIFAR-10 Batch 1:  loss 0.011260, train_accuracy 1, valid accuracy 0.6336
Epoch 325, CIFAR-10 Batch 1:  loss 0.015735, train_accuracy 1, valid accuracy 0.6468
Epoch 326, CIFAR-10 Batch 1:  loss 0.007050, train_accuracy 1, valid accuracy 0.641
Epoch 327, CIFAR-10 Batch 1:  loss 0.013236, train_accuracy 1, valid accuracy 0.6344
Epoch 328, CIFAR-10 Batch 1:  loss 0.012683, train_accuracy 1, valid accuracy 0.6316
Epoch 329, CIFAR-10 Batch 1:  loss 0.014233, train_accuracy 1, valid accuracy 0.6254
Epoch 330, CIFAR-10 Batch 1:  loss 0.007825, train_accuracy 1, valid accuracy 0.6512
Epoch 331, CIFAR-10 Batch 1:  loss 0.012143, train_accuracy 1, valid accuracy 0.6456
Epoch 332, CIFAR-10 Batch 1:  loss 0.009054, train_accuracy 1, valid accuracy 0.6406
Epoch 333, CIFAR-10 Batch 1:  loss 0.007262, train_accuracy 1, valid accuracy 0.6452
Epoch 334, CIFAR-10 Batch 1:  loss 0.004519, train_accuracy 1, valid accuracy 0.6534
Epoch 335, CIFAR-10 Batch 1:  loss 0.009209, train_accuracy 1, valid accuracy 0.6436
Epoch 336, CIFAR-10 Batch 1:  loss 0.007079, train_accuracy 1, valid accuracy 0.6362
Epoch 337, CIFAR-10 Batch 1:  loss 0.013783, train_accuracy 1, valid accuracy 0.6482
Epoch 338, CIFAR-10 Batch 1:  loss 0.012017, train_accuracy 1, valid accuracy 0.6428
Epoch 339, CIFAR-10 Batch 1:  loss 0.008574, train_accuracy 1, valid accuracy 0.6464
Epoch 340, CIFAR-10 Batch 1:  loss 0.006926, train_accuracy 1, valid accuracy 0.6396
Epoch 341, CIFAR-10 Batch 1:  loss 0.009378, train_accuracy 1, valid accuracy 0.639
Epoch 342, CIFAR-10 Batch 1:  loss 0.005311, train_accuracy 1, valid accuracy 0.6606
Epoch 343, CIFAR-10 Batch 1:  loss 0.004814, train_accuracy 1, valid accuracy 0.6414
Epoch 344, CIFAR-10 Batch 1:  loss 0.007073, train_accuracy 1, valid accuracy 0.6344
Epoch 345, CIFAR-10 Batch 1:  loss 0.006275, train_accuracy 1, valid accuracy 0.6596
Epoch 346, CIFAR-10 Batch 1:  loss 0.005301, train_accuracy 1, valid accuracy 0.6548
Epoch 347, CIFAR-10 Batch 1:  loss 0.006724, train_accuracy 1, valid accuracy 0.6524
Epoch 348, CIFAR-10 Batch 1:  loss 0.004266, train_accuracy 1, valid accuracy 0.6592
Epoch 349, CIFAR-10 Batch 1:  loss 0.006233, train_accuracy 1, valid accuracy 0.6216
Epoch 350, CIFAR-10 Batch 1:  loss 0.002972, train_accuracy 1, valid accuracy 0.6486
Epoch 351, CIFAR-10 Batch 1:  loss 0.003394, train_accuracy 1, valid accuracy 0.653
Epoch 352, CIFAR-10 Batch 1:  loss 0.002449, train_accuracy 1, valid accuracy 0.6578
Epoch 353, CIFAR-10 Batch 1:  loss 0.002873, train_accuracy 1, valid accuracy 0.6606
Epoch 354, CIFAR-10 Batch 1:  loss 0.002272, train_accuracy 1, valid accuracy 0.6634
Epoch 355, CIFAR-10 Batch 1:  loss 0.006290, train_accuracy 1, valid accuracy 0.6566
Epoch 356, CIFAR-10 Batch 1:  loss 0.004444, train_accuracy 1, valid accuracy 0.6604
Epoch 357, CIFAR-10 Batch 1:  loss 0.003743, train_accuracy 1, valid accuracy 0.6578
Epoch 358, CIFAR-10 Batch 1:  loss 0.002922, train_accuracy 1, valid accuracy 0.6514
Epoch 359, CIFAR-10 Batch 1:  loss 0.003911, train_accuracy 1, valid accuracy 0.6588
Epoch 360, CIFAR-10 Batch 1:  loss 0.003237, train_accuracy 1, valid accuracy 0.6528
Epoch 361, CIFAR-10 Batch 1:  loss 0.002325, train_accuracy 1, valid accuracy 0.6552
Epoch 362, CIFAR-10 Batch 1:  loss 0.003607, train_accuracy 1, valid accuracy 0.6582
Epoch 363, CIFAR-10 Batch 1:  loss 0.004775, train_accuracy 1, valid accuracy 0.6674
Epoch 364, CIFAR-10 Batch 1:  loss 0.005296, train_accuracy 1, valid accuracy 0.6644
Epoch 365, CIFAR-10 Batch 1:  loss 0.003685, train_accuracy 1, valid accuracy 0.6496
Epoch 366, CIFAR-10 Batch 1:  loss 0.001370, train_accuracy 1, valid accuracy 0.6672
Epoch 367, CIFAR-10 Batch 1:  loss 0.004389, train_accuracy 1, valid accuracy 0.657
Epoch 368, CIFAR-10 Batch 1:  loss 0.004789, train_accuracy 1, valid accuracy 0.6584
Epoch 369, CIFAR-10 Batch 1:  loss 0.003065, train_accuracy 1, valid accuracy 0.6508
Epoch 370, CIFAR-10 Batch 1:  loss 0.006805, train_accuracy 1, valid accuracy 0.6542
Epoch 371, CIFAR-10 Batch 1:  loss 0.002211, train_accuracy 1, valid accuracy 0.6608
Epoch 372, CIFAR-10 Batch 1:  loss 0.002235, train_accuracy 1, valid accuracy 0.6544
Epoch 373, CIFAR-10 Batch 1:  loss 0.002832, train_accuracy 1, valid accuracy 0.6622
Epoch 374, CIFAR-10 Batch 1:  loss 0.004036, train_accuracy 1, valid accuracy 0.6514
Epoch 375, CIFAR-10 Batch 1:  loss 0.003402, train_accuracy 1, valid accuracy 0.6496
Epoch 376, CIFAR-10 Batch 1:  loss 0.003108, train_accuracy 1, valid accuracy 0.6534
Epoch 377, CIFAR-10 Batch 1:  loss 0.002487, train_accuracy 1, valid accuracy 0.6542
Epoch 378, CIFAR-10 Batch 1:  loss 0.002142, train_accuracy 1, valid accuracy 0.6474
Epoch 379, CIFAR-10 Batch 1:  loss 0.002397, train_accuracy 1, valid accuracy 0.6576
Epoch 380, CIFAR-10 Batch 1:  loss 0.002262, train_accuracy 1, valid accuracy 0.6626
Epoch 381, CIFAR-10 Batch 1:  loss 0.002426, train_accuracy 1, valid accuracy 0.6468
Epoch 382, CIFAR-10 Batch 1:  loss 0.002947, train_accuracy 1, valid accuracy 0.6566
Epoch 383, CIFAR-10 Batch 1:  loss 0.003225, train_accuracy 1, valid accuracy 0.6584
Epoch 384, CIFAR-10 Batch 1:  loss 0.001134, train_accuracy 1, valid accuracy 0.6422
Epoch 385, CIFAR-10 Batch 1:  loss 0.001690, train_accuracy 1, valid accuracy 0.6472
Epoch 386, CIFAR-10 Batch 1:  loss 0.003496, train_accuracy 1, valid accuracy 0.6486
Epoch 387, CIFAR-10 Batch 1:  loss 0.003133, train_accuracy 1, valid accuracy 0.6474
Epoch 388, CIFAR-10 Batch 1:  loss 0.002191, train_accuracy 1, valid accuracy 0.6542
Epoch 389, CIFAR-10 Batch 1:  loss 0.002814, train_accuracy 1, valid accuracy 0.6552
Epoch 390, CIFAR-10 Batch 1:  loss 0.002282, train_accuracy 1, valid accuracy 0.6558
Epoch 391, CIFAR-10 Batch 1:  loss 0.002976, train_accuracy 1, valid accuracy 0.6338
Epoch 392, CIFAR-10 Batch 1:  loss 0.002132, train_accuracy 1, valid accuracy 0.6274
Epoch 393, CIFAR-10 Batch 1:  loss 0.001677, train_accuracy 1, valid accuracy 0.6622
Epoch 394, CIFAR-10 Batch 1:  loss 0.002307, train_accuracy 1, valid accuracy 0.6532
Epoch 395, CIFAR-10 Batch 1:  loss 0.001082, train_accuracy 1, valid accuracy 0.6632
Epoch 396, CIFAR-10 Batch 1:  loss 0.001204, train_accuracy 1, valid accuracy 0.6604
Epoch 397, CIFAR-10 Batch 1:  loss 0.001356, train_accuracy 1, valid accuracy 0.6552
Epoch 398, CIFAR-10 Batch 1:  loss 0.002081, train_accuracy 1, valid accuracy 0.6574
Epoch 399, CIFAR-10 Batch 1:  loss 0.012555, train_accuracy 1, valid accuracy 0.6384
Epoch 400, CIFAR-10 Batch 1:  loss 0.001756, train_accuracy 1, valid accuracy 0.6646
Epoch 401, CIFAR-10 Batch 1:  loss 0.002124, train_accuracy 1, valid accuracy 0.664
Epoch 402, CIFAR-10 Batch 1:  loss 0.001039, train_accuracy 1, valid accuracy 0.6554
Epoch 403, CIFAR-10 Batch 1:  loss 0.001239, train_accuracy 1, valid accuracy 0.6358
Epoch 404, CIFAR-10 Batch 1:  loss 0.001334, train_accuracy 1, valid accuracy 0.6506
Epoch 405, CIFAR-10 Batch 1:  loss 0.001183, train_accuracy 1, valid accuracy 0.6662
Epoch 406, CIFAR-10 Batch 1:  loss 0.001791, train_accuracy 1, valid accuracy 0.6626
Epoch 407, CIFAR-10 Batch 1:  loss 0.000715, train_accuracy 1, valid accuracy 0.6578
Epoch 408, CIFAR-10 Batch 1:  loss 0.001437, train_accuracy 1, valid accuracy 0.6536
Epoch 409, CIFAR-10 Batch 1:  loss 0.002518, train_accuracy 1, valid accuracy 0.6588
Epoch 410, CIFAR-10 Batch 1:  loss 0.000433, train_accuracy 1, valid accuracy 0.6566
Epoch 411, CIFAR-10 Batch 1:  loss 0.003549, train_accuracy 1, valid accuracy 0.6556
Epoch 412, CIFAR-10 Batch 1:  loss 0.001365, train_accuracy 1, valid accuracy 0.655
Epoch 413, CIFAR-10 Batch 1:  loss 0.002182, train_accuracy 1, valid accuracy 0.6628
Epoch 414, CIFAR-10 Batch 1:  loss 0.001548, train_accuracy 1, valid accuracy 0.6548
Epoch 415, CIFAR-10 Batch 1:  loss 0.003143, train_accuracy 1, valid accuracy 0.6486
Epoch 416, CIFAR-10 Batch 1:  loss 0.006639, train_accuracy 1, valid accuracy 0.6648
Epoch 417, CIFAR-10 Batch 1:  loss 0.001568, train_accuracy 1, valid accuracy 0.6632
Epoch 418, CIFAR-10 Batch 1:  loss 0.001408, train_accuracy 1, valid accuracy 0.65
Epoch 419, CIFAR-10 Batch 1:  loss 0.001898, train_accuracy 1, valid accuracy 0.661
Epoch 420, CIFAR-10 Batch 1:  loss 0.002104, train_accuracy 1, valid accuracy 0.6504
Epoch 421, CIFAR-10 Batch 1:  loss 0.001042, train_accuracy 1, valid accuracy 0.6496
Epoch 422, CIFAR-10 Batch 1:  loss 0.002364, train_accuracy 1, valid accuracy 0.6534
Epoch 423, CIFAR-10 Batch 1:  loss 0.001750, train_accuracy 1, valid accuracy 0.6596
Epoch 424, CIFAR-10 Batch 1:  loss 0.001213, train_accuracy 1, valid accuracy 0.668
Epoch 425, CIFAR-10 Batch 1:  loss 0.001071, train_accuracy 1, valid accuracy 0.6528
Epoch 426, CIFAR-10 Batch 1:  loss 0.001179, train_accuracy 1, valid accuracy 0.6544
Epoch 427, CIFAR-10 Batch 1:  loss 0.000980, train_accuracy 1, valid accuracy 0.6548
Epoch 428, CIFAR-10 Batch 1:  loss 0.001532, train_accuracy 1, valid accuracy 0.6566
Epoch 429, CIFAR-10 Batch 1:  loss 0.001147, train_accuracy 1, valid accuracy 0.6584
Epoch 430, CIFAR-10 Batch 1:  loss 0.001223, train_accuracy 1, valid accuracy 0.668
Epoch 431, CIFAR-10 Batch 1:  loss 0.001667, train_accuracy 1, valid accuracy 0.6598
Epoch 432, CIFAR-10 Batch 1:  loss 0.001341, train_accuracy 1, valid accuracy 0.658
Epoch 433, CIFAR-10 Batch 1:  loss 0.000827, train_accuracy 1, valid accuracy 0.6642
Epoch 434, CIFAR-10 Batch 1:  loss 0.000632, train_accuracy 1, valid accuracy 0.6738
Epoch 435, CIFAR-10 Batch 1:  loss 0.000756, train_accuracy 1, valid accuracy 0.6676
Epoch 436, CIFAR-10 Batch 1:  loss 0.001162, train_accuracy 1, valid accuracy 0.6644
Epoch 437, CIFAR-10 Batch 1:  loss 0.000632, train_accuracy 1, valid accuracy 0.6604
Epoch 438, CIFAR-10 Batch 1:  loss 0.001025, train_accuracy 1, valid accuracy 0.6586
Epoch 439, CIFAR-10 Batch 1:  loss 0.001597, train_accuracy 1, valid accuracy 0.6598
Epoch 440, CIFAR-10 Batch 1:  loss 0.001458, train_accuracy 1, valid accuracy 0.6564
Epoch 441, CIFAR-10 Batch 1:  loss 0.001659, train_accuracy 1, valid accuracy 0.6598
Epoch 442, CIFAR-10 Batch 1:  loss 0.001052, train_accuracy 1, valid accuracy 0.6674
Epoch 443, CIFAR-10 Batch 1:  loss 0.000611, train_accuracy 1, valid accuracy 0.6658
Epoch 444, CIFAR-10 Batch 1:  loss 0.000758, train_accuracy 1, valid accuracy 0.6716
Epoch 445, CIFAR-10 Batch 1:  loss 0.002168, train_accuracy 1, valid accuracy 0.6652
Epoch 446, CIFAR-10 Batch 1:  loss 0.001309, train_accuracy 1, valid accuracy 0.6702
Epoch 447, CIFAR-10 Batch 1:  loss 0.000422, train_accuracy 1, valid accuracy 0.6608
Epoch 448, CIFAR-10 Batch 1:  loss 0.001125, train_accuracy 1, valid accuracy 0.6586
Epoch 449, CIFAR-10 Batch 1:  loss 0.000960, train_accuracy 1, valid accuracy 0.6672
Epoch 450, CIFAR-10 Batch 1:  loss 0.001193, train_accuracy 1, valid accuracy 0.6652
Epoch 451, CIFAR-10 Batch 1:  loss 0.001166, train_accuracy 1, valid accuracy 0.6608
Epoch 452, CIFAR-10 Batch 1:  loss 0.000572, train_accuracy 1, valid accuracy 0.6562
Epoch 453, CIFAR-10 Batch 1:  loss 0.000955, train_accuracy 1, valid accuracy 0.6612
Epoch 454, CIFAR-10 Batch 1:  loss 0.000519, train_accuracy 1, valid accuracy 0.6668
Epoch 455, CIFAR-10 Batch 1:  loss 0.000889, train_accuracy 1, valid accuracy 0.6682
Epoch 456, CIFAR-10 Batch 1:  loss 0.000944, train_accuracy 1, valid accuracy 0.6712
Epoch 457, CIFAR-10 Batch 1:  loss 0.000535, train_accuracy 1, valid accuracy 0.6638
Epoch 458, CIFAR-10 Batch 1:  loss 0.000458, train_accuracy 1, valid accuracy 0.6642
Epoch 459, CIFAR-10 Batch 1:  loss 0.000616, train_accuracy 1, valid accuracy 0.6522
Epoch 460, CIFAR-10 Batch 1:  loss 0.000553, train_accuracy 1, valid accuracy 0.6508
Epoch 461, CIFAR-10 Batch 1:  loss 0.000804, train_accuracy 1, valid accuracy 0.6578
Epoch 462, CIFAR-10 Batch 1:  loss 0.000373, train_accuracy 1, valid accuracy 0.662
Epoch 463, CIFAR-10 Batch 1:  loss 0.000789, train_accuracy 1, valid accuracy 0.6426
Epoch 464, CIFAR-10 Batch 1:  loss 0.000908, train_accuracy 1, valid accuracy 0.649
Epoch 465, CIFAR-10 Batch 1:  loss 0.000429, train_accuracy 1, valid accuracy 0.6598
Epoch 466, CIFAR-10 Batch 1:  loss 0.000359, train_accuracy 1, valid accuracy 0.6494
Epoch 467, CIFAR-10 Batch 1:  loss 0.000324, train_accuracy 1, valid accuracy 0.6542
Epoch 468, CIFAR-10 Batch 1:  loss 0.000493, train_accuracy 1, valid accuracy 0.6528
Epoch 469, CIFAR-10 Batch 1:  loss 0.000605, train_accuracy 1, valid accuracy 0.6616
Epoch 470, CIFAR-10 Batch 1:  loss 0.000629, train_accuracy 1, valid accuracy 0.6618
Epoch 471, CIFAR-10 Batch 1:  loss 0.000419, train_accuracy 1, valid accuracy 0.661
Epoch 472, CIFAR-10 Batch 1:  loss 0.000293, train_accuracy 1, valid accuracy 0.6592
Epoch 473, CIFAR-10 Batch 1:  loss 0.000297, train_accuracy 1, valid accuracy 0.6614
Epoch 474, CIFAR-10 Batch 1:  loss 0.000368, train_accuracy 1, valid accuracy 0.6672
Epoch 475, CIFAR-10 Batch 1:  loss 0.001155, train_accuracy 1, valid accuracy 0.6654
Epoch 476, CIFAR-10 Batch 1:  loss 0.001204, train_accuracy 1, valid accuracy 0.6586
Epoch 477, CIFAR-10 Batch 1:  loss 0.000281, train_accuracy 1, valid accuracy 0.65
Epoch 478, CIFAR-10 Batch 1:  loss 0.000983, train_accuracy 1, valid accuracy 0.6692
Epoch 479, CIFAR-10 Batch 1:  loss 0.000416, train_accuracy 1, valid accuracy 0.6618
Epoch 480, CIFAR-10 Batch 1:  loss 0.000666, train_accuracy 1, valid accuracy 0.6616
Epoch 481, CIFAR-10 Batch 1:  loss 0.001717, train_accuracy 1, valid accuracy 0.6466
Epoch 482, CIFAR-10 Batch 1:  loss 0.000954, train_accuracy 1, valid accuracy 0.6676
Epoch 483, CIFAR-10 Batch 1:  loss 0.000280, train_accuracy 1, valid accuracy 0.6648
Epoch 484, CIFAR-10 Batch 1:  loss 0.000315, train_accuracy 1, valid accuracy 0.6688
Epoch 485, CIFAR-10 Batch 1:  loss 0.000908, train_accuracy 1, valid accuracy 0.6622
Epoch 486, CIFAR-10 Batch 1:  loss 0.000757, train_accuracy 1, valid accuracy 0.6574
Epoch 487, CIFAR-10 Batch 1:  loss 0.000513, train_accuracy 1, valid accuracy 0.6618
Epoch 488, CIFAR-10 Batch 1:  loss 0.000408, train_accuracy 1, valid accuracy 0.6562
Epoch 489, CIFAR-10 Batch 1:  loss 0.000456, train_accuracy 1, valid accuracy 0.6596
Epoch 490, CIFAR-10 Batch 1:  loss 0.000498, train_accuracy 1, valid accuracy 0.6672
Epoch 491, CIFAR-10 Batch 1:  loss 0.000696, train_accuracy 1, valid accuracy 0.6584
Epoch 492, CIFAR-10 Batch 1:  loss 0.000470, train_accuracy 1, valid accuracy 0.6568
Epoch 493, CIFAR-10 Batch 1:  loss 0.000627, train_accuracy 1, valid accuracy 0.6422
Epoch 494, CIFAR-10 Batch 1:  loss 0.000269, train_accuracy 1, valid accuracy 0.668
Epoch 495, CIFAR-10 Batch 1:  loss 0.000415, train_accuracy 1, valid accuracy 0.6566
Epoch 496, CIFAR-10 Batch 1:  loss 0.000193, train_accuracy 1, valid accuracy 0.6596
Epoch 497, CIFAR-10 Batch 1:  loss 0.000229, train_accuracy 1, valid accuracy 0.6672
Epoch 498, CIFAR-10 Batch 1:  loss 0.000169, train_accuracy 1, valid accuracy 0.6612
Epoch 499, CIFAR-10 Batch 1:  loss 0.000310, train_accuracy 1, valid accuracy 0.6624
Epoch 500, CIFAR-10 Batch 1:  loss 0.000485, train_accuracy 1, valid accuracy 0.659
Epoch 501, CIFAR-10 Batch 1:  loss 0.000379, train_accuracy 1, valid accuracy 0.6594
Epoch 502, CIFAR-10 Batch 1:  loss 0.000168, train_accuracy 1, valid accuracy 0.6652
Epoch 503, CIFAR-10 Batch 1:  loss 0.000373, train_accuracy 1, valid accuracy 0.6598
Epoch 504, CIFAR-10 Batch 1:  loss 0.000186, train_accuracy 1, valid accuracy 0.6662
Epoch 505, CIFAR-10 Batch 1:  loss 0.000132, train_accuracy 1, valid accuracy 0.671
Epoch 506, CIFAR-10 Batch 1:  loss 0.000366, train_accuracy 1, valid accuracy 0.6532
Epoch 507, CIFAR-10 Batch 1:  loss 0.000359, train_accuracy 1, valid accuracy 0.6612
Epoch 508, CIFAR-10 Batch 1:  loss 0.000201, train_accuracy 1, valid accuracy 0.6676
Epoch 509, CIFAR-10 Batch 1:  loss 0.000209, train_accuracy 1, valid accuracy 0.665
Epoch 510, CIFAR-10 Batch 1:  loss 0.000655, train_accuracy 1, valid accuracy 0.664
Epoch 511, CIFAR-10 Batch 1:  loss 0.000388, train_accuracy 1, valid accuracy 0.6686
Epoch 512, CIFAR-10 Batch 1:  loss 0.000952, train_accuracy 1, valid accuracy 0.6674
Epoch 513, CIFAR-10 Batch 1:  loss 0.000184, train_accuracy 1, valid accuracy 0.667
Epoch 514, CIFAR-10 Batch 1:  loss 0.000127, train_accuracy 1, valid accuracy 0.67
Epoch 515, CIFAR-10 Batch 1:  loss 0.000190, train_accuracy 1, valid accuracy 0.6668
Epoch 516, CIFAR-10 Batch 1:  loss 0.000257, train_accuracy 1, valid accuracy 0.6558
Epoch 517, CIFAR-10 Batch 1:  loss 0.000261, train_accuracy 1, valid accuracy 0.663
Epoch 518, CIFAR-10 Batch 1:  loss 0.000113, train_accuracy 1, valid accuracy 0.6568
Epoch 519, CIFAR-10 Batch 1:  loss 0.000371, train_accuracy 1, valid accuracy 0.6648
Epoch 520, CIFAR-10 Batch 1:  loss 0.000338, train_accuracy 1, valid accuracy 0.6678
Epoch 521, CIFAR-10 Batch 1:  loss 0.000117, train_accuracy 1, valid accuracy 0.6762
Epoch 522, CIFAR-10 Batch 1:  loss 0.000803, train_accuracy 1, valid accuracy 0.6794
Epoch 523, CIFAR-10 Batch 1:  loss 0.000222, train_accuracy 1, valid accuracy 0.6724
Epoch 524, CIFAR-10 Batch 1:  loss 0.000253, train_accuracy 1, valid accuracy 0.673
Epoch 525, CIFAR-10 Batch 1:  loss 0.000327, train_accuracy 1, valid accuracy 0.6626
Epoch 526, CIFAR-10 Batch 1:  loss 0.000458, train_accuracy 1, valid accuracy 0.677
Epoch 527, CIFAR-10 Batch 1:  loss 0.000209, train_accuracy 1, valid accuracy 0.6676
Epoch 528, CIFAR-10 Batch 1:  loss 0.000435, train_accuracy 1, valid accuracy 0.6742
Epoch 529, CIFAR-10 Batch 1:  loss 0.000226, train_accuracy 1, valid accuracy 0.671
Epoch 530, CIFAR-10 Batch 1:  loss 0.000470, train_accuracy 1, valid accuracy 0.6678
Epoch 531, CIFAR-10 Batch 1:  loss 0.000199, train_accuracy 1, valid accuracy 0.6722
Epoch 532, CIFAR-10 Batch 1:  loss 0.000101, train_accuracy 1, valid accuracy 0.6754
Epoch 533, CIFAR-10 Batch 1:  loss 0.000056, train_accuracy 1, valid accuracy 0.6734
Epoch 534, CIFAR-10 Batch 1:  loss 0.000155, train_accuracy 1, valid accuracy 0.6714
Epoch 535, CIFAR-10 Batch 1:  loss 0.000315, train_accuracy 1, valid accuracy 0.6728
Epoch 536, CIFAR-10 Batch 1:  loss 0.000136, train_accuracy 1, valid accuracy 0.6658
Epoch 537, CIFAR-10 Batch 1:  loss 0.000200, train_accuracy 1, valid accuracy 0.6736
Epoch 538, CIFAR-10 Batch 1:  loss 0.000166, train_accuracy 1, valid accuracy 0.6668
Epoch 539, CIFAR-10 Batch 1:  loss 0.000352, train_accuracy 1, valid accuracy 0.6662
Epoch 540, CIFAR-10 Batch 1:  loss 0.000266, train_accuracy 1, valid accuracy 0.6676
Epoch 541, CIFAR-10 Batch 1:  loss 0.000167, train_accuracy 1, valid accuracy 0.649
Epoch 542, CIFAR-10 Batch 1:  loss 0.000235, train_accuracy 1, valid accuracy 0.663
Epoch 543, CIFAR-10 Batch 1:  loss 0.000418, train_accuracy 1, valid accuracy 0.6714
Epoch 544, CIFAR-10 Batch 1:  loss 0.000128, train_accuracy 1, valid accuracy 0.6658
Epoch 545, CIFAR-10 Batch 1:  loss 0.000699, train_accuracy 1, valid accuracy 0.6654
Epoch 546, CIFAR-10 Batch 1:  loss 0.000207, train_accuracy 1, valid accuracy 0.662
Epoch 547, CIFAR-10 Batch 1:  loss 0.000095, train_accuracy 1, valid accuracy 0.6712
Epoch 548, CIFAR-10 Batch 1:  loss 0.000106, train_accuracy 1, valid accuracy 0.6652
Epoch 549, CIFAR-10 Batch 1:  loss 0.000213, train_accuracy 1, valid accuracy 0.6608
Epoch 550, CIFAR-10 Batch 1:  loss 0.000131, train_accuracy 1, valid accuracy 0.6668
Epoch 551, CIFAR-10 Batch 1:  loss 0.000369, train_accuracy 1, valid accuracy 0.6662
Epoch 552, CIFAR-10 Batch 1:  loss 0.000797, train_accuracy 1, valid accuracy 0.6706
Epoch 553, CIFAR-10 Batch 1:  loss 0.000184, train_accuracy 1, valid accuracy 0.6656
Epoch 554, CIFAR-10 Batch 1:  loss 0.000325, train_accuracy 1, valid accuracy 0.669
Epoch 555, CIFAR-10 Batch 1:  loss 0.000118, train_accuracy 1, valid accuracy 0.6696
Epoch 556, CIFAR-10 Batch 1:  loss 0.000164, train_accuracy 1, valid accuracy 0.6708
Epoch 557, CIFAR-10 Batch 1:  loss 0.000115, train_accuracy 1, valid accuracy 0.6676
Epoch 558, CIFAR-10 Batch 1:  loss 0.001063, train_accuracy 1, valid accuracy 0.6646
Epoch 559, CIFAR-10 Batch 1:  loss 0.000054, train_accuracy 1, valid accuracy 0.6752
Epoch 560, CIFAR-10 Batch 1:  loss 0.000502, train_accuracy 1, valid accuracy 0.677
Epoch 561, CIFAR-10 Batch 1:  loss 0.000101, train_accuracy 1, valid accuracy 0.6686
Epoch 562, CIFAR-10 Batch 1:  loss 0.000069, train_accuracy 1, valid accuracy 0.677
Epoch 563, CIFAR-10 Batch 1:  loss 0.000403, train_accuracy 1, valid accuracy 0.6794
Epoch 564, CIFAR-10 Batch 1:  loss 0.000090, train_accuracy 1, valid accuracy 0.6756
Epoch 565, CIFAR-10 Batch 1:  loss 0.000108, train_accuracy 1, valid accuracy 0.6762
Epoch 566, CIFAR-10 Batch 1:  loss 0.001369, train_accuracy 1, valid accuracy 0.6708
Epoch 567, CIFAR-10 Batch 1:  loss 0.000265, train_accuracy 1, valid accuracy 0.6738
Epoch 568, CIFAR-10 Batch 1:  loss 0.000393, train_accuracy 1, valid accuracy 0.6762
Epoch 569, CIFAR-10 Batch 1:  loss 0.000223, train_accuracy 1, valid accuracy 0.6702
Epoch 570, CIFAR-10 Batch 1:  loss 0.000118, train_accuracy 1, valid accuracy 0.6714
Epoch 571, CIFAR-10 Batch 1:  loss 0.000046, train_accuracy 1, valid accuracy 0.6648
Epoch 572, CIFAR-10 Batch 1:  loss 0.000092, train_accuracy 1, valid accuracy 0.67
Epoch 573, CIFAR-10 Batch 1:  loss 0.000060, train_accuracy 1, valid accuracy 0.6706
Epoch 574, CIFAR-10 Batch 1:  loss 0.000274, train_accuracy 1, valid accuracy 0.6756
Epoch 575, CIFAR-10 Batch 1:  loss 0.000056, train_accuracy 1, valid accuracy 0.667
Epoch 576, CIFAR-10 Batch 1:  loss 0.000073, train_accuracy 1, valid accuracy 0.6678
Epoch 577, CIFAR-10 Batch 1:  loss 0.000187, train_accuracy 1, valid accuracy 0.6686
Epoch 578, CIFAR-10 Batch 1:  loss 0.000117, train_accuracy 1, valid accuracy 0.6614
Epoch 579, CIFAR-10 Batch 1:  loss 0.000073, train_accuracy 1, valid accuracy 0.6774
Epoch 580, CIFAR-10 Batch 1:  loss 0.000107, train_accuracy 1, valid accuracy 0.6726
Epoch 581, CIFAR-10 Batch 1:  loss 0.000164, train_accuracy 1, valid accuracy 0.6688
Epoch 582, CIFAR-10 Batch 1:  loss 0.000124, train_accuracy 1, valid accuracy 0.677
Epoch 583, CIFAR-10 Batch 1:  loss 0.000521, train_accuracy 1, valid accuracy 0.67
Epoch 584, CIFAR-10 Batch 1:  loss 0.000151, train_accuracy 1, valid accuracy 0.6742
Epoch 585, CIFAR-10 Batch 1:  loss 0.000101, train_accuracy 1, valid accuracy 0.664
Epoch 586, CIFAR-10 Batch 1:  loss 0.000046, train_accuracy 1, valid accuracy 0.6752
Epoch 587, CIFAR-10 Batch 1:  loss 0.000042, train_accuracy 1, valid accuracy 0.6744
Epoch 588, CIFAR-10 Batch 1:  loss 0.000044, train_accuracy 1, valid accuracy 0.6656
Epoch 589, CIFAR-10 Batch 1:  loss 0.000055, train_accuracy 1, valid accuracy 0.6716
Epoch 590, CIFAR-10 Batch 1:  loss 0.000066, train_accuracy 1, valid accuracy 0.6666
Epoch 591, CIFAR-10 Batch 1:  loss 0.000104, train_accuracy 1, valid accuracy 0.6718
Epoch 592, CIFAR-10 Batch 1:  loss 0.000039, train_accuracy 1, valid accuracy 0.6594
Epoch 593, CIFAR-10 Batch 1:  loss 0.000223, train_accuracy 1, valid accuracy 0.6738
Epoch 594, CIFAR-10 Batch 1:  loss 0.000131, train_accuracy 1, valid accuracy 0.6708
Epoch 595, CIFAR-10 Batch 1:  loss 0.000040, train_accuracy 1, valid accuracy 0.6594
Epoch 596, CIFAR-10 Batch 1:  loss 0.000243, train_accuracy 1, valid accuracy 0.6714
Epoch 597, CIFAR-10 Batch 1:  loss 0.000375, train_accuracy 1, valid accuracy 0.658
Epoch 598, CIFAR-10 Batch 1:  loss 0.000060, train_accuracy 1, valid accuracy 0.6758
Epoch 599, CIFAR-10 Batch 1:  loss 0.000651, train_accuracy 1, valid accuracy 0.6804
Epoch 600, CIFAR-10 Batch 1:  loss 0.000074, train_accuracy 1, valid accuracy 0.6738
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Fully-Train-the-Model">Fully Train the Model<a class="anchor-link" href="#Fully-Train-the-Model">&#182;</a></h3><p>Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[161]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_model_path</span> <span class="o">=</span> <span class="s1">&#39;./image_classification&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training...&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="c1"># Training cycle</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Loop over all batches</span>
        <span class="n">n_batches</span> <span class="o">=</span> <span class="mi">5</span>
        <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_batches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess_training_batch</span><span class="p">(</span><span class="n">batch_i</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">train_neural_network</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">keep_probability</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;2}</span><span class="s1">, CIFAR-10 Batch </span><span class="si">{}</span><span class="s1">:  &#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            <span class="n">print_stats</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
            
    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_model_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training...
Epoch  1, CIFAR-10 Batch 1:  loss 2.271044, train_accuracy 0.175, valid accuracy 0.134
Epoch  1, CIFAR-10 Batch 2:  loss 2.334074, train_accuracy 0.05, valid accuracy 0.0946
Epoch  1, CIFAR-10 Batch 3:  loss 2.319691, train_accuracy 0.05, valid accuracy 0.0946
Epoch  1, CIFAR-10 Batch 4:  loss 2.285172, train_accuracy 0.15, valid accuracy 0.0946
Epoch  1, CIFAR-10 Batch 5:  loss 2.306232, train_accuracy 0.1, valid accuracy 0.0946
Epoch  2, CIFAR-10 Batch 1:  loss 2.307927, train_accuracy 0.1, valid accuracy 0.0946
Epoch  2, CIFAR-10 Batch 2:  loss 2.307360, train_accuracy 0.05, valid accuracy 0.0946
Epoch  2, CIFAR-10 Batch 3:  loss 2.310335, train_accuracy 0.05, valid accuracy 0.0946
Epoch  2, CIFAR-10 Batch 4:  loss 2.286575, train_accuracy 0.15, valid accuracy 0.0946
Epoch  2, CIFAR-10 Batch 5:  loss 2.313197, train_accuracy 0.1, valid accuracy 0.0946
Epoch  3, CIFAR-10 Batch 1:  loss 2.321627, train_accuracy 0.1, valid accuracy 0.0946
Epoch  3, CIFAR-10 Batch 2:  loss 2.318487, train_accuracy 0.05, valid accuracy 0.0946
Epoch  3, CIFAR-10 Batch 3:  loss 2.341111, train_accuracy 0.05, valid accuracy 0.0946
Epoch  3, CIFAR-10 Batch 4:  loss 2.281078, train_accuracy 0.15, valid accuracy 0.0946
Epoch  3, CIFAR-10 Batch 5:  loss 2.370485, train_accuracy 0.1, valid accuracy 0.0946
Epoch  4, CIFAR-10 Batch 1:  loss 2.385434, train_accuracy 0.1, valid accuracy 0.0946
Epoch  4, CIFAR-10 Batch 2:  loss 2.368228, train_accuracy 0.05, valid accuracy 0.0946
Epoch  4, CIFAR-10 Batch 3:  loss 2.389083, train_accuracy 0.05, valid accuracy 0.0946
Epoch  4, CIFAR-10 Batch 4:  loss 2.311312, train_accuracy 0.15, valid accuracy 0.0946
Epoch  4, CIFAR-10 Batch 5:  loss 2.502681, train_accuracy 0.1, valid accuracy 0.0946
Epoch  5, CIFAR-10 Batch 1:  loss 2.443245, train_accuracy 0.1, valid accuracy 0.0992
Epoch  5, CIFAR-10 Batch 2:  loss 2.379207, train_accuracy 0.075, valid accuracy 0.1008
Epoch  5, CIFAR-10 Batch 3:  loss 2.220908, train_accuracy 0.075, valid accuracy 0.1048
Epoch  5, CIFAR-10 Batch 4:  loss 2.261624, train_accuracy 0.15, valid accuracy 0.1144
Epoch  5, CIFAR-10 Batch 5:  loss 2.476570, train_accuracy 0.15, valid accuracy 0.1138
Epoch  6, CIFAR-10 Batch 1:  loss 2.501565, train_accuracy 0.1, valid accuracy 0.1142
Epoch  6, CIFAR-10 Batch 2:  loss 2.192663, train_accuracy 0.125, valid accuracy 0.1344
Epoch  6, CIFAR-10 Batch 3:  loss 2.125289, train_accuracy 0.125, valid accuracy 0.125
Epoch  6, CIFAR-10 Batch 4:  loss 2.102998, train_accuracy 0.2, valid accuracy 0.1438
Epoch  6, CIFAR-10 Batch 5:  loss 2.193203, train_accuracy 0.2, valid accuracy 0.16
Epoch  7, CIFAR-10 Batch 1:  loss 2.465976, train_accuracy 0.125, valid accuracy 0.156
Epoch  7, CIFAR-10 Batch 2:  loss 2.047404, train_accuracy 0.1, valid accuracy 0.1662
Epoch  7, CIFAR-10 Batch 3:  loss 2.017732, train_accuracy 0.15, valid accuracy 0.1562
Epoch  7, CIFAR-10 Batch 4:  loss 2.044284, train_accuracy 0.2, valid accuracy 0.151
Epoch  7, CIFAR-10 Batch 5:  loss 2.055947, train_accuracy 0.3, valid accuracy 0.2
Epoch  8, CIFAR-10 Batch 1:  loss 2.418849, train_accuracy 0.15, valid accuracy 0.1934
Epoch  8, CIFAR-10 Batch 2:  loss 2.070016, train_accuracy 0.1, valid accuracy 0.159
Epoch  8, CIFAR-10 Batch 3:  loss 1.891150, train_accuracy 0.175, valid accuracy 0.217
Epoch  8, CIFAR-10 Batch 4:  loss 1.920752, train_accuracy 0.225, valid accuracy 0.1978
Epoch  8, CIFAR-10 Batch 5:  loss 2.070249, train_accuracy 0.275, valid accuracy 0.2064
Epoch  9, CIFAR-10 Batch 1:  loss 2.481122, train_accuracy 0.125, valid accuracy 0.1798
Epoch  9, CIFAR-10 Batch 2:  loss 1.980615, train_accuracy 0.125, valid accuracy 0.1828
Epoch  9, CIFAR-10 Batch 3:  loss 1.919423, train_accuracy 0.15, valid accuracy 0.2076
Epoch  9, CIFAR-10 Batch 4:  loss 1.918592, train_accuracy 0.2, valid accuracy 0.2006
Epoch  9, CIFAR-10 Batch 5:  loss 2.085673, train_accuracy 0.3, valid accuracy 0.198
Epoch 10, CIFAR-10 Batch 1:  loss 2.339881, train_accuracy 0.175, valid accuracy 0.2148
Epoch 10, CIFAR-10 Batch 2:  loss 1.846202, train_accuracy 0.2, valid accuracy 0.2282
Epoch 10, CIFAR-10 Batch 3:  loss 1.947275, train_accuracy 0.15, valid accuracy 0.1998
Epoch 10, CIFAR-10 Batch 4:  loss 1.833250, train_accuracy 0.275, valid accuracy 0.2656
Epoch 10, CIFAR-10 Batch 5:  loss 2.078455, train_accuracy 0.275, valid accuracy 0.2048
Epoch 11, CIFAR-10 Batch 1:  loss 2.128017, train_accuracy 0.275, valid accuracy 0.2804
Epoch 11, CIFAR-10 Batch 2:  loss 1.970453, train_accuracy 0.175, valid accuracy 0.1824
Epoch 11, CIFAR-10 Batch 3:  loss 1.869625, train_accuracy 0.175, valid accuracy 0.221
Epoch 11, CIFAR-10 Batch 4:  loss 1.962877, train_accuracy 0.175, valid accuracy 0.2162
Epoch 11, CIFAR-10 Batch 5:  loss 1.893363, train_accuracy 0.275, valid accuracy 0.2574
Epoch 12, CIFAR-10 Batch 1:  loss 2.254345, train_accuracy 0.225, valid accuracy 0.2496
Epoch 12, CIFAR-10 Batch 2:  loss 1.946390, train_accuracy 0.175, valid accuracy 0.1932
Epoch 12, CIFAR-10 Batch 3:  loss 1.805210, train_accuracy 0.25, valid accuracy 0.2492
Epoch 12, CIFAR-10 Batch 4:  loss 1.899080, train_accuracy 0.25, valid accuracy 0.2502
Epoch 12, CIFAR-10 Batch 5:  loss 2.063457, train_accuracy 0.2, valid accuracy 0.221
Epoch 13, CIFAR-10 Batch 1:  loss 2.104213, train_accuracy 0.225, valid accuracy 0.2798
Epoch 13, CIFAR-10 Batch 2:  loss 2.042329, train_accuracy 0.2, valid accuracy 0.1964
Epoch 13, CIFAR-10 Batch 3:  loss 1.853367, train_accuracy 0.25, valid accuracy 0.2508
Epoch 13, CIFAR-10 Batch 4:  loss 1.905025, train_accuracy 0.275, valid accuracy 0.2384
Epoch 13, CIFAR-10 Batch 5:  loss 2.033168, train_accuracy 0.275, valid accuracy 0.2478
Epoch 14, CIFAR-10 Batch 1:  loss 2.131140, train_accuracy 0.3, valid accuracy 0.273
Epoch 14, CIFAR-10 Batch 2:  loss 1.948706, train_accuracy 0.175, valid accuracy 0.234
Epoch 14, CIFAR-10 Batch 3:  loss 1.781045, train_accuracy 0.375, valid accuracy 0.2864
Epoch 14, CIFAR-10 Batch 4:  loss 1.832924, train_accuracy 0.3, valid accuracy 0.2776
Epoch 14, CIFAR-10 Batch 5:  loss 1.867050, train_accuracy 0.35, valid accuracy 0.2902
Epoch 15, CIFAR-10 Batch 1:  loss 1.978346, train_accuracy 0.3, valid accuracy 0.3236
Epoch 15, CIFAR-10 Batch 2:  loss 1.877707, train_accuracy 0.225, valid accuracy 0.267
Epoch 15, CIFAR-10 Batch 3:  loss 1.877368, train_accuracy 0.375, valid accuracy 0.2662
Epoch 15, CIFAR-10 Batch 4:  loss 1.854818, train_accuracy 0.325, valid accuracy 0.2778
Epoch 15, CIFAR-10 Batch 5:  loss 1.991333, train_accuracy 0.375, valid accuracy 0.2736
Epoch 16, CIFAR-10 Batch 1:  loss 2.116701, train_accuracy 0.275, valid accuracy 0.2942
Epoch 16, CIFAR-10 Batch 2:  loss 1.846279, train_accuracy 0.225, valid accuracy 0.2826
Epoch 16, CIFAR-10 Batch 3:  loss 1.670655, train_accuracy 0.375, valid accuracy 0.3392
Epoch 16, CIFAR-10 Batch 4:  loss 1.822055, train_accuracy 0.325, valid accuracy 0.3122
Epoch 16, CIFAR-10 Batch 5:  loss 1.890085, train_accuracy 0.275, valid accuracy 0.3046
Epoch 17, CIFAR-10 Batch 1:  loss 2.092095, train_accuracy 0.35, valid accuracy 0.32
Epoch 17, CIFAR-10 Batch 2:  loss 1.924997, train_accuracy 0.225, valid accuracy 0.2596
Epoch 17, CIFAR-10 Batch 3:  loss 1.678016, train_accuracy 0.4, valid accuracy 0.3296
Epoch 17, CIFAR-10 Batch 4:  loss 1.846020, train_accuracy 0.325, valid accuracy 0.302
Epoch 17, CIFAR-10 Batch 5:  loss 1.837720, train_accuracy 0.35, valid accuracy 0.3238
Epoch 18, CIFAR-10 Batch 1:  loss 1.870719, train_accuracy 0.375, valid accuracy 0.3782
Epoch 18, CIFAR-10 Batch 2:  loss 1.829102, train_accuracy 0.2, valid accuracy 0.2938
Epoch 18, CIFAR-10 Batch 3:  loss 1.625607, train_accuracy 0.425, valid accuracy 0.3246
Epoch 18, CIFAR-10 Batch 4:  loss 1.793105, train_accuracy 0.35, valid accuracy 0.329
Epoch 18, CIFAR-10 Batch 5:  loss 1.873678, train_accuracy 0.35, valid accuracy 0.3198
Epoch 19, CIFAR-10 Batch 1:  loss 1.965288, train_accuracy 0.35, valid accuracy 0.3586
Epoch 19, CIFAR-10 Batch 2:  loss 1.878035, train_accuracy 0.25, valid accuracy 0.2962
Epoch 19, CIFAR-10 Batch 3:  loss 1.707242, train_accuracy 0.375, valid accuracy 0.3402
Epoch 19, CIFAR-10 Batch 4:  loss 1.716683, train_accuracy 0.35, valid accuracy 0.3554
Epoch 19, CIFAR-10 Batch 5:  loss 1.896444, train_accuracy 0.35, valid accuracy 0.3142
Epoch 20, CIFAR-10 Batch 1:  loss 1.876846, train_accuracy 0.35, valid accuracy 0.3732
Epoch 20, CIFAR-10 Batch 2:  loss 1.695452, train_accuracy 0.325, valid accuracy 0.3526
Epoch 20, CIFAR-10 Batch 3:  loss 1.681953, train_accuracy 0.45, valid accuracy 0.3548
Epoch 20, CIFAR-10 Batch 4:  loss 1.750260, train_accuracy 0.35, valid accuracy 0.344
Epoch 20, CIFAR-10 Batch 5:  loss 1.785180, train_accuracy 0.35, valid accuracy 0.3528
Epoch 21, CIFAR-10 Batch 1:  loss 1.802564, train_accuracy 0.375, valid accuracy 0.4086
Epoch 21, CIFAR-10 Batch 2:  loss 1.751834, train_accuracy 0.3, valid accuracy 0.3188
Epoch 21, CIFAR-10 Batch 3:  loss 1.567519, train_accuracy 0.375, valid accuracy 0.3978
Epoch 21, CIFAR-10 Batch 4:  loss 1.654115, train_accuracy 0.425, valid accuracy 0.3906
Epoch 21, CIFAR-10 Batch 5:  loss 1.763160, train_accuracy 0.475, valid accuracy 0.3396
Epoch 22, CIFAR-10 Batch 1:  loss 1.721428, train_accuracy 0.4, valid accuracy 0.4288
Epoch 22, CIFAR-10 Batch 2:  loss 1.662067, train_accuracy 0.35, valid accuracy 0.342
Epoch 22, CIFAR-10 Batch 3:  loss 1.489990, train_accuracy 0.45, valid accuracy 0.4216
Epoch 22, CIFAR-10 Batch 4:  loss 1.760961, train_accuracy 0.375, valid accuracy 0.3584
Epoch 22, CIFAR-10 Batch 5:  loss 1.926632, train_accuracy 0.35, valid accuracy 0.3078
Epoch 23, CIFAR-10 Batch 1:  loss 1.970618, train_accuracy 0.325, valid accuracy 0.381
Epoch 23, CIFAR-10 Batch 2:  loss 1.663108, train_accuracy 0.325, valid accuracy 0.3704
Epoch 23, CIFAR-10 Batch 3:  loss 1.655905, train_accuracy 0.375, valid accuracy 0.368
Epoch 23, CIFAR-10 Batch 4:  loss 1.705709, train_accuracy 0.45, valid accuracy 0.381
Epoch 23, CIFAR-10 Batch 5:  loss 1.624981, train_accuracy 0.425, valid accuracy 0.3942
Epoch 24, CIFAR-10 Batch 1:  loss 1.690188, train_accuracy 0.375, valid accuracy 0.4266
Epoch 24, CIFAR-10 Batch 2:  loss 1.580999, train_accuracy 0.375, valid accuracy 0.39
Epoch 24, CIFAR-10 Batch 3:  loss 1.524716, train_accuracy 0.375, valid accuracy 0.413
Epoch 24, CIFAR-10 Batch 4:  loss 1.641106, train_accuracy 0.425, valid accuracy 0.4108
Epoch 24, CIFAR-10 Batch 5:  loss 1.508768, train_accuracy 0.45, valid accuracy 0.4282
Epoch 25, CIFAR-10 Batch 1:  loss 1.849681, train_accuracy 0.35, valid accuracy 0.4168
Epoch 25, CIFAR-10 Batch 2:  loss 1.664115, train_accuracy 0.35, valid accuracy 0.39
Epoch 25, CIFAR-10 Batch 3:  loss 1.486332, train_accuracy 0.5, valid accuracy 0.4314
Epoch 25, CIFAR-10 Batch 4:  loss 1.507466, train_accuracy 0.45, valid accuracy 0.4344
Epoch 25, CIFAR-10 Batch 5:  loss 1.549412, train_accuracy 0.45, valid accuracy 0.3986
Epoch 26, CIFAR-10 Batch 1:  loss 1.529082, train_accuracy 0.425, valid accuracy 0.459
Epoch 26, CIFAR-10 Batch 2:  loss 1.675216, train_accuracy 0.3, valid accuracy 0.3722
Epoch 26, CIFAR-10 Batch 3:  loss 1.445127, train_accuracy 0.475, valid accuracy 0.4428
Epoch 26, CIFAR-10 Batch 4:  loss 1.510837, train_accuracy 0.525, valid accuracy 0.4476
Epoch 26, CIFAR-10 Batch 5:  loss 1.539917, train_accuracy 0.475, valid accuracy 0.4172
Epoch 27, CIFAR-10 Batch 1:  loss 1.842671, train_accuracy 0.35, valid accuracy 0.4212
Epoch 27, CIFAR-10 Batch 2:  loss 1.523134, train_accuracy 0.4, valid accuracy 0.4284
Epoch 27, CIFAR-10 Batch 3:  loss 1.448401, train_accuracy 0.45, valid accuracy 0.448
Epoch 27, CIFAR-10 Batch 4:  loss 1.523332, train_accuracy 0.475, valid accuracy 0.4366
Epoch 27, CIFAR-10 Batch 5:  loss 1.567614, train_accuracy 0.475, valid accuracy 0.4106
Epoch 28, CIFAR-10 Batch 1:  loss 1.599994, train_accuracy 0.4, valid accuracy 0.4684
Epoch 28, CIFAR-10 Batch 2:  loss 1.468679, train_accuracy 0.525, valid accuracy 0.43
Epoch 28, CIFAR-10 Batch 3:  loss 1.463580, train_accuracy 0.5, valid accuracy 0.4222
Epoch 28, CIFAR-10 Batch 4:  loss 1.471771, train_accuracy 0.525, valid accuracy 0.4458
Epoch 28, CIFAR-10 Batch 5:  loss 1.476007, train_accuracy 0.475, valid accuracy 0.4314
Epoch 29, CIFAR-10 Batch 1:  loss 1.498986, train_accuracy 0.475, valid accuracy 0.4804
Epoch 29, CIFAR-10 Batch 2:  loss 1.507118, train_accuracy 0.475, valid accuracy 0.431
Epoch 29, CIFAR-10 Batch 3:  loss 1.313117, train_accuracy 0.575, valid accuracy 0.4928
Epoch 29, CIFAR-10 Batch 4:  loss 1.472046, train_accuracy 0.55, valid accuracy 0.4566
Epoch 29, CIFAR-10 Batch 5:  loss 1.400502, train_accuracy 0.575, valid accuracy 0.4428
Epoch 30, CIFAR-10 Batch 1:  loss 1.525667, train_accuracy 0.4, valid accuracy 0.4634
Epoch 30, CIFAR-10 Batch 2:  loss 1.415250, train_accuracy 0.475, valid accuracy 0.4276
Epoch 30, CIFAR-10 Batch 3:  loss 1.439679, train_accuracy 0.45, valid accuracy 0.4472
Epoch 30, CIFAR-10 Batch 4:  loss 1.322776, train_accuracy 0.55, valid accuracy 0.4994
Epoch 30, CIFAR-10 Batch 5:  loss 1.370803, train_accuracy 0.475, valid accuracy 0.4542
Epoch 31, CIFAR-10 Batch 1:  loss 1.424599, train_accuracy 0.425, valid accuracy 0.4906
Epoch 31, CIFAR-10 Batch 2:  loss 1.349580, train_accuracy 0.425, valid accuracy 0.4816
Epoch 31, CIFAR-10 Batch 3:  loss 1.334344, train_accuracy 0.45, valid accuracy 0.4682
Epoch 31, CIFAR-10 Batch 4:  loss 1.320359, train_accuracy 0.6, valid accuracy 0.4802
Epoch 31, CIFAR-10 Batch 5:  loss 1.289434, train_accuracy 0.525, valid accuracy 0.4752
Epoch 32, CIFAR-10 Batch 1:  loss 1.372583, train_accuracy 0.475, valid accuracy 0.4862
Epoch 32, CIFAR-10 Batch 2:  loss 1.364829, train_accuracy 0.525, valid accuracy 0.4488
Epoch 32, CIFAR-10 Batch 3:  loss 1.377442, train_accuracy 0.475, valid accuracy 0.476
Epoch 32, CIFAR-10 Batch 4:  loss 1.523991, train_accuracy 0.45, valid accuracy 0.4472
Epoch 32, CIFAR-10 Batch 5:  loss 1.479313, train_accuracy 0.525, valid accuracy 0.4532
Epoch 33, CIFAR-10 Batch 1:  loss 1.601253, train_accuracy 0.45, valid accuracy 0.4756
Epoch 33, CIFAR-10 Batch 2:  loss 1.308216, train_accuracy 0.5, valid accuracy 0.5068
Epoch 33, CIFAR-10 Batch 3:  loss 1.262900, train_accuracy 0.525, valid accuracy 0.5202
Epoch 33, CIFAR-10 Batch 4:  loss 1.269783, train_accuracy 0.575, valid accuracy 0.5102
Epoch 33, CIFAR-10 Batch 5:  loss 1.194381, train_accuracy 0.625, valid accuracy 0.5244
Epoch 34, CIFAR-10 Batch 1:  loss 1.342451, train_accuracy 0.425, valid accuracy 0.5058
Epoch 34, CIFAR-10 Batch 2:  loss 1.296099, train_accuracy 0.475, valid accuracy 0.4968
Epoch 34, CIFAR-10 Batch 3:  loss 1.344078, train_accuracy 0.45, valid accuracy 0.486
Epoch 34, CIFAR-10 Batch 4:  loss 1.393783, train_accuracy 0.55, valid accuracy 0.5002
Epoch 34, CIFAR-10 Batch 5:  loss 1.247730, train_accuracy 0.575, valid accuracy 0.5072
Epoch 35, CIFAR-10 Batch 1:  loss 1.181515, train_accuracy 0.575, valid accuracy 0.5528
Epoch 35, CIFAR-10 Batch 2:  loss 1.297121, train_accuracy 0.525, valid accuracy 0.4924
Epoch 35, CIFAR-10 Batch 3:  loss 1.130408, train_accuracy 0.625, valid accuracy 0.5438
Epoch 35, CIFAR-10 Batch 4:  loss 1.220897, train_accuracy 0.6, valid accuracy 0.529
Epoch 35, CIFAR-10 Batch 5:  loss 1.360435, train_accuracy 0.5, valid accuracy 0.458
Epoch 36, CIFAR-10 Batch 1:  loss 1.278018, train_accuracy 0.475, valid accuracy 0.5312
Epoch 36, CIFAR-10 Batch 2:  loss 1.228923, train_accuracy 0.5, valid accuracy 0.518
Epoch 36, CIFAR-10 Batch 3:  loss 1.189265, train_accuracy 0.55, valid accuracy 0.5134
Epoch 36, CIFAR-10 Batch 4:  loss 1.131226, train_accuracy 0.55, valid accuracy 0.5498
Epoch 36, CIFAR-10 Batch 5:  loss 1.147809, train_accuracy 0.6, valid accuracy 0.514
Epoch 37, CIFAR-10 Batch 1:  loss 1.310145, train_accuracy 0.5, valid accuracy 0.5326
Epoch 37, CIFAR-10 Batch 2:  loss 1.228172, train_accuracy 0.5, valid accuracy 0.5278
Epoch 37, CIFAR-10 Batch 3:  loss 1.275494, train_accuracy 0.475, valid accuracy 0.503
Epoch 37, CIFAR-10 Batch 4:  loss 1.109810, train_accuracy 0.65, valid accuracy 0.5366
Epoch 37, CIFAR-10 Batch 5:  loss 1.202451, train_accuracy 0.625, valid accuracy 0.5168
Epoch 38, CIFAR-10 Batch 1:  loss 1.194128, train_accuracy 0.55, valid accuracy 0.554
Epoch 38, CIFAR-10 Batch 2:  loss 1.182513, train_accuracy 0.525, valid accuracy 0.538
Epoch 38, CIFAR-10 Batch 3:  loss 1.091033, train_accuracy 0.6, valid accuracy 0.554
Epoch 38, CIFAR-10 Batch 4:  loss 1.152747, train_accuracy 0.575, valid accuracy 0.5408
Epoch 38, CIFAR-10 Batch 5:  loss 1.076687, train_accuracy 0.6, valid accuracy 0.5486
Epoch 39, CIFAR-10 Batch 1:  loss 1.143540, train_accuracy 0.6, valid accuracy 0.5498
Epoch 39, CIFAR-10 Batch 2:  loss 1.178898, train_accuracy 0.525, valid accuracy 0.557
Epoch 39, CIFAR-10 Batch 3:  loss 1.217030, train_accuracy 0.5, valid accuracy 0.5298
Epoch 39, CIFAR-10 Batch 4:  loss 0.992664, train_accuracy 0.7, valid accuracy 0.5716
Epoch 39, CIFAR-10 Batch 5:  loss 1.162126, train_accuracy 0.6, valid accuracy 0.5086
Epoch 40, CIFAR-10 Batch 1:  loss 1.158829, train_accuracy 0.525, valid accuracy 0.5612
Epoch 40, CIFAR-10 Batch 2:  loss 1.247941, train_accuracy 0.5, valid accuracy 0.5496
Epoch 40, CIFAR-10 Batch 3:  loss 1.158469, train_accuracy 0.5, valid accuracy 0.5356
Epoch 40, CIFAR-10 Batch 4:  loss 0.947233, train_accuracy 0.7, valid accuracy 0.5898
Epoch 40, CIFAR-10 Batch 5:  loss 1.048439, train_accuracy 0.65, valid accuracy 0.544
Epoch 41, CIFAR-10 Batch 1:  loss 1.125670, train_accuracy 0.55, valid accuracy 0.5666
Epoch 41, CIFAR-10 Batch 2:  loss 1.152957, train_accuracy 0.525, valid accuracy 0.5598
Epoch 41, CIFAR-10 Batch 3:  loss 1.080931, train_accuracy 0.55, valid accuracy 0.5768
Epoch 41, CIFAR-10 Batch 4:  loss 1.115965, train_accuracy 0.575, valid accuracy 0.5396
Epoch 41, CIFAR-10 Batch 5:  loss 1.208271, train_accuracy 0.625, valid accuracy 0.5062
Epoch 42, CIFAR-10 Batch 1:  loss 1.086362, train_accuracy 0.6, valid accuracy 0.5828
Epoch 42, CIFAR-10 Batch 2:  loss 1.151170, train_accuracy 0.55, valid accuracy 0.57
Epoch 42, CIFAR-10 Batch 3:  loss 1.032405, train_accuracy 0.525, valid accuracy 0.5818
Epoch 42, CIFAR-10 Batch 4:  loss 1.030534, train_accuracy 0.7, valid accuracy 0.5698
Epoch 42, CIFAR-10 Batch 5:  loss 1.033735, train_accuracy 0.725, valid accuracy 0.5686
Epoch 43, CIFAR-10 Batch 1:  loss 1.121751, train_accuracy 0.575, valid accuracy 0.5722
Epoch 43, CIFAR-10 Batch 2:  loss 1.143200, train_accuracy 0.625, valid accuracy 0.5702
Epoch 43, CIFAR-10 Batch 3:  loss 0.953962, train_accuracy 0.675, valid accuracy 0.585
Epoch 43, CIFAR-10 Batch 4:  loss 0.982509, train_accuracy 0.675, valid accuracy 0.5744
Epoch 43, CIFAR-10 Batch 5:  loss 0.970620, train_accuracy 0.675, valid accuracy 0.559
Epoch 44, CIFAR-10 Batch 1:  loss 1.035159, train_accuracy 0.575, valid accuracy 0.5916
Epoch 44, CIFAR-10 Batch 2:  loss 1.162024, train_accuracy 0.575, valid accuracy 0.5742
Epoch 44, CIFAR-10 Batch 3:  loss 0.970094, train_accuracy 0.575, valid accuracy 0.591
Epoch 44, CIFAR-10 Batch 4:  loss 0.869121, train_accuracy 0.725, valid accuracy 0.5992
Epoch 44, CIFAR-10 Batch 5:  loss 0.927748, train_accuracy 0.775, valid accuracy 0.596
Epoch 45, CIFAR-10 Batch 1:  loss 0.953810, train_accuracy 0.625, valid accuracy 0.6096
Epoch 45, CIFAR-10 Batch 2:  loss 1.177540, train_accuracy 0.55, valid accuracy 0.5814
Epoch 45, CIFAR-10 Batch 3:  loss 1.136366, train_accuracy 0.575, valid accuracy 0.5378
Epoch 45, CIFAR-10 Batch 4:  loss 0.912520, train_accuracy 0.725, valid accuracy 0.5984
Epoch 45, CIFAR-10 Batch 5:  loss 0.933036, train_accuracy 0.775, valid accuracy 0.5786
Epoch 46, CIFAR-10 Batch 1:  loss 0.915990, train_accuracy 0.675, valid accuracy 0.6054
Epoch 46, CIFAR-10 Batch 2:  loss 1.092247, train_accuracy 0.625, valid accuracy 0.569
Epoch 46, CIFAR-10 Batch 3:  loss 1.031745, train_accuracy 0.55, valid accuracy 0.572
Epoch 46, CIFAR-10 Batch 4:  loss 0.880066, train_accuracy 0.775, valid accuracy 0.5838
Epoch 46, CIFAR-10 Batch 5:  loss 0.965285, train_accuracy 0.725, valid accuracy 0.59
Epoch 47, CIFAR-10 Batch 1:  loss 0.946281, train_accuracy 0.675, valid accuracy 0.6122
Epoch 47, CIFAR-10 Batch 2:  loss 0.971507, train_accuracy 0.6, valid accuracy 0.591
Epoch 47, CIFAR-10 Batch 3:  loss 0.836289, train_accuracy 0.65, valid accuracy 0.6318
Epoch 47, CIFAR-10 Batch 4:  loss 0.934505, train_accuracy 0.75, valid accuracy 0.5664
Epoch 47, CIFAR-10 Batch 5:  loss 0.891864, train_accuracy 0.7, valid accuracy 0.5884
Epoch 48, CIFAR-10 Batch 1:  loss 0.839569, train_accuracy 0.675, valid accuracy 0.6278
Epoch 48, CIFAR-10 Batch 2:  loss 1.060783, train_accuracy 0.625, valid accuracy 0.5846
Epoch 48, CIFAR-10 Batch 3:  loss 0.902010, train_accuracy 0.6, valid accuracy 0.6098
Epoch 48, CIFAR-10 Batch 4:  loss 0.791108, train_accuracy 0.775, valid accuracy 0.6268
Epoch 48, CIFAR-10 Batch 5:  loss 0.847665, train_accuracy 0.725, valid accuracy 0.6012
Epoch 49, CIFAR-10 Batch 1:  loss 0.934348, train_accuracy 0.675, valid accuracy 0.617
Epoch 49, CIFAR-10 Batch 2:  loss 0.980735, train_accuracy 0.7, valid accuracy 0.6162
Epoch 49, CIFAR-10 Batch 3:  loss 0.877590, train_accuracy 0.6, valid accuracy 0.6106
Epoch 49, CIFAR-10 Batch 4:  loss 0.662328, train_accuracy 0.875, valid accuracy 0.6424
Epoch 49, CIFAR-10 Batch 5:  loss 0.967010, train_accuracy 0.675, valid accuracy 0.578
Epoch 50, CIFAR-10 Batch 1:  loss 0.821405, train_accuracy 0.675, valid accuracy 0.6466
Epoch 50, CIFAR-10 Batch 2:  loss 0.898624, train_accuracy 0.625, valid accuracy 0.6192
Epoch 50, CIFAR-10 Batch 3:  loss 0.806297, train_accuracy 0.75, valid accuracy 0.6234
Epoch 50, CIFAR-10 Batch 4:  loss 0.693006, train_accuracy 0.825, valid accuracy 0.6578
Epoch 50, CIFAR-10 Batch 5:  loss 0.813661, train_accuracy 0.75, valid accuracy 0.6212
Epoch 51, CIFAR-10 Batch 1:  loss 0.819792, train_accuracy 0.725, valid accuracy 0.6482
Epoch 51, CIFAR-10 Batch 2:  loss 0.861473, train_accuracy 0.725, valid accuracy 0.624
Epoch 51, CIFAR-10 Batch 3:  loss 0.784527, train_accuracy 0.8, valid accuracy 0.616
Epoch 51, CIFAR-10 Batch 4:  loss 0.748757, train_accuracy 0.8, valid accuracy 0.6264
Epoch 51, CIFAR-10 Batch 5:  loss 0.903420, train_accuracy 0.7, valid accuracy 0.5836
Epoch 52, CIFAR-10 Batch 1:  loss 0.724446, train_accuracy 0.725, valid accuracy 0.6496
Epoch 52, CIFAR-10 Batch 2:  loss 0.792611, train_accuracy 0.775, valid accuracy 0.644
Epoch 52, CIFAR-10 Batch 3:  loss 0.808915, train_accuracy 0.675, valid accuracy 0.6266
Epoch 52, CIFAR-10 Batch 4:  loss 0.768101, train_accuracy 0.725, valid accuracy 0.6182
Epoch 52, CIFAR-10 Batch 5:  loss 0.787360, train_accuracy 0.725, valid accuracy 0.5986
Epoch 53, CIFAR-10 Batch 1:  loss 0.744170, train_accuracy 0.675, valid accuracy 0.6502
Epoch 53, CIFAR-10 Batch 2:  loss 0.877120, train_accuracy 0.7, valid accuracy 0.6312
Epoch 53, CIFAR-10 Batch 3:  loss 0.828575, train_accuracy 0.7, valid accuracy 0.6014
Epoch 53, CIFAR-10 Batch 4:  loss 0.741724, train_accuracy 0.775, valid accuracy 0.6136
Epoch 53, CIFAR-10 Batch 5:  loss 0.791263, train_accuracy 0.8, valid accuracy 0.613
Epoch 54, CIFAR-10 Batch 1:  loss 0.758548, train_accuracy 0.725, valid accuracy 0.643
Epoch 54, CIFAR-10 Batch 2:  loss 0.880433, train_accuracy 0.75, valid accuracy 0.6108
Epoch 54, CIFAR-10 Batch 3:  loss 0.693740, train_accuracy 0.8, valid accuracy 0.6236
Epoch 54, CIFAR-10 Batch 4:  loss 0.709744, train_accuracy 0.775, valid accuracy 0.628
Epoch 54, CIFAR-10 Batch 5:  loss 0.695770, train_accuracy 0.8, valid accuracy 0.6346
Epoch 55, CIFAR-10 Batch 1:  loss 0.715957, train_accuracy 0.675, valid accuracy 0.6536
Epoch 55, CIFAR-10 Batch 2:  loss 0.626039, train_accuracy 0.875, valid accuracy 0.6656
Epoch 55, CIFAR-10 Batch 3:  loss 0.744257, train_accuracy 0.725, valid accuracy 0.6456
Epoch 55, CIFAR-10 Batch 4:  loss 0.602788, train_accuracy 0.875, valid accuracy 0.6564
Epoch 55, CIFAR-10 Batch 5:  loss 0.655302, train_accuracy 0.8, valid accuracy 0.6504
Epoch 56, CIFAR-10 Batch 1:  loss 0.722425, train_accuracy 0.775, valid accuracy 0.66
Epoch 56, CIFAR-10 Batch 2:  loss 0.737733, train_accuracy 0.8, valid accuracy 0.6622
Epoch 56, CIFAR-10 Batch 3:  loss 0.765361, train_accuracy 0.75, valid accuracy 0.6284
Epoch 56, CIFAR-10 Batch 4:  loss 0.597862, train_accuracy 0.85, valid accuracy 0.6516
Epoch 56, CIFAR-10 Batch 5:  loss 0.712303, train_accuracy 0.8, valid accuracy 0.632
Epoch 57, CIFAR-10 Batch 1:  loss 0.711807, train_accuracy 0.7, valid accuracy 0.6652
Epoch 57, CIFAR-10 Batch 2:  loss 0.769213, train_accuracy 0.825, valid accuracy 0.6074
Epoch 57, CIFAR-10 Batch 3:  loss 0.658236, train_accuracy 0.775, valid accuracy 0.6466
Epoch 57, CIFAR-10 Batch 4:  loss 0.629447, train_accuracy 0.875, valid accuracy 0.6324
Epoch 57, CIFAR-10 Batch 5:  loss 0.616860, train_accuracy 0.8, valid accuracy 0.6442
Epoch 58, CIFAR-10 Batch 1:  loss 0.604290, train_accuracy 0.75, valid accuracy 0.6762
Epoch 58, CIFAR-10 Batch 2:  loss 0.641316, train_accuracy 0.825, valid accuracy 0.658
Epoch 58, CIFAR-10 Batch 3:  loss 0.684759, train_accuracy 0.75, valid accuracy 0.634
Epoch 58, CIFAR-10 Batch 4:  loss 0.631951, train_accuracy 0.825, valid accuracy 0.6372
Epoch 58, CIFAR-10 Batch 5:  loss 0.591599, train_accuracy 0.875, valid accuracy 0.6626
Epoch 59, CIFAR-10 Batch 1:  loss 0.645560, train_accuracy 0.75, valid accuracy 0.675
Epoch 59, CIFAR-10 Batch 2:  loss 0.634261, train_accuracy 0.825, valid accuracy 0.6468
Epoch 59, CIFAR-10 Batch 3:  loss 0.664659, train_accuracy 0.8, valid accuracy 0.6446
Epoch 59, CIFAR-10 Batch 4:  loss 0.537345, train_accuracy 0.85, valid accuracy 0.6682
Epoch 59, CIFAR-10 Batch 5:  loss 0.646416, train_accuracy 0.825, valid accuracy 0.6552
Epoch 60, CIFAR-10 Batch 1:  loss 0.597867, train_accuracy 0.825, valid accuracy 0.6788
Epoch 60, CIFAR-10 Batch 2:  loss 0.653040, train_accuracy 0.775, valid accuracy 0.6522
Epoch 60, CIFAR-10 Batch 3:  loss 0.621518, train_accuracy 0.9, valid accuracy 0.6546
Epoch 60, CIFAR-10 Batch 4:  loss 0.522278, train_accuracy 0.85, valid accuracy 0.6656
Epoch 60, CIFAR-10 Batch 5:  loss 0.574840, train_accuracy 0.875, valid accuracy 0.6578
Epoch 61, CIFAR-10 Batch 1:  loss 0.684382, train_accuracy 0.75, valid accuracy 0.6618
Epoch 61, CIFAR-10 Batch 2:  loss 0.575198, train_accuracy 0.875, valid accuracy 0.6832
Epoch 61, CIFAR-10 Batch 3:  loss 0.520367, train_accuracy 0.875, valid accuracy 0.6842
Epoch 61, CIFAR-10 Batch 4:  loss 0.483688, train_accuracy 0.925, valid accuracy 0.6848
Epoch 61, CIFAR-10 Batch 5:  loss 0.596578, train_accuracy 0.85, valid accuracy 0.6586
Epoch 62, CIFAR-10 Batch 1:  loss 0.553290, train_accuracy 0.8, valid accuracy 0.698
Epoch 62, CIFAR-10 Batch 2:  loss 0.519195, train_accuracy 0.9, valid accuracy 0.6812
Epoch 62, CIFAR-10 Batch 3:  loss 0.510083, train_accuracy 0.875, valid accuracy 0.6736
Epoch 62, CIFAR-10 Batch 4:  loss 0.492281, train_accuracy 0.875, valid accuracy 0.6812
Epoch 62, CIFAR-10 Batch 5:  loss 0.578490, train_accuracy 0.825, valid accuracy 0.6664
Epoch 63, CIFAR-10 Batch 1:  loss 0.556583, train_accuracy 0.8, valid accuracy 0.6938
Epoch 63, CIFAR-10 Batch 2:  loss 0.530466, train_accuracy 0.85, valid accuracy 0.6786
Epoch 63, CIFAR-10 Batch 3:  loss 0.505612, train_accuracy 0.9, valid accuracy 0.678
Epoch 63, CIFAR-10 Batch 4:  loss 0.522833, train_accuracy 0.875, valid accuracy 0.6536
Epoch 63, CIFAR-10 Batch 5:  loss 0.545556, train_accuracy 0.85, valid accuracy 0.6624
Epoch 64, CIFAR-10 Batch 1:  loss 0.556303, train_accuracy 0.775, valid accuracy 0.699
Epoch 64, CIFAR-10 Batch 2:  loss 0.493317, train_accuracy 0.9, valid accuracy 0.6862
Epoch 64, CIFAR-10 Batch 3:  loss 0.573200, train_accuracy 0.9, valid accuracy 0.686
Epoch 64, CIFAR-10 Batch 4:  loss 0.482270, train_accuracy 0.825, valid accuracy 0.6734
Epoch 64, CIFAR-10 Batch 5:  loss 0.529360, train_accuracy 0.875, valid accuracy 0.665
Epoch 65, CIFAR-10 Batch 1:  loss 0.503995, train_accuracy 0.875, valid accuracy 0.708
Epoch 65, CIFAR-10 Batch 2:  loss 0.555663, train_accuracy 0.85, valid accuracy 0.6796
Epoch 65, CIFAR-10 Batch 3:  loss 0.535766, train_accuracy 0.9, valid accuracy 0.6862
Epoch 65, CIFAR-10 Batch 4:  loss 0.442237, train_accuracy 0.9, valid accuracy 0.6778
Epoch 65, CIFAR-10 Batch 5:  loss 0.581082, train_accuracy 0.85, valid accuracy 0.672
Epoch 66, CIFAR-10 Batch 1:  loss 0.485018, train_accuracy 0.875, valid accuracy 0.7076
Epoch 66, CIFAR-10 Batch 2:  loss 0.490134, train_accuracy 0.9, valid accuracy 0.6894
Epoch 66, CIFAR-10 Batch 3:  loss 0.552040, train_accuracy 0.875, valid accuracy 0.666
Epoch 66, CIFAR-10 Batch 4:  loss 0.403948, train_accuracy 0.95, valid accuracy 0.6828
Epoch 66, CIFAR-10 Batch 5:  loss 0.494317, train_accuracy 0.875, valid accuracy 0.678
Epoch 67, CIFAR-10 Batch 1:  loss 0.464382, train_accuracy 0.875, valid accuracy 0.7038
Epoch 67, CIFAR-10 Batch 2:  loss 0.505741, train_accuracy 0.85, valid accuracy 0.6744
Epoch 67, CIFAR-10 Batch 3:  loss 0.512518, train_accuracy 0.9, valid accuracy 0.6776
Epoch 67, CIFAR-10 Batch 4:  loss 0.430421, train_accuracy 0.925, valid accuracy 0.6924
Epoch 67, CIFAR-10 Batch 5:  loss 0.488371, train_accuracy 0.875, valid accuracy 0.6882
Epoch 68, CIFAR-10 Batch 1:  loss 0.453979, train_accuracy 0.9, valid accuracy 0.7086
Epoch 68, CIFAR-10 Batch 2:  loss 0.437693, train_accuracy 0.9, valid accuracy 0.6994
Epoch 68, CIFAR-10 Batch 3:  loss 0.457800, train_accuracy 0.925, valid accuracy 0.7114
Epoch 68, CIFAR-10 Batch 4:  loss 0.444153, train_accuracy 0.9, valid accuracy 0.6948
Epoch 68, CIFAR-10 Batch 5:  loss 0.445373, train_accuracy 0.95, valid accuracy 0.7052
Epoch 69, CIFAR-10 Batch 1:  loss 0.528806, train_accuracy 0.85, valid accuracy 0.7126
Epoch 69, CIFAR-10 Batch 2:  loss 0.404905, train_accuracy 0.95, valid accuracy 0.695
Epoch 69, CIFAR-10 Batch 3:  loss 0.459547, train_accuracy 0.95, valid accuracy 0.7044
Epoch 69, CIFAR-10 Batch 4:  loss 0.482656, train_accuracy 0.875, valid accuracy 0.692
Epoch 69, CIFAR-10 Batch 5:  loss 0.396591, train_accuracy 0.925, valid accuracy 0.6974
Epoch 70, CIFAR-10 Batch 1:  loss 0.485558, train_accuracy 0.9, valid accuracy 0.7062
Epoch 70, CIFAR-10 Batch 2:  loss 0.418883, train_accuracy 0.975, valid accuracy 0.702
Epoch 70, CIFAR-10 Batch 3:  loss 0.463238, train_accuracy 0.875, valid accuracy 0.6684
Epoch 70, CIFAR-10 Batch 4:  loss 0.365099, train_accuracy 0.95, valid accuracy 0.7042
Epoch 70, CIFAR-10 Batch 5:  loss 0.431817, train_accuracy 0.85, valid accuracy 0.687
Epoch 71, CIFAR-10 Batch 1:  loss 0.445296, train_accuracy 0.9, valid accuracy 0.7066
Epoch 71, CIFAR-10 Batch 2:  loss 0.451146, train_accuracy 0.9, valid accuracy 0.6858
Epoch 71, CIFAR-10 Batch 3:  loss 0.433473, train_accuracy 0.9, valid accuracy 0.7064
Epoch 71, CIFAR-10 Batch 4:  loss 0.384506, train_accuracy 0.9, valid accuracy 0.6918
Epoch 71, CIFAR-10 Batch 5:  loss 0.387208, train_accuracy 0.875, valid accuracy 0.709
Epoch 72, CIFAR-10 Batch 1:  loss 0.593620, train_accuracy 0.85, valid accuracy 0.692
Epoch 72, CIFAR-10 Batch 2:  loss 0.419875, train_accuracy 0.9, valid accuracy 0.696
Epoch 72, CIFAR-10 Batch 3:  loss 0.428347, train_accuracy 0.975, valid accuracy 0.6886
Epoch 72, CIFAR-10 Batch 4:  loss 0.349258, train_accuracy 0.95, valid accuracy 0.7098
Epoch 72, CIFAR-10 Batch 5:  loss 0.361295, train_accuracy 0.925, valid accuracy 0.6992
Epoch 73, CIFAR-10 Batch 1:  loss 0.444569, train_accuracy 0.95, valid accuracy 0.7226
Epoch 73, CIFAR-10 Batch 2:  loss 0.348188, train_accuracy 0.975, valid accuracy 0.7072
Epoch 73, CIFAR-10 Batch 3:  loss 0.424960, train_accuracy 0.95, valid accuracy 0.6796
Epoch 73, CIFAR-10 Batch 4:  loss 0.409780, train_accuracy 0.9, valid accuracy 0.6938
Epoch 73, CIFAR-10 Batch 5:  loss 0.452432, train_accuracy 0.875, valid accuracy 0.684
Epoch 74, CIFAR-10 Batch 1:  loss 0.396286, train_accuracy 0.95, valid accuracy 0.7256
Epoch 74, CIFAR-10 Batch 2:  loss 0.408701, train_accuracy 0.95, valid accuracy 0.7036
Epoch 74, CIFAR-10 Batch 3:  loss 0.415674, train_accuracy 0.95, valid accuracy 0.698
Epoch 74, CIFAR-10 Batch 4:  loss 0.328526, train_accuracy 0.9, valid accuracy 0.6906
Epoch 74, CIFAR-10 Batch 5:  loss 0.373147, train_accuracy 0.9, valid accuracy 0.7108
Epoch 75, CIFAR-10 Batch 1:  loss 0.381045, train_accuracy 0.975, valid accuracy 0.735
Epoch 75, CIFAR-10 Batch 2:  loss 0.378748, train_accuracy 0.925, valid accuracy 0.6946
Epoch 75, CIFAR-10 Batch 3:  loss 0.415470, train_accuracy 0.95, valid accuracy 0.6948
Epoch 75, CIFAR-10 Batch 4:  loss 0.297050, train_accuracy 0.95, valid accuracy 0.721
Epoch 75, CIFAR-10 Batch 5:  loss 0.405161, train_accuracy 0.95, valid accuracy 0.697
Epoch 76, CIFAR-10 Batch 1:  loss 0.437699, train_accuracy 0.925, valid accuracy 0.7218
Epoch 76, CIFAR-10 Batch 2:  loss 0.333497, train_accuracy 0.95, valid accuracy 0.715
Epoch 76, CIFAR-10 Batch 3:  loss 0.401009, train_accuracy 0.975, valid accuracy 0.7006
Epoch 76, CIFAR-10 Batch 4:  loss 0.326549, train_accuracy 0.925, valid accuracy 0.7086
Epoch 76, CIFAR-10 Batch 5:  loss 0.325145, train_accuracy 0.975, valid accuracy 0.7216
Epoch 77, CIFAR-10 Batch 1:  loss 0.438713, train_accuracy 0.9, valid accuracy 0.7098
Epoch 77, CIFAR-10 Batch 2:  loss 0.353128, train_accuracy 0.95, valid accuracy 0.7086
Epoch 77, CIFAR-10 Batch 3:  loss 0.343943, train_accuracy 0.95, valid accuracy 0.7032
Epoch 77, CIFAR-10 Batch 4:  loss 0.349678, train_accuracy 0.925, valid accuracy 0.7022
Epoch 77, CIFAR-10 Batch 5:  loss 0.268707, train_accuracy 1, valid accuracy 0.7222
Epoch 78, CIFAR-10 Batch 1:  loss 0.389804, train_accuracy 0.9, valid accuracy 0.7198
Epoch 78, CIFAR-10 Batch 2:  loss 0.315393, train_accuracy 0.975, valid accuracy 0.7166
Epoch 78, CIFAR-10 Batch 3:  loss 0.331260, train_accuracy 0.95, valid accuracy 0.7106
Epoch 78, CIFAR-10 Batch 4:  loss 0.326001, train_accuracy 0.925, valid accuracy 0.7036
Epoch 78, CIFAR-10 Batch 5:  loss 0.273141, train_accuracy 0.975, valid accuracy 0.7074
Epoch 79, CIFAR-10 Batch 1:  loss 0.388199, train_accuracy 0.925, valid accuracy 0.7186
Epoch 79, CIFAR-10 Batch 2:  loss 0.319482, train_accuracy 0.975, valid accuracy 0.7142
Epoch 79, CIFAR-10 Batch 3:  loss 0.301571, train_accuracy 0.95, valid accuracy 0.7274
Epoch 79, CIFAR-10 Batch 4:  loss 0.266620, train_accuracy 0.975, valid accuracy 0.7274
Epoch 79, CIFAR-10 Batch 5:  loss 0.303517, train_accuracy 0.95, valid accuracy 0.711
Epoch 80, CIFAR-10 Batch 1:  loss 0.343106, train_accuracy 0.975, valid accuracy 0.743
Epoch 80, CIFAR-10 Batch 2:  loss 0.317904, train_accuracy 0.975, valid accuracy 0.7138
Epoch 80, CIFAR-10 Batch 3:  loss 0.286390, train_accuracy 0.95, valid accuracy 0.7064
Epoch 80, CIFAR-10 Batch 4:  loss 0.257363, train_accuracy 0.95, valid accuracy 0.7252
Epoch 80, CIFAR-10 Batch 5:  loss 0.288184, train_accuracy 0.975, valid accuracy 0.7114
Epoch 81, CIFAR-10 Batch 1:  loss 0.362915, train_accuracy 0.95, valid accuracy 0.735
Epoch 81, CIFAR-10 Batch 2:  loss 0.312612, train_accuracy 0.975, valid accuracy 0.7216
Epoch 81, CIFAR-10 Batch 3:  loss 0.361740, train_accuracy 0.95, valid accuracy 0.6998
Epoch 81, CIFAR-10 Batch 4:  loss 0.270288, train_accuracy 0.95, valid accuracy 0.7238
Epoch 81, CIFAR-10 Batch 5:  loss 0.242587, train_accuracy 1, valid accuracy 0.7298
Epoch 82, CIFAR-10 Batch 1:  loss 0.304943, train_accuracy 0.95, valid accuracy 0.7492
Epoch 82, CIFAR-10 Batch 2:  loss 0.290070, train_accuracy 0.975, valid accuracy 0.729
Epoch 82, CIFAR-10 Batch 3:  loss 0.307349, train_accuracy 0.975, valid accuracy 0.7162
Epoch 82, CIFAR-10 Batch 4:  loss 0.263745, train_accuracy 0.95, valid accuracy 0.7422
Epoch 82, CIFAR-10 Batch 5:  loss 0.314377, train_accuracy 0.95, valid accuracy 0.7138
Epoch 83, CIFAR-10 Batch 1:  loss 0.355767, train_accuracy 0.95, valid accuracy 0.713
Epoch 83, CIFAR-10 Batch 2:  loss 0.282227, train_accuracy 0.975, valid accuracy 0.723
Epoch 83, CIFAR-10 Batch 3:  loss 0.256077, train_accuracy 0.95, valid accuracy 0.7204
Epoch 83, CIFAR-10 Batch 4:  loss 0.244001, train_accuracy 0.975, valid accuracy 0.7402
Epoch 83, CIFAR-10 Batch 5:  loss 0.262094, train_accuracy 0.95, valid accuracy 0.7286
Epoch 84, CIFAR-10 Batch 1:  loss 0.313435, train_accuracy 0.95, valid accuracy 0.7454
Epoch 84, CIFAR-10 Batch 2:  loss 0.349619, train_accuracy 0.925, valid accuracy 0.7084
Epoch 84, CIFAR-10 Batch 3:  loss 0.262030, train_accuracy 0.975, valid accuracy 0.7196
Epoch 84, CIFAR-10 Batch 4:  loss 0.262100, train_accuracy 0.925, valid accuracy 0.728
Epoch 84, CIFAR-10 Batch 5:  loss 0.287046, train_accuracy 0.975, valid accuracy 0.7152
Epoch 85, CIFAR-10 Batch 1:  loss 0.299888, train_accuracy 0.95, valid accuracy 0.7456
Epoch 85, CIFAR-10 Batch 2:  loss 0.287766, train_accuracy 0.975, valid accuracy 0.7308
Epoch 85, CIFAR-10 Batch 3:  loss 0.275444, train_accuracy 1, valid accuracy 0.716
Epoch 85, CIFAR-10 Batch 4:  loss 0.270724, train_accuracy 0.925, valid accuracy 0.7246
Epoch 85, CIFAR-10 Batch 5:  loss 0.221934, train_accuracy 1, valid accuracy 0.7346
Epoch 86, CIFAR-10 Batch 1:  loss 0.324443, train_accuracy 0.9, valid accuracy 0.7392
Epoch 86, CIFAR-10 Batch 2:  loss 0.241802, train_accuracy 0.975, valid accuracy 0.7328
Epoch 86, CIFAR-10 Batch 3:  loss 0.390288, train_accuracy 0.925, valid accuracy 0.6768
Epoch 86, CIFAR-10 Batch 4:  loss 0.220279, train_accuracy 0.95, valid accuracy 0.7382
Epoch 86, CIFAR-10 Batch 5:  loss 0.210745, train_accuracy 1, valid accuracy 0.738
Epoch 87, CIFAR-10 Batch 1:  loss 0.297152, train_accuracy 0.95, valid accuracy 0.7468
Epoch 87, CIFAR-10 Batch 2:  loss 0.262388, train_accuracy 0.975, valid accuracy 0.7188
Epoch 87, CIFAR-10 Batch 3:  loss 0.266239, train_accuracy 0.975, valid accuracy 0.7214
Epoch 87, CIFAR-10 Batch 4:  loss 0.206904, train_accuracy 0.975, valid accuracy 0.7314
Epoch 87, CIFAR-10 Batch 5:  loss 0.247299, train_accuracy 1, valid accuracy 0.7114
Epoch 88, CIFAR-10 Batch 1:  loss 0.310059, train_accuracy 0.95, valid accuracy 0.7484
Epoch 88, CIFAR-10 Batch 2:  loss 0.285476, train_accuracy 0.95, valid accuracy 0.7214
Epoch 88, CIFAR-10 Batch 3:  loss 0.244184, train_accuracy 0.975, valid accuracy 0.7052
Epoch 88, CIFAR-10 Batch 4:  loss 0.205253, train_accuracy 0.975, valid accuracy 0.7384
Epoch 88, CIFAR-10 Batch 5:  loss 0.231289, train_accuracy 1, valid accuracy 0.7294
Epoch 89, CIFAR-10 Batch 1:  loss 0.280811, train_accuracy 0.925, valid accuracy 0.7526
Epoch 89, CIFAR-10 Batch 2:  loss 0.268638, train_accuracy 0.95, valid accuracy 0.7308
Epoch 89, CIFAR-10 Batch 3:  loss 0.252547, train_accuracy 0.95, valid accuracy 0.7326
Epoch 89, CIFAR-10 Batch 4:  loss 0.218241, train_accuracy 0.95, valid accuracy 0.7206
Epoch 89, CIFAR-10 Batch 5:  loss 0.330778, train_accuracy 0.975, valid accuracy 0.6786
Epoch 90, CIFAR-10 Batch 1:  loss 0.283055, train_accuracy 0.975, valid accuracy 0.7446
Epoch 90, CIFAR-10 Batch 2:  loss 0.294140, train_accuracy 0.975, valid accuracy 0.7316
Epoch 90, CIFAR-10 Batch 3:  loss 0.209385, train_accuracy 0.975, valid accuracy 0.726
Epoch 90, CIFAR-10 Batch 4:  loss 0.221696, train_accuracy 0.95, valid accuracy 0.736
Epoch 90, CIFAR-10 Batch 5:  loss 0.251832, train_accuracy 1, valid accuracy 0.7144
Epoch 91, CIFAR-10 Batch 1:  loss 0.278032, train_accuracy 0.975, valid accuracy 0.746
Epoch 91, CIFAR-10 Batch 2:  loss 0.203122, train_accuracy 1, valid accuracy 0.7532
Epoch 91, CIFAR-10 Batch 3:  loss 0.260541, train_accuracy 0.975, valid accuracy 0.6934
Epoch 91, CIFAR-10 Batch 4:  loss 0.209139, train_accuracy 0.975, valid accuracy 0.736
Epoch 91, CIFAR-10 Batch 5:  loss 0.189152, train_accuracy 1, valid accuracy 0.7294
Epoch 92, CIFAR-10 Batch 1:  loss 0.235726, train_accuracy 0.975, valid accuracy 0.7628
Epoch 92, CIFAR-10 Batch 2:  loss 0.215720, train_accuracy 1, valid accuracy 0.7358
Epoch 92, CIFAR-10 Batch 3:  loss 0.251879, train_accuracy 0.975, valid accuracy 0.703
Epoch 92, CIFAR-10 Batch 4:  loss 0.168907, train_accuracy 0.95, valid accuracy 0.7574
Epoch 92, CIFAR-10 Batch 5:  loss 0.195817, train_accuracy 0.975, valid accuracy 0.7314
Epoch 93, CIFAR-10 Batch 1:  loss 0.272657, train_accuracy 0.975, valid accuracy 0.7556
Epoch 93, CIFAR-10 Batch 2:  loss 0.202095, train_accuracy 0.975, valid accuracy 0.7556
Epoch 93, CIFAR-10 Batch 3:  loss 0.220301, train_accuracy 1, valid accuracy 0.7368
Epoch 93, CIFAR-10 Batch 4:  loss 0.196345, train_accuracy 0.95, valid accuracy 0.744
Epoch 93, CIFAR-10 Batch 5:  loss 0.187791, train_accuracy 1, valid accuracy 0.7322
Epoch 94, CIFAR-10 Batch 1:  loss 0.235554, train_accuracy 0.95, valid accuracy 0.7582
Epoch 94, CIFAR-10 Batch 2:  loss 0.205702, train_accuracy 0.975, valid accuracy 0.7362
Epoch 94, CIFAR-10 Batch 3:  loss 0.211005, train_accuracy 0.975, valid accuracy 0.715
Epoch 94, CIFAR-10 Batch 4:  loss 0.209714, train_accuracy 0.95, valid accuracy 0.7498
Epoch 94, CIFAR-10 Batch 5:  loss 0.188027, train_accuracy 1, valid accuracy 0.7348
Epoch 95, CIFAR-10 Batch 1:  loss 0.291226, train_accuracy 0.925, valid accuracy 0.738
Epoch 95, CIFAR-10 Batch 2:  loss 0.193775, train_accuracy 1, valid accuracy 0.7364
Epoch 95, CIFAR-10 Batch 3:  loss 0.218080, train_accuracy 1, valid accuracy 0.7116
Epoch 95, CIFAR-10 Batch 4:  loss 0.180257, train_accuracy 0.95, valid accuracy 0.7406
Epoch 95, CIFAR-10 Batch 5:  loss 0.173394, train_accuracy 1, valid accuracy 0.7354
Epoch 96, CIFAR-10 Batch 1:  loss 0.246748, train_accuracy 0.975, valid accuracy 0.7618
Epoch 96, CIFAR-10 Batch 2:  loss 0.187309, train_accuracy 0.975, valid accuracy 0.7356
Epoch 96, CIFAR-10 Batch 3:  loss 0.164537, train_accuracy 1, valid accuracy 0.7498
Epoch 96, CIFAR-10 Batch 4:  loss 0.220719, train_accuracy 0.95, valid accuracy 0.733
Epoch 96, CIFAR-10 Batch 5:  loss 0.158058, train_accuracy 1, valid accuracy 0.7576
Epoch 97, CIFAR-10 Batch 1:  loss 0.234221, train_accuracy 0.975, valid accuracy 0.7538
Epoch 97, CIFAR-10 Batch 2:  loss 0.210890, train_accuracy 0.975, valid accuracy 0.7484
Epoch 97, CIFAR-10 Batch 3:  loss 0.171037, train_accuracy 1, valid accuracy 0.7376
Epoch 97, CIFAR-10 Batch 4:  loss 0.210297, train_accuracy 0.975, valid accuracy 0.7412
Epoch 97, CIFAR-10 Batch 5:  loss 0.174516, train_accuracy 1, valid accuracy 0.7374
Epoch 98, CIFAR-10 Batch 1:  loss 0.215604, train_accuracy 0.95, valid accuracy 0.7512
Epoch 98, CIFAR-10 Batch 2:  loss 0.207287, train_accuracy 1, valid accuracy 0.7496
Epoch 98, CIFAR-10 Batch 3:  loss 0.177129, train_accuracy 1, valid accuracy 0.7286
Epoch 98, CIFAR-10 Batch 4:  loss 0.167291, train_accuracy 0.95, valid accuracy 0.7534
Epoch 98, CIFAR-10 Batch 5:  loss 0.190549, train_accuracy 0.975, valid accuracy 0.7184
Epoch 99, CIFAR-10 Batch 1:  loss 0.221690, train_accuracy 0.975, valid accuracy 0.7456
Epoch 99, CIFAR-10 Batch 2:  loss 0.182064, train_accuracy 1, valid accuracy 0.7498
Epoch 99, CIFAR-10 Batch 3:  loss 0.179396, train_accuracy 0.975, valid accuracy 0.729
Epoch 99, CIFAR-10 Batch 4:  loss 0.207154, train_accuracy 0.95, valid accuracy 0.7496
Epoch 99, CIFAR-10 Batch 5:  loss 0.117632, train_accuracy 1, valid accuracy 0.7648
Epoch 100, CIFAR-10 Batch 1:  loss 0.188507, train_accuracy 1, valid accuracy 0.7592
Epoch 100, CIFAR-10 Batch 2:  loss 0.207158, train_accuracy 1, valid accuracy 0.7374
Epoch 100, CIFAR-10 Batch 3:  loss 0.176509, train_accuracy 0.975, valid accuracy 0.7412
Epoch 100, CIFAR-10 Batch 4:  loss 0.150519, train_accuracy 0.975, valid accuracy 0.765
Epoch 100, CIFAR-10 Batch 5:  loss 0.165463, train_accuracy 1, valid accuracy 0.73
Epoch 101, CIFAR-10 Batch 1:  loss 0.200974, train_accuracy 0.975, valid accuracy 0.7578
Epoch 101, CIFAR-10 Batch 2:  loss 0.175899, train_accuracy 1, valid accuracy 0.7252
Epoch 101, CIFAR-10 Batch 3:  loss 0.168425, train_accuracy 0.975, valid accuracy 0.7282
Epoch 101, CIFAR-10 Batch 4:  loss 0.164477, train_accuracy 0.95, valid accuracy 0.757
Epoch 101, CIFAR-10 Batch 5:  loss 0.153765, train_accuracy 1, valid accuracy 0.7384
Epoch 102, CIFAR-10 Batch 1:  loss 0.182251, train_accuracy 1, valid accuracy 0.761
Epoch 102, CIFAR-10 Batch 2:  loss 0.173281, train_accuracy 1, valid accuracy 0.7344
Epoch 102, CIFAR-10 Batch 3:  loss 0.158348, train_accuracy 0.975, valid accuracy 0.7332
Epoch 102, CIFAR-10 Batch 4:  loss 0.177006, train_accuracy 0.95, valid accuracy 0.7422
Epoch 102, CIFAR-10 Batch 5:  loss 0.142608, train_accuracy 1, valid accuracy 0.7424
Epoch 103, CIFAR-10 Batch 1:  loss 0.189819, train_accuracy 1, valid accuracy 0.7594
Epoch 103, CIFAR-10 Batch 2:  loss 0.163389, train_accuracy 1, valid accuracy 0.7492
Epoch 103, CIFAR-10 Batch 3:  loss 0.200847, train_accuracy 0.95, valid accuracy 0.7356
Epoch 103, CIFAR-10 Batch 4:  loss 0.150733, train_accuracy 1, valid accuracy 0.758
Epoch 103, CIFAR-10 Batch 5:  loss 0.136260, train_accuracy 1, valid accuracy 0.7434
Epoch 104, CIFAR-10 Batch 1:  loss 0.214737, train_accuracy 1, valid accuracy 0.7548
Epoch 104, CIFAR-10 Batch 2:  loss 0.163329, train_accuracy 0.975, valid accuracy 0.7414
Epoch 104, CIFAR-10 Batch 3:  loss 0.186494, train_accuracy 1, valid accuracy 0.7444
Epoch 104, CIFAR-10 Batch 4:  loss 0.144177, train_accuracy 0.975, valid accuracy 0.751
Epoch 104, CIFAR-10 Batch 5:  loss 0.181900, train_accuracy 1, valid accuracy 0.732
Epoch 105, CIFAR-10 Batch 1:  loss 0.170262, train_accuracy 1, valid accuracy 0.7668
Epoch 105, CIFAR-10 Batch 2:  loss 0.180172, train_accuracy 1, valid accuracy 0.7502
Epoch 105, CIFAR-10 Batch 3:  loss 0.156582, train_accuracy 1, valid accuracy 0.738
Epoch 105, CIFAR-10 Batch 4:  loss 0.175381, train_accuracy 0.975, valid accuracy 0.7552
Epoch 105, CIFAR-10 Batch 5:  loss 0.112746, train_accuracy 1, valid accuracy 0.7514
Epoch 106, CIFAR-10 Batch 1:  loss 0.178845, train_accuracy 1, valid accuracy 0.754
Epoch 106, CIFAR-10 Batch 2:  loss 0.185258, train_accuracy 0.975, valid accuracy 0.7386
Epoch 106, CIFAR-10 Batch 3:  loss 0.149840, train_accuracy 1, valid accuracy 0.7488
Epoch 106, CIFAR-10 Batch 4:  loss 0.147479, train_accuracy 1, valid accuracy 0.76
Epoch 106, CIFAR-10 Batch 5:  loss 0.146041, train_accuracy 1, valid accuracy 0.752
Epoch 107, CIFAR-10 Batch 1:  loss 0.145794, train_accuracy 1, valid accuracy 0.7632
Epoch 107, CIFAR-10 Batch 2:  loss 0.155446, train_accuracy 1, valid accuracy 0.7356
Epoch 107, CIFAR-10 Batch 3:  loss 0.173740, train_accuracy 0.975, valid accuracy 0.737
Epoch 107, CIFAR-10 Batch 4:  loss 0.157232, train_accuracy 0.95, valid accuracy 0.7574
Epoch 107, CIFAR-10 Batch 5:  loss 0.103955, train_accuracy 1, valid accuracy 0.7432
Epoch 108, CIFAR-10 Batch 1:  loss 0.149351, train_accuracy 1, valid accuracy 0.7672
Epoch 108, CIFAR-10 Batch 2:  loss 0.141181, train_accuracy 1, valid accuracy 0.746
Epoch 108, CIFAR-10 Batch 3:  loss 0.128715, train_accuracy 1, valid accuracy 0.7554
Epoch 108, CIFAR-10 Batch 4:  loss 0.189682, train_accuracy 1, valid accuracy 0.7462
Epoch 108, CIFAR-10 Batch 5:  loss 0.107694, train_accuracy 1, valid accuracy 0.7492
Epoch 109, CIFAR-10 Batch 1:  loss 0.152399, train_accuracy 1, valid accuracy 0.7688
Epoch 109, CIFAR-10 Batch 2:  loss 0.106702, train_accuracy 1, valid accuracy 0.762
Epoch 109, CIFAR-10 Batch 3:  loss 0.146071, train_accuracy 1, valid accuracy 0.7634
Epoch 109, CIFAR-10 Batch 4:  loss 0.142716, train_accuracy 1, valid accuracy 0.7644
Epoch 109, CIFAR-10 Batch 5:  loss 0.115409, train_accuracy 1, valid accuracy 0.7468
Epoch 110, CIFAR-10 Batch 1:  loss 0.169844, train_accuracy 1, valid accuracy 0.7616
Epoch 110, CIFAR-10 Batch 2:  loss 0.142787, train_accuracy 1, valid accuracy 0.738
Epoch 110, CIFAR-10 Batch 3:  loss 0.147212, train_accuracy 0.975, valid accuracy 0.7684
Epoch 110, CIFAR-10 Batch 4:  loss 0.137188, train_accuracy 0.975, valid accuracy 0.7646
Epoch 110, CIFAR-10 Batch 5:  loss 0.096221, train_accuracy 1, valid accuracy 0.7542
Epoch 111, CIFAR-10 Batch 1:  loss 0.153003, train_accuracy 1, valid accuracy 0.7694
Epoch 111, CIFAR-10 Batch 2:  loss 0.149669, train_accuracy 1, valid accuracy 0.7404
Epoch 111, CIFAR-10 Batch 3:  loss 0.151975, train_accuracy 1, valid accuracy 0.7432
Epoch 111, CIFAR-10 Batch 4:  loss 0.126635, train_accuracy 1, valid accuracy 0.7614
Epoch 111, CIFAR-10 Batch 5:  loss 0.086850, train_accuracy 1, valid accuracy 0.7638
Epoch 112, CIFAR-10 Batch 1:  loss 0.127230, train_accuracy 1, valid accuracy 0.7708
Epoch 112, CIFAR-10 Batch 2:  loss 0.108316, train_accuracy 1, valid accuracy 0.7472
Epoch 112, CIFAR-10 Batch 3:  loss 0.134257, train_accuracy 1, valid accuracy 0.7526
Epoch 112, CIFAR-10 Batch 4:  loss 0.151566, train_accuracy 0.95, valid accuracy 0.7646
Epoch 112, CIFAR-10 Batch 5:  loss 0.087767, train_accuracy 1, valid accuracy 0.76
Epoch 113, CIFAR-10 Batch 1:  loss 0.114350, train_accuracy 1, valid accuracy 0.7602
Epoch 113, CIFAR-10 Batch 2:  loss 0.113712, train_accuracy 1, valid accuracy 0.7388
Epoch 113, CIFAR-10 Batch 3:  loss 0.146909, train_accuracy 1, valid accuracy 0.7448
Epoch 113, CIFAR-10 Batch 4:  loss 0.178822, train_accuracy 0.975, valid accuracy 0.7596
Epoch 113, CIFAR-10 Batch 5:  loss 0.106407, train_accuracy 1, valid accuracy 0.7472
Epoch 114, CIFAR-10 Batch 1:  loss 0.173264, train_accuracy 1, valid accuracy 0.7628
Epoch 114, CIFAR-10 Batch 2:  loss 0.124487, train_accuracy 1, valid accuracy 0.7508
Epoch 114, CIFAR-10 Batch 3:  loss 0.135689, train_accuracy 1, valid accuracy 0.7428
Epoch 114, CIFAR-10 Batch 4:  loss 0.144941, train_accuracy 1, valid accuracy 0.7588
Epoch 114, CIFAR-10 Batch 5:  loss 0.142013, train_accuracy 1, valid accuracy 0.7238
Epoch 115, CIFAR-10 Batch 1:  loss 0.139609, train_accuracy 1, valid accuracy 0.757
Epoch 115, CIFAR-10 Batch 2:  loss 0.139380, train_accuracy 1, valid accuracy 0.7262
Epoch 115, CIFAR-10 Batch 3:  loss 0.161087, train_accuracy 1, valid accuracy 0.72
Epoch 115, CIFAR-10 Batch 4:  loss 0.146779, train_accuracy 1, valid accuracy 0.765
Epoch 115, CIFAR-10 Batch 5:  loss 0.103279, train_accuracy 1, valid accuracy 0.7614
Epoch 116, CIFAR-10 Batch 1:  loss 0.124400, train_accuracy 1, valid accuracy 0.7604
Epoch 116, CIFAR-10 Batch 2:  loss 0.119178, train_accuracy 1, valid accuracy 0.7514
Epoch 116, CIFAR-10 Batch 3:  loss 0.144206, train_accuracy 1, valid accuracy 0.7552
Epoch 116, CIFAR-10 Batch 4:  loss 0.129640, train_accuracy 1, valid accuracy 0.757
Epoch 116, CIFAR-10 Batch 5:  loss 0.084232, train_accuracy 1, valid accuracy 0.7706
Epoch 117, CIFAR-10 Batch 1:  loss 0.119316, train_accuracy 1, valid accuracy 0.7608
Epoch 117, CIFAR-10 Batch 2:  loss 0.085422, train_accuracy 1, valid accuracy 0.7708
Epoch 117, CIFAR-10 Batch 3:  loss 0.130962, train_accuracy 1, valid accuracy 0.763
Epoch 117, CIFAR-10 Batch 4:  loss 0.143391, train_accuracy 1, valid accuracy 0.7608
Epoch 117, CIFAR-10 Batch 5:  loss 0.089652, train_accuracy 1, valid accuracy 0.753
Epoch 118, CIFAR-10 Batch 1:  loss 0.112740, train_accuracy 1, valid accuracy 0.7728
Epoch 118, CIFAR-10 Batch 2:  loss 0.145422, train_accuracy 0.975, valid accuracy 0.74
Epoch 118, CIFAR-10 Batch 3:  loss 0.131971, train_accuracy 1, valid accuracy 0.7464
Epoch 118, CIFAR-10 Batch 4:  loss 0.115012, train_accuracy 1, valid accuracy 0.7666
Epoch 118, CIFAR-10 Batch 5:  loss 0.079504, train_accuracy 1, valid accuracy 0.7638
Epoch 119, CIFAR-10 Batch 1:  loss 0.113977, train_accuracy 1, valid accuracy 0.7772
Epoch 119, CIFAR-10 Batch 2:  loss 0.108491, train_accuracy 1, valid accuracy 0.741
Epoch 119, CIFAR-10 Batch 3:  loss 0.117242, train_accuracy 1, valid accuracy 0.7442
Epoch 119, CIFAR-10 Batch 4:  loss 0.141286, train_accuracy 1, valid accuracy 0.7578
Epoch 119, CIFAR-10 Batch 5:  loss 0.095137, train_accuracy 1, valid accuracy 0.76
Epoch 120, CIFAR-10 Batch 1:  loss 0.116266, train_accuracy 1, valid accuracy 0.7734
Epoch 120, CIFAR-10 Batch 2:  loss 0.094064, train_accuracy 1, valid accuracy 0.7688
Epoch 120, CIFAR-10 Batch 3:  loss 0.128597, train_accuracy 1, valid accuracy 0.7486
Epoch 120, CIFAR-10 Batch 4:  loss 0.112146, train_accuracy 1, valid accuracy 0.7724
Epoch 120, CIFAR-10 Batch 5:  loss 0.059790, train_accuracy 1, valid accuracy 0.7716
Epoch 121, CIFAR-10 Batch 1:  loss 0.109376, train_accuracy 1, valid accuracy 0.7706
Epoch 121, CIFAR-10 Batch 2:  loss 0.130408, train_accuracy 1, valid accuracy 0.7264
Epoch 121, CIFAR-10 Batch 3:  loss 0.103876, train_accuracy 1, valid accuracy 0.7582
Epoch 121, CIFAR-10 Batch 4:  loss 0.109577, train_accuracy 1, valid accuracy 0.7668
Epoch 121, CIFAR-10 Batch 5:  loss 0.085516, train_accuracy 1, valid accuracy 0.7578
Epoch 122, CIFAR-10 Batch 1:  loss 0.114699, train_accuracy 1, valid accuracy 0.7678
Epoch 122, CIFAR-10 Batch 2:  loss 0.092775, train_accuracy 1, valid accuracy 0.757
Epoch 122, CIFAR-10 Batch 3:  loss 0.120725, train_accuracy 1, valid accuracy 0.745
Epoch 122, CIFAR-10 Batch 4:  loss 0.087679, train_accuracy 1, valid accuracy 0.7694
Epoch 122, CIFAR-10 Batch 5:  loss 0.103477, train_accuracy 1, valid accuracy 0.7512
Epoch 123, CIFAR-10 Batch 1:  loss 0.104650, train_accuracy 1, valid accuracy 0.7768
Epoch 123, CIFAR-10 Batch 2:  loss 0.084737, train_accuracy 1, valid accuracy 0.7536
Epoch 123, CIFAR-10 Batch 3:  loss 0.099333, train_accuracy 1, valid accuracy 0.7634
Epoch 123, CIFAR-10 Batch 4:  loss 0.080360, train_accuracy 1, valid accuracy 0.7704
Epoch 123, CIFAR-10 Batch 5:  loss 0.084027, train_accuracy 1, valid accuracy 0.773
Epoch 124, CIFAR-10 Batch 1:  loss 0.079694, train_accuracy 1, valid accuracy 0.777
Epoch 124, CIFAR-10 Batch 2:  loss 0.080198, train_accuracy 1, valid accuracy 0.7546
Epoch 124, CIFAR-10 Batch 3:  loss 0.082638, train_accuracy 1, valid accuracy 0.7544
Epoch 124, CIFAR-10 Batch 4:  loss 0.090729, train_accuracy 1, valid accuracy 0.7726
Epoch 124, CIFAR-10 Batch 5:  loss 0.090900, train_accuracy 1, valid accuracy 0.7526
Epoch 125, CIFAR-10 Batch 1:  loss 0.081832, train_accuracy 1, valid accuracy 0.7806
Epoch 125, CIFAR-10 Batch 2:  loss 0.090939, train_accuracy 1, valid accuracy 0.75
Epoch 125, CIFAR-10 Batch 3:  loss 0.072840, train_accuracy 1, valid accuracy 0.7618
Epoch 125, CIFAR-10 Batch 4:  loss 0.098424, train_accuracy 0.975, valid accuracy 0.7654
Epoch 125, CIFAR-10 Batch 5:  loss 0.071199, train_accuracy 1, valid accuracy 0.7562
Epoch 126, CIFAR-10 Batch 1:  loss 0.089007, train_accuracy 1, valid accuracy 0.7692
Epoch 126, CIFAR-10 Batch 2:  loss 0.071252, train_accuracy 1, valid accuracy 0.7458
Epoch 126, CIFAR-10 Batch 3:  loss 0.068289, train_accuracy 1, valid accuracy 0.7612
Epoch 126, CIFAR-10 Batch 4:  loss 0.163706, train_accuracy 0.975, valid accuracy 0.7508
Epoch 126, CIFAR-10 Batch 5:  loss 0.084356, train_accuracy 1, valid accuracy 0.739
Epoch 127, CIFAR-10 Batch 1:  loss 0.081390, train_accuracy 1, valid accuracy 0.7676
Epoch 127, CIFAR-10 Batch 2:  loss 0.115803, train_accuracy 1, valid accuracy 0.7378
Epoch 127, CIFAR-10 Batch 3:  loss 0.077971, train_accuracy 1, valid accuracy 0.7566
Epoch 127, CIFAR-10 Batch 4:  loss 0.100057, train_accuracy 1, valid accuracy 0.7624
Epoch 127, CIFAR-10 Batch 5:  loss 0.062108, train_accuracy 1, valid accuracy 0.761
Epoch 128, CIFAR-10 Batch 1:  loss 0.087679, train_accuracy 1, valid accuracy 0.7794
Epoch 128, CIFAR-10 Batch 2:  loss 0.059464, train_accuracy 1, valid accuracy 0.7612
Epoch 128, CIFAR-10 Batch 3:  loss 0.063561, train_accuracy 1, valid accuracy 0.7604
Epoch 128, CIFAR-10 Batch 4:  loss 0.101954, train_accuracy 1, valid accuracy 0.7556
Epoch 128, CIFAR-10 Batch 5:  loss 0.055586, train_accuracy 1, valid accuracy 0.7626
Epoch 129, CIFAR-10 Batch 1:  loss 0.094369, train_accuracy 1, valid accuracy 0.7764
Epoch 129, CIFAR-10 Batch 2:  loss 0.073989, train_accuracy 1, valid accuracy 0.7582
Epoch 129, CIFAR-10 Batch 3:  loss 0.073423, train_accuracy 1, valid accuracy 0.7588
Epoch 129, CIFAR-10 Batch 4:  loss 0.071902, train_accuracy 1, valid accuracy 0.7764
Epoch 129, CIFAR-10 Batch 5:  loss 0.052740, train_accuracy 1, valid accuracy 0.77
Epoch 130, CIFAR-10 Batch 1:  loss 0.085677, train_accuracy 1, valid accuracy 0.7684
Epoch 130, CIFAR-10 Batch 2:  loss 0.057832, train_accuracy 1, valid accuracy 0.7596
Epoch 130, CIFAR-10 Batch 3:  loss 0.069018, train_accuracy 1, valid accuracy 0.7616
Epoch 130, CIFAR-10 Batch 4:  loss 0.089614, train_accuracy 1, valid accuracy 0.7516
Epoch 130, CIFAR-10 Batch 5:  loss 0.106299, train_accuracy 1, valid accuracy 0.7628
Epoch 131, CIFAR-10 Batch 1:  loss 0.096902, train_accuracy 1, valid accuracy 0.7608
Epoch 131, CIFAR-10 Batch 2:  loss 0.089907, train_accuracy 1, valid accuracy 0.7372
Epoch 131, CIFAR-10 Batch 3:  loss 0.074626, train_accuracy 1, valid accuracy 0.7644
Epoch 131, CIFAR-10 Batch 4:  loss 0.071163, train_accuracy 1, valid accuracy 0.7632
Epoch 131, CIFAR-10 Batch 5:  loss 0.083832, train_accuracy 1, valid accuracy 0.7482
Epoch 132, CIFAR-10 Batch 1:  loss 0.087113, train_accuracy 1, valid accuracy 0.7742
Epoch 132, CIFAR-10 Batch 2:  loss 0.057124, train_accuracy 1, valid accuracy 0.7536
Epoch 132, CIFAR-10 Batch 3:  loss 0.060568, train_accuracy 1, valid accuracy 0.7666
Epoch 132, CIFAR-10 Batch 4:  loss 0.091620, train_accuracy 1, valid accuracy 0.7694
Epoch 132, CIFAR-10 Batch 5:  loss 0.075473, train_accuracy 1, valid accuracy 0.7634
Epoch 133, CIFAR-10 Batch 1:  loss 0.076120, train_accuracy 1, valid accuracy 0.7758
Epoch 133, CIFAR-10 Batch 2:  loss 0.049971, train_accuracy 1, valid accuracy 0.7606
Epoch 133, CIFAR-10 Batch 3:  loss 0.064961, train_accuracy 1, valid accuracy 0.7646
Epoch 133, CIFAR-10 Batch 4:  loss 0.067694, train_accuracy 1, valid accuracy 0.7582
Epoch 133, CIFAR-10 Batch 5:  loss 0.057637, train_accuracy 1, valid accuracy 0.7742
Epoch 134, CIFAR-10 Batch 1:  loss 0.071956, train_accuracy 1, valid accuracy 0.777
Epoch 134, CIFAR-10 Batch 2:  loss 0.041080, train_accuracy 1, valid accuracy 0.7696
Epoch 134, CIFAR-10 Batch 3:  loss 0.085768, train_accuracy 1, valid accuracy 0.7504
Epoch 134, CIFAR-10 Batch 4:  loss 0.093242, train_accuracy 1, valid accuracy 0.762
Epoch 134, CIFAR-10 Batch 5:  loss 0.049847, train_accuracy 1, valid accuracy 0.774
Epoch 135, CIFAR-10 Batch 1:  loss 0.082924, train_accuracy 1, valid accuracy 0.7654
Epoch 135, CIFAR-10 Batch 2:  loss 0.048733, train_accuracy 1, valid accuracy 0.7402
Epoch 135, CIFAR-10 Batch 3:  loss 0.061726, train_accuracy 1, valid accuracy 0.7638
Epoch 135, CIFAR-10 Batch 4:  loss 0.073138, train_accuracy 1, valid accuracy 0.7768
Epoch 135, CIFAR-10 Batch 5:  loss 0.071892, train_accuracy 1, valid accuracy 0.7544
Epoch 136, CIFAR-10 Batch 1:  loss 0.076867, train_accuracy 1, valid accuracy 0.771
Epoch 136, CIFAR-10 Batch 2:  loss 0.035729, train_accuracy 1, valid accuracy 0.7696
Epoch 136, CIFAR-10 Batch 3:  loss 0.076245, train_accuracy 1, valid accuracy 0.7654
Epoch 136, CIFAR-10 Batch 4:  loss 0.061655, train_accuracy 1, valid accuracy 0.7838
Epoch 136, CIFAR-10 Batch 5:  loss 0.077607, train_accuracy 1, valid accuracy 0.7464
Epoch 137, CIFAR-10 Batch 1:  loss 0.086502, train_accuracy 1, valid accuracy 0.772
Epoch 137, CIFAR-10 Batch 2:  loss 0.050846, train_accuracy 1, valid accuracy 0.7636
Epoch 137, CIFAR-10 Batch 3:  loss 0.067862, train_accuracy 1, valid accuracy 0.776
Epoch 137, CIFAR-10 Batch 4:  loss 0.050852, train_accuracy 1, valid accuracy 0.773
Epoch 137, CIFAR-10 Batch 5:  loss 0.103253, train_accuracy 1, valid accuracy 0.7356
Epoch 138, CIFAR-10 Batch 1:  loss 0.073699, train_accuracy 1, valid accuracy 0.7786
Epoch 138, CIFAR-10 Batch 2:  loss 0.072762, train_accuracy 1, valid accuracy 0.7362
Epoch 138, CIFAR-10 Batch 3:  loss 0.045855, train_accuracy 1, valid accuracy 0.7802
Epoch 138, CIFAR-10 Batch 4:  loss 0.052903, train_accuracy 1, valid accuracy 0.7688
Epoch 138, CIFAR-10 Batch 5:  loss 0.072709, train_accuracy 1, valid accuracy 0.7636
Epoch 139, CIFAR-10 Batch 1:  loss 0.065842, train_accuracy 1, valid accuracy 0.7754
Epoch 139, CIFAR-10 Batch 2:  loss 0.048679, train_accuracy 1, valid accuracy 0.762
Epoch 139, CIFAR-10 Batch 3:  loss 0.067138, train_accuracy 1, valid accuracy 0.7564
Epoch 139, CIFAR-10 Batch 4:  loss 0.061532, train_accuracy 1, valid accuracy 0.7696
Epoch 139, CIFAR-10 Batch 5:  loss 0.069727, train_accuracy 1, valid accuracy 0.7652
Epoch 140, CIFAR-10 Batch 1:  loss 0.087470, train_accuracy 1, valid accuracy 0.7746
Epoch 140, CIFAR-10 Batch 2:  loss 0.053916, train_accuracy 1, valid accuracy 0.758
Epoch 140, CIFAR-10 Batch 3:  loss 0.038920, train_accuracy 1, valid accuracy 0.7754
Epoch 140, CIFAR-10 Batch 4:  loss 0.058706, train_accuracy 1, valid accuracy 0.7696
Epoch 140, CIFAR-10 Batch 5:  loss 0.058903, train_accuracy 1, valid accuracy 0.767
Epoch 141, CIFAR-10 Batch 1:  loss 0.069731, train_accuracy 1, valid accuracy 0.7806
Epoch 141, CIFAR-10 Batch 2:  loss 0.061664, train_accuracy 1, valid accuracy 0.7648
Epoch 141, CIFAR-10 Batch 3:  loss 0.036632, train_accuracy 1, valid accuracy 0.7736
Epoch 141, CIFAR-10 Batch 4:  loss 0.059635, train_accuracy 1, valid accuracy 0.786
Epoch 141, CIFAR-10 Batch 5:  loss 0.047789, train_accuracy 1, valid accuracy 0.766
Epoch 142, CIFAR-10 Batch 1:  loss 0.051732, train_accuracy 1, valid accuracy 0.7724
Epoch 142, CIFAR-10 Batch 2:  loss 0.040149, train_accuracy 1, valid accuracy 0.7526
Epoch 142, CIFAR-10 Batch 3:  loss 0.058502, train_accuracy 1, valid accuracy 0.766
Epoch 142, CIFAR-10 Batch 4:  loss 0.059437, train_accuracy 1, valid accuracy 0.7764
Epoch 142, CIFAR-10 Batch 5:  loss 0.089044, train_accuracy 1, valid accuracy 0.7624
Epoch 143, CIFAR-10 Batch 1:  loss 0.060771, train_accuracy 1, valid accuracy 0.768
Epoch 143, CIFAR-10 Batch 2:  loss 0.042642, train_accuracy 1, valid accuracy 0.7536
Epoch 143, CIFAR-10 Batch 3:  loss 0.079303, train_accuracy 1, valid accuracy 0.76
Epoch 143, CIFAR-10 Batch 4:  loss 0.056654, train_accuracy 1, valid accuracy 0.779
Epoch 143, CIFAR-10 Batch 5:  loss 0.059908, train_accuracy 1, valid accuracy 0.7624
Epoch 144, CIFAR-10 Batch 1:  loss 0.053706, train_accuracy 1, valid accuracy 0.7804
Epoch 144, CIFAR-10 Batch 2:  loss 0.038228, train_accuracy 1, valid accuracy 0.7654
Epoch 144, CIFAR-10 Batch 3:  loss 0.058099, train_accuracy 1, valid accuracy 0.758
Epoch 144, CIFAR-10 Batch 4:  loss 0.066170, train_accuracy 0.975, valid accuracy 0.778
Epoch 144, CIFAR-10 Batch 5:  loss 0.049193, train_accuracy 1, valid accuracy 0.7758
Epoch 145, CIFAR-10 Batch 1:  loss 0.046952, train_accuracy 1, valid accuracy 0.7844
Epoch 145, CIFAR-10 Batch 2:  loss 0.033329, train_accuracy 1, valid accuracy 0.7772
Epoch 145, CIFAR-10 Batch 3:  loss 0.070127, train_accuracy 1, valid accuracy 0.7672
Epoch 145, CIFAR-10 Batch 4:  loss 0.063872, train_accuracy 1, valid accuracy 0.7728
Epoch 145, CIFAR-10 Batch 5:  loss 0.031907, train_accuracy 1, valid accuracy 0.7766
Epoch 146, CIFAR-10 Batch 1:  loss 0.051123, train_accuracy 1, valid accuracy 0.7804
Epoch 146, CIFAR-10 Batch 2:  loss 0.064065, train_accuracy 0.975, valid accuracy 0.7538
Epoch 146, CIFAR-10 Batch 3:  loss 0.067346, train_accuracy 1, valid accuracy 0.7646
Epoch 146, CIFAR-10 Batch 4:  loss 0.069656, train_accuracy 1, valid accuracy 0.7658
Epoch 146, CIFAR-10 Batch 5:  loss 0.066386, train_accuracy 1, valid accuracy 0.7426
Epoch 147, CIFAR-10 Batch 1:  loss 0.045137, train_accuracy 1, valid accuracy 0.7816
Epoch 147, CIFAR-10 Batch 2:  loss 0.038330, train_accuracy 1, valid accuracy 0.763
Epoch 147, CIFAR-10 Batch 3:  loss 0.044856, train_accuracy 1, valid accuracy 0.777
Epoch 147, CIFAR-10 Batch 4:  loss 0.078312, train_accuracy 0.975, valid accuracy 0.7612
Epoch 147, CIFAR-10 Batch 5:  loss 0.042709, train_accuracy 1, valid accuracy 0.7776
Epoch 148, CIFAR-10 Batch 1:  loss 0.040386, train_accuracy 1, valid accuracy 0.781
Epoch 148, CIFAR-10 Batch 2:  loss 0.032122, train_accuracy 1, valid accuracy 0.7558
Epoch 148, CIFAR-10 Batch 3:  loss 0.043818, train_accuracy 1, valid accuracy 0.7744
Epoch 148, CIFAR-10 Batch 4:  loss 0.045029, train_accuracy 1, valid accuracy 0.782
Epoch 148, CIFAR-10 Batch 5:  loss 0.047014, train_accuracy 1, valid accuracy 0.7666
Epoch 149, CIFAR-10 Batch 1:  loss 0.055759, train_accuracy 1, valid accuracy 0.7904
Epoch 149, CIFAR-10 Batch 2:  loss 0.040617, train_accuracy 1, valid accuracy 0.7692
Epoch 149, CIFAR-10 Batch 3:  loss 0.062168, train_accuracy 1, valid accuracy 0.77
Epoch 149, CIFAR-10 Batch 4:  loss 0.064705, train_accuracy 1, valid accuracy 0.7662
Epoch 149, CIFAR-10 Batch 5:  loss 0.043368, train_accuracy 1, valid accuracy 0.7656
Epoch 150, CIFAR-10 Batch 1:  loss 0.056404, train_accuracy 1, valid accuracy 0.7784
Epoch 150, CIFAR-10 Batch 2:  loss 0.042379, train_accuracy 1, valid accuracy 0.7816
Epoch 150, CIFAR-10 Batch 3:  loss 0.036468, train_accuracy 1, valid accuracy 0.7832
Epoch 150, CIFAR-10 Batch 4:  loss 0.066334, train_accuracy 0.975, valid accuracy 0.7688
Epoch 150, CIFAR-10 Batch 5:  loss 0.052403, train_accuracy 1, valid accuracy 0.7678
Epoch 151, CIFAR-10 Batch 1:  loss 0.059825, train_accuracy 1, valid accuracy 0.7854
Epoch 151, CIFAR-10 Batch 2:  loss 0.038964, train_accuracy 1, valid accuracy 0.7688
Epoch 151, CIFAR-10 Batch 3:  loss 0.043168, train_accuracy 1, valid accuracy 0.7758
Epoch 151, CIFAR-10 Batch 4:  loss 0.042927, train_accuracy 1, valid accuracy 0.7814
Epoch 151, CIFAR-10 Batch 5:  loss 0.039540, train_accuracy 1, valid accuracy 0.7686
Epoch 152, CIFAR-10 Batch 1:  loss 0.051347, train_accuracy 1, valid accuracy 0.7778
Epoch 152, CIFAR-10 Batch 2:  loss 0.046129, train_accuracy 1, valid accuracy 0.779
Epoch 152, CIFAR-10 Batch 3:  loss 0.053208, train_accuracy 1, valid accuracy 0.766
Epoch 152, CIFAR-10 Batch 4:  loss 0.059126, train_accuracy 0.975, valid accuracy 0.7738
Epoch 152, CIFAR-10 Batch 5:  loss 0.030179, train_accuracy 1, valid accuracy 0.7738
Epoch 153, CIFAR-10 Batch 1:  loss 0.038702, train_accuracy 1, valid accuracy 0.7842
Epoch 153, CIFAR-10 Batch 2:  loss 0.033709, train_accuracy 1, valid accuracy 0.781
Epoch 153, CIFAR-10 Batch 3:  loss 0.044980, train_accuracy 1, valid accuracy 0.7632
Epoch 153, CIFAR-10 Batch 4:  loss 0.030266, train_accuracy 1, valid accuracy 0.78
Epoch 153, CIFAR-10 Batch 5:  loss 0.047337, train_accuracy 1, valid accuracy 0.778
Epoch 154, CIFAR-10 Batch 1:  loss 0.034135, train_accuracy 1, valid accuracy 0.7822
Epoch 154, CIFAR-10 Batch 2:  loss 0.022310, train_accuracy 1, valid accuracy 0.7788
Epoch 154, CIFAR-10 Batch 3:  loss 0.034123, train_accuracy 1, valid accuracy 0.7724
Epoch 154, CIFAR-10 Batch 4:  loss 0.039459, train_accuracy 1, valid accuracy 0.7838
Epoch 154, CIFAR-10 Batch 5:  loss 0.045504, train_accuracy 1, valid accuracy 0.7688
Epoch 155, CIFAR-10 Batch 1:  loss 0.041743, train_accuracy 1, valid accuracy 0.7812
Epoch 155, CIFAR-10 Batch 2:  loss 0.042963, train_accuracy 1, valid accuracy 0.7664
Epoch 155, CIFAR-10 Batch 3:  loss 0.031257, train_accuracy 1, valid accuracy 0.7846
Epoch 155, CIFAR-10 Batch 4:  loss 0.034852, train_accuracy 1, valid accuracy 0.7772
Epoch 155, CIFAR-10 Batch 5:  loss 0.038767, train_accuracy 1, valid accuracy 0.7692
Epoch 156, CIFAR-10 Batch 1:  loss 0.038363, train_accuracy 1, valid accuracy 0.7826
Epoch 156, CIFAR-10 Batch 2:  loss 0.024972, train_accuracy 1, valid accuracy 0.7792
Epoch 156, CIFAR-10 Batch 3:  loss 0.035612, train_accuracy 1, valid accuracy 0.7744
Epoch 156, CIFAR-10 Batch 4:  loss 0.074001, train_accuracy 0.975, valid accuracy 0.7668
Epoch 156, CIFAR-10 Batch 5:  loss 0.041205, train_accuracy 1, valid accuracy 0.7604
Epoch 157, CIFAR-10 Batch 1:  loss 0.043662, train_accuracy 1, valid accuracy 0.7848
Epoch 157, CIFAR-10 Batch 2:  loss 0.026762, train_accuracy 1, valid accuracy 0.7696
Epoch 157, CIFAR-10 Batch 3:  loss 0.033257, train_accuracy 1, valid accuracy 0.7808
Epoch 157, CIFAR-10 Batch 4:  loss 0.057474, train_accuracy 1, valid accuracy 0.777
Epoch 157, CIFAR-10 Batch 5:  loss 0.034308, train_accuracy 1, valid accuracy 0.7766
Epoch 158, CIFAR-10 Batch 1:  loss 0.046933, train_accuracy 1, valid accuracy 0.7814
Epoch 158, CIFAR-10 Batch 2:  loss 0.020183, train_accuracy 1, valid accuracy 0.78
Epoch 158, CIFAR-10 Batch 3:  loss 0.029607, train_accuracy 1, valid accuracy 0.7744
Epoch 158, CIFAR-10 Batch 4:  loss 0.047996, train_accuracy 1, valid accuracy 0.7814
Epoch 158, CIFAR-10 Batch 5:  loss 0.041868, train_accuracy 1, valid accuracy 0.7752
Epoch 159, CIFAR-10 Batch 1:  loss 0.044711, train_accuracy 1, valid accuracy 0.782
Epoch 159, CIFAR-10 Batch 2:  loss 0.061200, train_accuracy 1, valid accuracy 0.7596
Epoch 159, CIFAR-10 Batch 3:  loss 0.034721, train_accuracy 1, valid accuracy 0.7656
Epoch 159, CIFAR-10 Batch 4:  loss 0.036171, train_accuracy 1, valid accuracy 0.7808
Epoch 159, CIFAR-10 Batch 5:  loss 0.067569, train_accuracy 1, valid accuracy 0.7494
Epoch 160, CIFAR-10 Batch 1:  loss 0.042177, train_accuracy 1, valid accuracy 0.7792
Epoch 160, CIFAR-10 Batch 2:  loss 0.029247, train_accuracy 1, valid accuracy 0.7814
Epoch 160, CIFAR-10 Batch 3:  loss 0.024640, train_accuracy 1, valid accuracy 0.775
Epoch 160, CIFAR-10 Batch 4:  loss 0.036433, train_accuracy 1, valid accuracy 0.7754
Epoch 160, CIFAR-10 Batch 5:  loss 0.050875, train_accuracy 1, valid accuracy 0.7656
Epoch 161, CIFAR-10 Batch 1:  loss 0.035379, train_accuracy 1, valid accuracy 0.7804
Epoch 161, CIFAR-10 Batch 2:  loss 0.017564, train_accuracy 1, valid accuracy 0.7782
Epoch 161, CIFAR-10 Batch 3:  loss 0.039190, train_accuracy 1, valid accuracy 0.7696
Epoch 161, CIFAR-10 Batch 4:  loss 0.045438, train_accuracy 1, valid accuracy 0.7808
Epoch 161, CIFAR-10 Batch 5:  loss 0.030178, train_accuracy 1, valid accuracy 0.7794
Epoch 162, CIFAR-10 Batch 1:  loss 0.034243, train_accuracy 1, valid accuracy 0.7858
Epoch 162, CIFAR-10 Batch 2:  loss 0.036548, train_accuracy 1, valid accuracy 0.7666
Epoch 162, CIFAR-10 Batch 3:  loss 0.029155, train_accuracy 1, valid accuracy 0.7706
Epoch 162, CIFAR-10 Batch 4:  loss 0.050178, train_accuracy 1, valid accuracy 0.7712
Epoch 162, CIFAR-10 Batch 5:  loss 0.028662, train_accuracy 1, valid accuracy 0.7702
Epoch 163, CIFAR-10 Batch 1:  loss 0.038500, train_accuracy 1, valid accuracy 0.7884
Epoch 163, CIFAR-10 Batch 2:  loss 0.030928, train_accuracy 1, valid accuracy 0.7754
Epoch 163, CIFAR-10 Batch 3:  loss 0.049153, train_accuracy 1, valid accuracy 0.7822
Epoch 163, CIFAR-10 Batch 4:  loss 0.067394, train_accuracy 1, valid accuracy 0.7634
Epoch 163, CIFAR-10 Batch 5:  loss 0.026409, train_accuracy 1, valid accuracy 0.784
Epoch 164, CIFAR-10 Batch 1:  loss 0.039543, train_accuracy 1, valid accuracy 0.7806
Epoch 164, CIFAR-10 Batch 2:  loss 0.031830, train_accuracy 1, valid accuracy 0.7744
Epoch 164, CIFAR-10 Batch 3:  loss 0.033778, train_accuracy 1, valid accuracy 0.7796
Epoch 164, CIFAR-10 Batch 4:  loss 0.029514, train_accuracy 1, valid accuracy 0.783
Epoch 164, CIFAR-10 Batch 5:  loss 0.026419, train_accuracy 1, valid accuracy 0.7776
Epoch 165, CIFAR-10 Batch 1:  loss 0.034781, train_accuracy 1, valid accuracy 0.7892
Epoch 165, CIFAR-10 Batch 2:  loss 0.026147, train_accuracy 1, valid accuracy 0.7884
Epoch 165, CIFAR-10 Batch 3:  loss 0.021372, train_accuracy 1, valid accuracy 0.7874
Epoch 165, CIFAR-10 Batch 4:  loss 0.018998, train_accuracy 1, valid accuracy 0.7868
Epoch 165, CIFAR-10 Batch 5:  loss 0.035600, train_accuracy 1, valid accuracy 0.7784
Epoch 166, CIFAR-10 Batch 1:  loss 0.026438, train_accuracy 1, valid accuracy 0.7818
Epoch 166, CIFAR-10 Batch 2:  loss 0.024313, train_accuracy 1, valid accuracy 0.78
Epoch 166, CIFAR-10 Batch 3:  loss 0.025620, train_accuracy 1, valid accuracy 0.7856
Epoch 166, CIFAR-10 Batch 4:  loss 0.047858, train_accuracy 1, valid accuracy 0.7812
Epoch 166, CIFAR-10 Batch 5:  loss 0.043412, train_accuracy 1, valid accuracy 0.767
Epoch 167, CIFAR-10 Batch 1:  loss 0.040185, train_accuracy 1, valid accuracy 0.7768
Epoch 167, CIFAR-10 Batch 2:  loss 0.028984, train_accuracy 1, valid accuracy 0.777
Epoch 167, CIFAR-10 Batch 3:  loss 0.034236, train_accuracy 1, valid accuracy 0.7752
Epoch 167, CIFAR-10 Batch 4:  loss 0.046434, train_accuracy 1, valid accuracy 0.7838
Epoch 167, CIFAR-10 Batch 5:  loss 0.035854, train_accuracy 1, valid accuracy 0.7778
Epoch 168, CIFAR-10 Batch 1:  loss 0.024937, train_accuracy 1, valid accuracy 0.7958
Epoch 168, CIFAR-10 Batch 2:  loss 0.039193, train_accuracy 1, valid accuracy 0.7618
Epoch 168, CIFAR-10 Batch 3:  loss 0.033515, train_accuracy 1, valid accuracy 0.7826
Epoch 168, CIFAR-10 Batch 4:  loss 0.043801, train_accuracy 0.975, valid accuracy 0.7846
Epoch 168, CIFAR-10 Batch 5:  loss 0.039815, train_accuracy 1, valid accuracy 0.7442
Epoch 169, CIFAR-10 Batch 1:  loss 0.027599, train_accuracy 1, valid accuracy 0.7828
Epoch 169, CIFAR-10 Batch 2:  loss 0.023173, train_accuracy 1, valid accuracy 0.7718
Epoch 169, CIFAR-10 Batch 3:  loss 0.032100, train_accuracy 1, valid accuracy 0.7682
Epoch 169, CIFAR-10 Batch 4:  loss 0.037516, train_accuracy 1, valid accuracy 0.7762
Epoch 169, CIFAR-10 Batch 5:  loss 0.039999, train_accuracy 1, valid accuracy 0.7688
Epoch 170, CIFAR-10 Batch 1:  loss 0.029894, train_accuracy 1, valid accuracy 0.7756
Epoch 170, CIFAR-10 Batch 2:  loss 0.017163, train_accuracy 1, valid accuracy 0.7822
Epoch 170, CIFAR-10 Batch 3:  loss 0.044608, train_accuracy 1, valid accuracy 0.7874
Epoch 170, CIFAR-10 Batch 4:  loss 0.044865, train_accuracy 1, valid accuracy 0.7866
Epoch 170, CIFAR-10 Batch 5:  loss 0.022886, train_accuracy 1, valid accuracy 0.7798
Epoch 171, CIFAR-10 Batch 1:  loss 0.023781, train_accuracy 1, valid accuracy 0.79
Epoch 171, CIFAR-10 Batch 2:  loss 0.021268, train_accuracy 1, valid accuracy 0.7872
Epoch 171, CIFAR-10 Batch 3:  loss 0.029420, train_accuracy 1, valid accuracy 0.781
Epoch 171, CIFAR-10 Batch 4:  loss 0.049719, train_accuracy 0.975, valid accuracy 0.7692
Epoch 171, CIFAR-10 Batch 5:  loss 0.033261, train_accuracy 1, valid accuracy 0.7722
Epoch 172, CIFAR-10 Batch 1:  loss 0.030982, train_accuracy 1, valid accuracy 0.7866
Epoch 172, CIFAR-10 Batch 2:  loss 0.029981, train_accuracy 1, valid accuracy 0.7868
Epoch 172, CIFAR-10 Batch 3:  loss 0.038683, train_accuracy 1, valid accuracy 0.7752
Epoch 172, CIFAR-10 Batch 4:  loss 0.031797, train_accuracy 1, valid accuracy 0.7848
Epoch 172, CIFAR-10 Batch 5:  loss 0.025738, train_accuracy 1, valid accuracy 0.7766
Epoch 173, CIFAR-10 Batch 1:  loss 0.026394, train_accuracy 1, valid accuracy 0.795
Epoch 173, CIFAR-10 Batch 2:  loss 0.029774, train_accuracy 1, valid accuracy 0.7668
Epoch 173, CIFAR-10 Batch 3:  loss 0.028213, train_accuracy 1, valid accuracy 0.7824
Epoch 173, CIFAR-10 Batch 4:  loss 0.044686, train_accuracy 1, valid accuracy 0.7618
Epoch 173, CIFAR-10 Batch 5:  loss 0.022713, train_accuracy 1, valid accuracy 0.7674
Epoch 174, CIFAR-10 Batch 1:  loss 0.033169, train_accuracy 1, valid accuracy 0.7946
Epoch 174, CIFAR-10 Batch 2:  loss 0.028017, train_accuracy 1, valid accuracy 0.7768
Epoch 174, CIFAR-10 Batch 3:  loss 0.018478, train_accuracy 1, valid accuracy 0.786
Epoch 174, CIFAR-10 Batch 4:  loss 0.034992, train_accuracy 1, valid accuracy 0.7888
Epoch 174, CIFAR-10 Batch 5:  loss 0.029810, train_accuracy 1, valid accuracy 0.7654
Epoch 175, CIFAR-10 Batch 1:  loss 0.110487, train_accuracy 0.975, valid accuracy 0.7692
Epoch 175, CIFAR-10 Batch 2:  loss 0.011297, train_accuracy 1, valid accuracy 0.7818
Epoch 175, CIFAR-10 Batch 3:  loss 0.042072, train_accuracy 1, valid accuracy 0.7712
Epoch 175, CIFAR-10 Batch 4:  loss 0.040785, train_accuracy 1, valid accuracy 0.786
Epoch 175, CIFAR-10 Batch 5:  loss 0.016942, train_accuracy 1, valid accuracy 0.7914
Epoch 176, CIFAR-10 Batch 1:  loss 0.028312, train_accuracy 1, valid accuracy 0.791
Epoch 176, CIFAR-10 Batch 2:  loss 0.023843, train_accuracy 1, valid accuracy 0.7758
Epoch 176, CIFAR-10 Batch 3:  loss 0.015783, train_accuracy 1, valid accuracy 0.7918
Epoch 176, CIFAR-10 Batch 4:  loss 0.033127, train_accuracy 1, valid accuracy 0.7894
Epoch 176, CIFAR-10 Batch 5:  loss 0.016139, train_accuracy 1, valid accuracy 0.7706
Epoch 177, CIFAR-10 Batch 1:  loss 0.024850, train_accuracy 1, valid accuracy 0.7974
Epoch 177, CIFAR-10 Batch 2:  loss 0.018498, train_accuracy 1, valid accuracy 0.7902
Epoch 177, CIFAR-10 Batch 3:  loss 0.024839, train_accuracy 1, valid accuracy 0.7814
Epoch 177, CIFAR-10 Batch 4:  loss 0.026677, train_accuracy 1, valid accuracy 0.7842
Epoch 177, CIFAR-10 Batch 5:  loss 0.015957, train_accuracy 1, valid accuracy 0.779
Epoch 178, CIFAR-10 Batch 1:  loss 0.027042, train_accuracy 1, valid accuracy 0.7926
Epoch 178, CIFAR-10 Batch 2:  loss 0.092561, train_accuracy 0.975, valid accuracy 0.75
Epoch 178, CIFAR-10 Batch 3:  loss 0.022071, train_accuracy 1, valid accuracy 0.7792
Epoch 178, CIFAR-10 Batch 4:  loss 0.029273, train_accuracy 1, valid accuracy 0.7826
Epoch 178, CIFAR-10 Batch 5:  loss 0.018090, train_accuracy 1, valid accuracy 0.7806
Epoch 179, CIFAR-10 Batch 1:  loss 0.019984, train_accuracy 1, valid accuracy 0.7922
Epoch 179, CIFAR-10 Batch 2:  loss 0.015480, train_accuracy 1, valid accuracy 0.7882
Epoch 179, CIFAR-10 Batch 3:  loss 0.030072, train_accuracy 1, valid accuracy 0.7808
Epoch 179, CIFAR-10 Batch 4:  loss 0.016110, train_accuracy 1, valid accuracy 0.7884
Epoch 179, CIFAR-10 Batch 5:  loss 0.028567, train_accuracy 1, valid accuracy 0.7704
Epoch 180, CIFAR-10 Batch 1:  loss 0.023080, train_accuracy 1, valid accuracy 0.7916
Epoch 180, CIFAR-10 Batch 2:  loss 0.016288, train_accuracy 1, valid accuracy 0.7816
Epoch 180, CIFAR-10 Batch 3:  loss 0.015960, train_accuracy 1, valid accuracy 0.787
Epoch 180, CIFAR-10 Batch 4:  loss 0.031681, train_accuracy 1, valid accuracy 0.7884
Epoch 180, CIFAR-10 Batch 5:  loss 0.027985, train_accuracy 1, valid accuracy 0.7934
Epoch 181, CIFAR-10 Batch 1:  loss 0.047364, train_accuracy 1, valid accuracy 0.7834
Epoch 181, CIFAR-10 Batch 2:  loss 0.028401, train_accuracy 1, valid accuracy 0.7736
Epoch 181, CIFAR-10 Batch 3:  loss 0.026866, train_accuracy 1, valid accuracy 0.7842
Epoch 181, CIFAR-10 Batch 4:  loss 0.016979, train_accuracy 1, valid accuracy 0.7832
Epoch 181, CIFAR-10 Batch 5:  loss 0.023727, train_accuracy 1, valid accuracy 0.7836
Epoch 182, CIFAR-10 Batch 1:  loss 0.026873, train_accuracy 1, valid accuracy 0.7996
Epoch 182, CIFAR-10 Batch 2:  loss 0.029161, train_accuracy 1, valid accuracy 0.7674
Epoch 182, CIFAR-10 Batch 3:  loss 0.029087, train_accuracy 1, valid accuracy 0.7868
Epoch 182, CIFAR-10 Batch 4:  loss 0.021366, train_accuracy 1, valid accuracy 0.7844
Epoch 182, CIFAR-10 Batch 5:  loss 0.024557, train_accuracy 1, valid accuracy 0.7898
Epoch 183, CIFAR-10 Batch 1:  loss 0.023892, train_accuracy 1, valid accuracy 0.7846
Epoch 183, CIFAR-10 Batch 2:  loss 0.021660, train_accuracy 1, valid accuracy 0.7844
Epoch 183, CIFAR-10 Batch 3:  loss 0.030171, train_accuracy 1, valid accuracy 0.7908
Epoch 183, CIFAR-10 Batch 4:  loss 0.047316, train_accuracy 0.975, valid accuracy 0.776
Epoch 183, CIFAR-10 Batch 5:  loss 0.021657, train_accuracy 1, valid accuracy 0.7766
Epoch 184, CIFAR-10 Batch 1:  loss 0.038461, train_accuracy 0.975, valid accuracy 0.7896
Epoch 184, CIFAR-10 Batch 2:  loss 0.020536, train_accuracy 1, valid accuracy 0.7938
Epoch 184, CIFAR-10 Batch 3:  loss 0.019527, train_accuracy 1, valid accuracy 0.7732
Epoch 184, CIFAR-10 Batch 4:  loss 0.058002, train_accuracy 0.975, valid accuracy 0.776
Epoch 184, CIFAR-10 Batch 5:  loss 0.013577, train_accuracy 1, valid accuracy 0.7844
Epoch 185, CIFAR-10 Batch 1:  loss 0.034596, train_accuracy 1, valid accuracy 0.7832
Epoch 185, CIFAR-10 Batch 2:  loss 0.010848, train_accuracy 1, valid accuracy 0.7838
Epoch 185, CIFAR-10 Batch 3:  loss 0.020603, train_accuracy 1, valid accuracy 0.7798
Epoch 185, CIFAR-10 Batch 4:  loss 0.020685, train_accuracy 1, valid accuracy 0.791
Epoch 185, CIFAR-10 Batch 5:  loss 0.012392, train_accuracy 1, valid accuracy 0.781
Epoch 186, CIFAR-10 Batch 1:  loss 0.025899, train_accuracy 1, valid accuracy 0.792
Epoch 186, CIFAR-10 Batch 2:  loss 0.051514, train_accuracy 1, valid accuracy 0.7706
Epoch 186, CIFAR-10 Batch 3:  loss 0.028268, train_accuracy 1, valid accuracy 0.7894
Epoch 186, CIFAR-10 Batch 4:  loss 0.028234, train_accuracy 1, valid accuracy 0.7808
Epoch 186, CIFAR-10 Batch 5:  loss 0.016188, train_accuracy 1, valid accuracy 0.7844
Epoch 187, CIFAR-10 Batch 1:  loss 0.026025, train_accuracy 1, valid accuracy 0.7862
Epoch 187, CIFAR-10 Batch 2:  loss 0.023210, train_accuracy 1, valid accuracy 0.7648
Epoch 187, CIFAR-10 Batch 3:  loss 0.024193, train_accuracy 1, valid accuracy 0.762
Epoch 187, CIFAR-10 Batch 4:  loss 0.016580, train_accuracy 1, valid accuracy 0.7848
Epoch 187, CIFAR-10 Batch 5:  loss 0.019221, train_accuracy 1, valid accuracy 0.7662
Epoch 188, CIFAR-10 Batch 1:  loss 0.037037, train_accuracy 1, valid accuracy 0.7918
Epoch 188, CIFAR-10 Batch 2:  loss 0.016413, train_accuracy 1, valid accuracy 0.7736
Epoch 188, CIFAR-10 Batch 3:  loss 0.021869, train_accuracy 1, valid accuracy 0.788
Epoch 188, CIFAR-10 Batch 4:  loss 0.045145, train_accuracy 0.975, valid accuracy 0.7876
Epoch 188, CIFAR-10 Batch 5:  loss 0.009676, train_accuracy 1, valid accuracy 0.7862
Epoch 189, CIFAR-10 Batch 1:  loss 0.021704, train_accuracy 1, valid accuracy 0.7896
Epoch 189, CIFAR-10 Batch 2:  loss 0.016012, train_accuracy 1, valid accuracy 0.7872
Epoch 189, CIFAR-10 Batch 3:  loss 0.027715, train_accuracy 1, valid accuracy 0.7698
Epoch 189, CIFAR-10 Batch 4:  loss 0.031915, train_accuracy 1, valid accuracy 0.7928
Epoch 189, CIFAR-10 Batch 5:  loss 0.027615, train_accuracy 1, valid accuracy 0.7696
Epoch 190, CIFAR-10 Batch 1:  loss 0.023925, train_accuracy 1, valid accuracy 0.7784
Epoch 190, CIFAR-10 Batch 2:  loss 0.014687, train_accuracy 1, valid accuracy 0.78
Epoch 190, CIFAR-10 Batch 3:  loss 0.037377, train_accuracy 1, valid accuracy 0.7784
Epoch 190, CIFAR-10 Batch 4:  loss 0.042561, train_accuracy 0.975, valid accuracy 0.787
Epoch 190, CIFAR-10 Batch 5:  loss 0.028876, train_accuracy 1, valid accuracy 0.762
Epoch 191, CIFAR-10 Batch 1:  loss 0.025444, train_accuracy 1, valid accuracy 0.7782
Epoch 191, CIFAR-10 Batch 2:  loss 0.018452, train_accuracy 1, valid accuracy 0.784
Epoch 191, CIFAR-10 Batch 3:  loss 0.017686, train_accuracy 1, valid accuracy 0.7864
Epoch 191, CIFAR-10 Batch 4:  loss 0.019041, train_accuracy 1, valid accuracy 0.7946
Epoch 191, CIFAR-10 Batch 5:  loss 0.012802, train_accuracy 1, valid accuracy 0.7804
Epoch 192, CIFAR-10 Batch 1:  loss 0.015216, train_accuracy 1, valid accuracy 0.7904
Epoch 192, CIFAR-10 Batch 2:  loss 0.017638, train_accuracy 1, valid accuracy 0.7936
Epoch 192, CIFAR-10 Batch 3:  loss 0.026981, train_accuracy 1, valid accuracy 0.7772
Epoch 192, CIFAR-10 Batch 4:  loss 0.031692, train_accuracy 1, valid accuracy 0.7806
Epoch 192, CIFAR-10 Batch 5:  loss 0.033762, train_accuracy 1, valid accuracy 0.761
Epoch 193, CIFAR-10 Batch 1:  loss 0.037994, train_accuracy 1, valid accuracy 0.7684
Epoch 193, CIFAR-10 Batch 2:  loss 0.017489, train_accuracy 1, valid accuracy 0.7828
Epoch 193, CIFAR-10 Batch 3:  loss 0.028277, train_accuracy 1, valid accuracy 0.7858
Epoch 193, CIFAR-10 Batch 4:  loss 0.041885, train_accuracy 0.975, valid accuracy 0.7764
Epoch 193, CIFAR-10 Batch 5:  loss 0.019729, train_accuracy 1, valid accuracy 0.7764
Epoch 194, CIFAR-10 Batch 1:  loss 0.022182, train_accuracy 1, valid accuracy 0.796
Epoch 194, CIFAR-10 Batch 2:  loss 0.031619, train_accuracy 1, valid accuracy 0.7724
Epoch 194, CIFAR-10 Batch 3:  loss 0.020820, train_accuracy 1, valid accuracy 0.7796
Epoch 194, CIFAR-10 Batch 4:  loss 0.027712, train_accuracy 1, valid accuracy 0.7898
Epoch 194, CIFAR-10 Batch 5:  loss 0.017687, train_accuracy 1, valid accuracy 0.7748
Epoch 195, CIFAR-10 Batch 1:  loss 0.010922, train_accuracy 1, valid accuracy 0.8
Epoch 195, CIFAR-10 Batch 2:  loss 0.010532, train_accuracy 1, valid accuracy 0.7966
Epoch 195, CIFAR-10 Batch 3:  loss 0.030230, train_accuracy 1, valid accuracy 0.7858
Epoch 195, CIFAR-10 Batch 4:  loss 0.053313, train_accuracy 0.975, valid accuracy 0.7852
Epoch 195, CIFAR-10 Batch 5:  loss 0.011896, train_accuracy 1, valid accuracy 0.7794
Epoch 196, CIFAR-10 Batch 1:  loss 0.020325, train_accuracy 1, valid accuracy 0.7898
Epoch 196, CIFAR-10 Batch 2:  loss 0.011549, train_accuracy 1, valid accuracy 0.7786
Epoch 196, CIFAR-10 Batch 3:  loss 0.027888, train_accuracy 1, valid accuracy 0.786
Epoch 196, CIFAR-10 Batch 4:  loss 0.023946, train_accuracy 1, valid accuracy 0.7954
Epoch 196, CIFAR-10 Batch 5:  loss 0.016125, train_accuracy 1, valid accuracy 0.7798
Epoch 197, CIFAR-10 Batch 1:  loss 0.020430, train_accuracy 1, valid accuracy 0.7948
Epoch 197, CIFAR-10 Batch 2:  loss 0.014944, train_accuracy 1, valid accuracy 0.7892
Epoch 197, CIFAR-10 Batch 3:  loss 0.019596, train_accuracy 1, valid accuracy 0.7888
Epoch 197, CIFAR-10 Batch 4:  loss 0.021267, train_accuracy 1, valid accuracy 0.7938
Epoch 197, CIFAR-10 Batch 5:  loss 0.013708, train_accuracy 1, valid accuracy 0.785
Epoch 198, CIFAR-10 Batch 1:  loss 0.023915, train_accuracy 1, valid accuracy 0.7926
Epoch 198, CIFAR-10 Batch 2:  loss 0.009832, train_accuracy 1, valid accuracy 0.79
Epoch 198, CIFAR-10 Batch 3:  loss 0.017356, train_accuracy 1, valid accuracy 0.7858
Epoch 198, CIFAR-10 Batch 4:  loss 0.016048, train_accuracy 1, valid accuracy 0.7918
Epoch 198, CIFAR-10 Batch 5:  loss 0.013858, train_accuracy 1, valid accuracy 0.7884
Epoch 199, CIFAR-10 Batch 1:  loss 0.021398, train_accuracy 1, valid accuracy 0.7904
Epoch 199, CIFAR-10 Batch 2:  loss 0.008405, train_accuracy 1, valid accuracy 0.7892
Epoch 199, CIFAR-10 Batch 3:  loss 0.019073, train_accuracy 1, valid accuracy 0.78
Epoch 199, CIFAR-10 Batch 4:  loss 0.033494, train_accuracy 1, valid accuracy 0.7828
Epoch 199, CIFAR-10 Batch 5:  loss 0.009217, train_accuracy 1, valid accuracy 0.7978
Epoch 200, CIFAR-10 Batch 1:  loss 0.023047, train_accuracy 1, valid accuracy 0.7934
Epoch 200, CIFAR-10 Batch 2:  loss 0.006376, train_accuracy 1, valid accuracy 0.7942
Epoch 200, CIFAR-10 Batch 3:  loss 0.022377, train_accuracy 1, valid accuracy 0.7816
Epoch 200, CIFAR-10 Batch 4:  loss 0.011276, train_accuracy 1, valid accuracy 0.7946
Epoch 200, CIFAR-10 Batch 5:  loss 0.021505, train_accuracy 1, valid accuracy 0.7754
Epoch 201, CIFAR-10 Batch 1:  loss 0.017343, train_accuracy 1, valid accuracy 0.7956
Epoch 201, CIFAR-10 Batch 2:  loss 0.015956, train_accuracy 1, valid accuracy 0.7882
Epoch 201, CIFAR-10 Batch 3:  loss 0.037355, train_accuracy 1, valid accuracy 0.7564
Epoch 201, CIFAR-10 Batch 4:  loss 0.018445, train_accuracy 1, valid accuracy 0.7878
Epoch 201, CIFAR-10 Batch 5:  loss 0.014702, train_accuracy 1, valid accuracy 0.7908
Epoch 202, CIFAR-10 Batch 1:  loss 0.015507, train_accuracy 1, valid accuracy 0.79
Epoch 202, CIFAR-10 Batch 2:  loss 0.008785, train_accuracy 1, valid accuracy 0.7862
Epoch 202, CIFAR-10 Batch 3:  loss 0.024725, train_accuracy 1, valid accuracy 0.7634
Epoch 202, CIFAR-10 Batch 4:  loss 0.017002, train_accuracy 1, valid accuracy 0.7936
Epoch 202, CIFAR-10 Batch 5:  loss 0.016980, train_accuracy 1, valid accuracy 0.7772
Epoch 203, CIFAR-10 Batch 1:  loss 0.012666, train_accuracy 1, valid accuracy 0.791
Epoch 203, CIFAR-10 Batch 2:  loss 0.012610, train_accuracy 1, valid accuracy 0.7804
Epoch 203, CIFAR-10 Batch 3:  loss 0.018706, train_accuracy 1, valid accuracy 0.7784
Epoch 203, CIFAR-10 Batch 4:  loss 0.012311, train_accuracy 1, valid accuracy 0.797
Epoch 203, CIFAR-10 Batch 5:  loss 0.022424, train_accuracy 1, valid accuracy 0.796
Epoch 204, CIFAR-10 Batch 1:  loss 0.016712, train_accuracy 1, valid accuracy 0.8076
Epoch 204, CIFAR-10 Batch 2:  loss 0.036430, train_accuracy 1, valid accuracy 0.7688
Epoch 204, CIFAR-10 Batch 3:  loss 0.016928, train_accuracy 1, valid accuracy 0.7824
Epoch 204, CIFAR-10 Batch 4:  loss 0.019275, train_accuracy 1, valid accuracy 0.7818
Epoch 204, CIFAR-10 Batch 5:  loss 0.013168, train_accuracy 1, valid accuracy 0.7862
Epoch 205, CIFAR-10 Batch 1:  loss 0.012212, train_accuracy 1, valid accuracy 0.7986
Epoch 205, CIFAR-10 Batch 2:  loss 0.007805, train_accuracy 1, valid accuracy 0.7872
Epoch 205, CIFAR-10 Batch 3:  loss 0.011740, train_accuracy 1, valid accuracy 0.787
Epoch 205, CIFAR-10 Batch 4:  loss 0.014641, train_accuracy 1, valid accuracy 0.7886
Epoch 205, CIFAR-10 Batch 5:  loss 0.011587, train_accuracy 1, valid accuracy 0.79
Epoch 206, CIFAR-10 Batch 1:  loss 0.016605, train_accuracy 1, valid accuracy 0.7864
Epoch 206, CIFAR-10 Batch 2:  loss 0.007706, train_accuracy 1, valid accuracy 0.7968
Epoch 206, CIFAR-10 Batch 3:  loss 0.011368, train_accuracy 1, valid accuracy 0.786
Epoch 206, CIFAR-10 Batch 4:  loss 0.025801, train_accuracy 1, valid accuracy 0.7934
Epoch 206, CIFAR-10 Batch 5:  loss 0.015560, train_accuracy 1, valid accuracy 0.781
Epoch 207, CIFAR-10 Batch 1:  loss 0.017779, train_accuracy 1, valid accuracy 0.7794
Epoch 207, CIFAR-10 Batch 2:  loss 0.008305, train_accuracy 1, valid accuracy 0.785
Epoch 207, CIFAR-10 Batch 3:  loss 0.013588, train_accuracy 1, valid accuracy 0.7692
Epoch 207, CIFAR-10 Batch 4:  loss 0.030694, train_accuracy 1, valid accuracy 0.7844
Epoch 207, CIFAR-10 Batch 5:  loss 0.007974, train_accuracy 1, valid accuracy 0.7782
Epoch 208, CIFAR-10 Batch 1:  loss 0.018181, train_accuracy 1, valid accuracy 0.7962
Epoch 208, CIFAR-10 Batch 2:  loss 0.010095, train_accuracy 1, valid accuracy 0.7868
Epoch 208, CIFAR-10 Batch 3:  loss 0.013439, train_accuracy 1, valid accuracy 0.7596
Epoch 208, CIFAR-10 Batch 4:  loss 0.012736, train_accuracy 1, valid accuracy 0.7856
Epoch 208, CIFAR-10 Batch 5:  loss 0.009724, train_accuracy 1, valid accuracy 0.7916
Epoch 209, CIFAR-10 Batch 1:  loss 0.018473, train_accuracy 1, valid accuracy 0.7888
Epoch 209, CIFAR-10 Batch 2:  loss 0.017094, train_accuracy 1, valid accuracy 0.7776
Epoch 209, CIFAR-10 Batch 3:  loss 0.016940, train_accuracy 1, valid accuracy 0.7772
Epoch 209, CIFAR-10 Batch 4:  loss 0.013741, train_accuracy 1, valid accuracy 0.799
Epoch 209, CIFAR-10 Batch 5:  loss 0.019128, train_accuracy 1, valid accuracy 0.7732
Epoch 210, CIFAR-10 Batch 1:  loss 0.010671, train_accuracy 1, valid accuracy 0.793
Epoch 210, CIFAR-10 Batch 2:  loss 0.012899, train_accuracy 1, valid accuracy 0.7916
Epoch 210, CIFAR-10 Batch 3:  loss 0.020090, train_accuracy 1, valid accuracy 0.7768
Epoch 210, CIFAR-10 Batch 4:  loss 0.026389, train_accuracy 1, valid accuracy 0.7796
Epoch 210, CIFAR-10 Batch 5:  loss 0.009829, train_accuracy 1, valid accuracy 0.789
Epoch 211, CIFAR-10 Batch 1:  loss 0.010259, train_accuracy 1, valid accuracy 0.7982
Epoch 211, CIFAR-10 Batch 2:  loss 0.008709, train_accuracy 1, valid accuracy 0.7822
Epoch 211, CIFAR-10 Batch 3:  loss 0.015747, train_accuracy 1, valid accuracy 0.7794
Epoch 211, CIFAR-10 Batch 4:  loss 0.012051, train_accuracy 1, valid accuracy 0.7978
Epoch 211, CIFAR-10 Batch 5:  loss 0.010362, train_accuracy 1, valid accuracy 0.7946
Epoch 212, CIFAR-10 Batch 1:  loss 0.018809, train_accuracy 1, valid accuracy 0.794
Epoch 212, CIFAR-10 Batch 2:  loss 0.010567, train_accuracy 1, valid accuracy 0.7946
Epoch 212, CIFAR-10 Batch 3:  loss 0.008539, train_accuracy 1, valid accuracy 0.7888
Epoch 212, CIFAR-10 Batch 4:  loss 0.013698, train_accuracy 1, valid accuracy 0.7972
Epoch 212, CIFAR-10 Batch 5:  loss 0.036382, train_accuracy 1, valid accuracy 0.759
Epoch 213, CIFAR-10 Batch 1:  loss 0.013316, train_accuracy 1, valid accuracy 0.79
Epoch 213, CIFAR-10 Batch 2:  loss 0.017202, train_accuracy 1, valid accuracy 0.7914
Epoch 213, CIFAR-10 Batch 3:  loss 0.013302, train_accuracy 1, valid accuracy 0.7788
Epoch 213, CIFAR-10 Batch 4:  loss 0.012021, train_accuracy 1, valid accuracy 0.797
Epoch 213, CIFAR-10 Batch 5:  loss 0.025058, train_accuracy 1, valid accuracy 0.7734
Epoch 214, CIFAR-10 Batch 1:  loss 0.016635, train_accuracy 1, valid accuracy 0.7898
Epoch 214, CIFAR-10 Batch 2:  loss 0.017989, train_accuracy 1, valid accuracy 0.78
Epoch 214, CIFAR-10 Batch 3:  loss 0.014254, train_accuracy 1, valid accuracy 0.773
Epoch 214, CIFAR-10 Batch 4:  loss 0.014185, train_accuracy 1, valid accuracy 0.7994
Epoch 214, CIFAR-10 Batch 5:  loss 0.020100, train_accuracy 1, valid accuracy 0.759
Epoch 215, CIFAR-10 Batch 1:  loss 0.017472, train_accuracy 1, valid accuracy 0.7796
Epoch 215, CIFAR-10 Batch 2:  loss 0.008781, train_accuracy 1, valid accuracy 0.785
Epoch 215, CIFAR-10 Batch 3:  loss 0.009478, train_accuracy 1, valid accuracy 0.7822
Epoch 215, CIFAR-10 Batch 4:  loss 0.030528, train_accuracy 1, valid accuracy 0.781
Epoch 215, CIFAR-10 Batch 5:  loss 0.017242, train_accuracy 1, valid accuracy 0.7818
Epoch 216, CIFAR-10 Batch 1:  loss 0.016529, train_accuracy 1, valid accuracy 0.7894
Epoch 216, CIFAR-10 Batch 2:  loss 0.018276, train_accuracy 1, valid accuracy 0.7832
Epoch 216, CIFAR-10 Batch 3:  loss 0.008096, train_accuracy 1, valid accuracy 0.7836
Epoch 216, CIFAR-10 Batch 4:  loss 0.007004, train_accuracy 1, valid accuracy 0.7842
Epoch 216, CIFAR-10 Batch 5:  loss 0.015671, train_accuracy 1, valid accuracy 0.7968
Epoch 217, CIFAR-10 Batch 1:  loss 0.016233, train_accuracy 1, valid accuracy 0.7892
Epoch 217, CIFAR-10 Batch 2:  loss 0.007890, train_accuracy 1, valid accuracy 0.7848
Epoch 217, CIFAR-10 Batch 3:  loss 0.012293, train_accuracy 1, valid accuracy 0.796
Epoch 217, CIFAR-10 Batch 4:  loss 0.022928, train_accuracy 1, valid accuracy 0.7772
Epoch 217, CIFAR-10 Batch 5:  loss 0.011427, train_accuracy 1, valid accuracy 0.7866
Epoch 218, CIFAR-10 Batch 1:  loss 0.011958, train_accuracy 1, valid accuracy 0.7996
Epoch 218, CIFAR-10 Batch 2:  loss 0.006884, train_accuracy 1, valid accuracy 0.7812
Epoch 218, CIFAR-10 Batch 3:  loss 0.010904, train_accuracy 1, valid accuracy 0.7858
Epoch 218, CIFAR-10 Batch 4:  loss 0.012114, train_accuracy 1, valid accuracy 0.7886
Epoch 218, CIFAR-10 Batch 5:  loss 0.010252, train_accuracy 1, valid accuracy 0.7992
Epoch 219, CIFAR-10 Batch 1:  loss 0.009002, train_accuracy 1, valid accuracy 0.7978
Epoch 219, CIFAR-10 Batch 2:  loss 0.010806, train_accuracy 1, valid accuracy 0.7916
Epoch 219, CIFAR-10 Batch 3:  loss 0.010085, train_accuracy 1, valid accuracy 0.7712
Epoch 219, CIFAR-10 Batch 4:  loss 0.013100, train_accuracy 1, valid accuracy 0.7856
Epoch 219, CIFAR-10 Batch 5:  loss 0.011592, train_accuracy 1, valid accuracy 0.788
Epoch 220, CIFAR-10 Batch 1:  loss 0.013366, train_accuracy 1, valid accuracy 0.802
Epoch 220, CIFAR-10 Batch 2:  loss 0.007778, train_accuracy 1, valid accuracy 0.7898
Epoch 220, CIFAR-10 Batch 3:  loss 0.022938, train_accuracy 1, valid accuracy 0.7834
Epoch 220, CIFAR-10 Batch 4:  loss 0.008887, train_accuracy 1, valid accuracy 0.8026
Epoch 220, CIFAR-10 Batch 5:  loss 0.007260, train_accuracy 1, valid accuracy 0.7964
Epoch 221, CIFAR-10 Batch 1:  loss 0.012810, train_accuracy 1, valid accuracy 0.7952
Epoch 221, CIFAR-10 Batch 2:  loss 0.009804, train_accuracy 1, valid accuracy 0.7788
Epoch 221, CIFAR-10 Batch 3:  loss 0.009673, train_accuracy 1, valid accuracy 0.793
Epoch 221, CIFAR-10 Batch 4:  loss 0.010440, train_accuracy 1, valid accuracy 0.7964
Epoch 221, CIFAR-10 Batch 5:  loss 0.008504, train_accuracy 1, valid accuracy 0.7874
Epoch 222, CIFAR-10 Batch 1:  loss 0.012226, train_accuracy 1, valid accuracy 0.7998
Epoch 222, CIFAR-10 Batch 2:  loss 0.004415, train_accuracy 1, valid accuracy 0.7926
Epoch 222, CIFAR-10 Batch 3:  loss 0.013573, train_accuracy 1, valid accuracy 0.7772
Epoch 222, CIFAR-10 Batch 4:  loss 0.014033, train_accuracy 1, valid accuracy 0.7906
Epoch 222, CIFAR-10 Batch 5:  loss 0.013950, train_accuracy 1, valid accuracy 0.7872
Epoch 223, CIFAR-10 Batch 1:  loss 0.013890, train_accuracy 1, valid accuracy 0.8022
Epoch 223, CIFAR-10 Batch 2:  loss 0.008250, train_accuracy 1, valid accuracy 0.7904
Epoch 223, CIFAR-10 Batch 3:  loss 0.008443, train_accuracy 1, valid accuracy 0.7864
Epoch 223, CIFAR-10 Batch 4:  loss 0.013319, train_accuracy 1, valid accuracy 0.7946
Epoch 223, CIFAR-10 Batch 5:  loss 0.019221, train_accuracy 1, valid accuracy 0.7862
Epoch 224, CIFAR-10 Batch 1:  loss 0.011528, train_accuracy 1, valid accuracy 0.7914
Epoch 224, CIFAR-10 Batch 2:  loss 0.006423, train_accuracy 1, valid accuracy 0.789
Epoch 224, CIFAR-10 Batch 3:  loss 0.007512, train_accuracy 1, valid accuracy 0.785
Epoch 224, CIFAR-10 Batch 4:  loss 0.023307, train_accuracy 1, valid accuracy 0.7936
Epoch 224, CIFAR-10 Batch 5:  loss 0.030842, train_accuracy 1, valid accuracy 0.7814
Epoch 225, CIFAR-10 Batch 1:  loss 0.011852, train_accuracy 1, valid accuracy 0.7966
Epoch 225, CIFAR-10 Batch 2:  loss 0.005585, train_accuracy 1, valid accuracy 0.7924
Epoch 225, CIFAR-10 Batch 3:  loss 0.006353, train_accuracy 1, valid accuracy 0.7812
Epoch 225, CIFAR-10 Batch 4:  loss 0.039229, train_accuracy 0.975, valid accuracy 0.7842
Epoch 225, CIFAR-10 Batch 5:  loss 0.006760, train_accuracy 1, valid accuracy 0.7976
Epoch 226, CIFAR-10 Batch 1:  loss 0.011248, train_accuracy 1, valid accuracy 0.791
Epoch 226, CIFAR-10 Batch 2:  loss 0.005107, train_accuracy 1, valid accuracy 0.791
Epoch 226, CIFAR-10 Batch 3:  loss 0.015669, train_accuracy 1, valid accuracy 0.7848
Epoch 226, CIFAR-10 Batch 4:  loss 0.008444, train_accuracy 1, valid accuracy 0.7896
Epoch 226, CIFAR-10 Batch 5:  loss 0.014511, train_accuracy 1, valid accuracy 0.782
Epoch 227, CIFAR-10 Batch 1:  loss 0.015052, train_accuracy 1, valid accuracy 0.799
Epoch 227, CIFAR-10 Batch 2:  loss 0.005982, train_accuracy 1, valid accuracy 0.7842
Epoch 227, CIFAR-10 Batch 3:  loss 0.010661, train_accuracy 1, valid accuracy 0.7848
Epoch 227, CIFAR-10 Batch 4:  loss 0.011114, train_accuracy 1, valid accuracy 0.7828
Epoch 227, CIFAR-10 Batch 5:  loss 0.007318, train_accuracy 1, valid accuracy 0.7944
Epoch 228, CIFAR-10 Batch 1:  loss 0.012025, train_accuracy 1, valid accuracy 0.7902
Epoch 228, CIFAR-10 Batch 2:  loss 0.013757, train_accuracy 1, valid accuracy 0.7896
Epoch 228, CIFAR-10 Batch 3:  loss 0.013932, train_accuracy 1, valid accuracy 0.7708
Epoch 228, CIFAR-10 Batch 4:  loss 0.009094, train_accuracy 1, valid accuracy 0.796
Epoch 228, CIFAR-10 Batch 5:  loss 0.017097, train_accuracy 1, valid accuracy 0.7936
Epoch 229, CIFAR-10 Batch 1:  loss 0.010690, train_accuracy 1, valid accuracy 0.799
Epoch 229, CIFAR-10 Batch 2:  loss 0.006436, train_accuracy 1, valid accuracy 0.7972
Epoch 229, CIFAR-10 Batch 3:  loss 0.005228, train_accuracy 1, valid accuracy 0.7864
Epoch 229, CIFAR-10 Batch 4:  loss 0.008009, train_accuracy 1, valid accuracy 0.7882
Epoch 229, CIFAR-10 Batch 5:  loss 0.018767, train_accuracy 1, valid accuracy 0.7592
Epoch 230, CIFAR-10 Batch 1:  loss 0.019588, train_accuracy 1, valid accuracy 0.788
Epoch 230, CIFAR-10 Batch 2:  loss 0.005067, train_accuracy 1, valid accuracy 0.7972
Epoch 230, CIFAR-10 Batch 3:  loss 0.012734, train_accuracy 1, valid accuracy 0.7824
Epoch 230, CIFAR-10 Batch 4:  loss 0.009848, train_accuracy 1, valid accuracy 0.79
Epoch 230, CIFAR-10 Batch 5:  loss 0.006088, train_accuracy 1, valid accuracy 0.795
Epoch 231, CIFAR-10 Batch 1:  loss 0.013645, train_accuracy 1, valid accuracy 0.797
Epoch 231, CIFAR-10 Batch 2:  loss 0.008911, train_accuracy 1, valid accuracy 0.7734
Epoch 231, CIFAR-10 Batch 3:  loss 0.013898, train_accuracy 1, valid accuracy 0.7908
Epoch 231, CIFAR-10 Batch 4:  loss 0.006219, train_accuracy 1, valid accuracy 0.799
Epoch 231, CIFAR-10 Batch 5:  loss 0.009377, train_accuracy 1, valid accuracy 0.7906
Epoch 232, CIFAR-10 Batch 1:  loss 0.012435, train_accuracy 1, valid accuracy 0.7902
Epoch 232, CIFAR-10 Batch 2:  loss 0.006399, train_accuracy 1, valid accuracy 0.7952
Epoch 232, CIFAR-10 Batch 3:  loss 0.005835, train_accuracy 1, valid accuracy 0.7916
Epoch 232, CIFAR-10 Batch 4:  loss 0.007505, train_accuracy 1, valid accuracy 0.8004
Epoch 232, CIFAR-10 Batch 5:  loss 0.016445, train_accuracy 1, valid accuracy 0.7762
Epoch 233, CIFAR-10 Batch 1:  loss 0.015440, train_accuracy 1, valid accuracy 0.7856
Epoch 233, CIFAR-10 Batch 2:  loss 0.004423, train_accuracy 1, valid accuracy 0.8056
Epoch 233, CIFAR-10 Batch 3:  loss 0.016805, train_accuracy 1, valid accuracy 0.7832
Epoch 233, CIFAR-10 Batch 4:  loss 0.008069, train_accuracy 1, valid accuracy 0.7954
Epoch 233, CIFAR-10 Batch 5:  loss 0.007734, train_accuracy 1, valid accuracy 0.7972
Epoch 234, CIFAR-10 Batch 1:  loss 0.008561, train_accuracy 1, valid accuracy 0.8022
Epoch 234, CIFAR-10 Batch 2:  loss 0.004427, train_accuracy 1, valid accuracy 0.8048
Epoch 234, CIFAR-10 Batch 3:  loss 0.009219, train_accuracy 1, valid accuracy 0.795
Epoch 234, CIFAR-10 Batch 4:  loss 0.005873, train_accuracy 1, valid accuracy 0.7984
Epoch 234, CIFAR-10 Batch 5:  loss 0.008918, train_accuracy 1, valid accuracy 0.7996
Epoch 235, CIFAR-10 Batch 1:  loss 0.009762, train_accuracy 1, valid accuracy 0.8002
Epoch 235, CIFAR-10 Batch 2:  loss 0.004219, train_accuracy 1, valid accuracy 0.7948
Epoch 235, CIFAR-10 Batch 3:  loss 0.012786, train_accuracy 1, valid accuracy 0.786
Epoch 235, CIFAR-10 Batch 4:  loss 0.007831, train_accuracy 1, valid accuracy 0.7956
Epoch 235, CIFAR-10 Batch 5:  loss 0.012944, train_accuracy 1, valid accuracy 0.7886
Epoch 236, CIFAR-10 Batch 1:  loss 0.007875, train_accuracy 1, valid accuracy 0.8008
Epoch 236, CIFAR-10 Batch 2:  loss 0.003279, train_accuracy 1, valid accuracy 0.7902
Epoch 236, CIFAR-10 Batch 3:  loss 0.017131, train_accuracy 1, valid accuracy 0.7844
Epoch 236, CIFAR-10 Batch 4:  loss 0.007557, train_accuracy 1, valid accuracy 0.8034
Epoch 236, CIFAR-10 Batch 5:  loss 0.008342, train_accuracy 1, valid accuracy 0.7904
Epoch 237, CIFAR-10 Batch 1:  loss 0.011877, train_accuracy 1, valid accuracy 0.8046
Epoch 237, CIFAR-10 Batch 2:  loss 0.005485, train_accuracy 1, valid accuracy 0.7888
Epoch 237, CIFAR-10 Batch 3:  loss 0.007856, train_accuracy 1, valid accuracy 0.7864
Epoch 237, CIFAR-10 Batch 4:  loss 0.004300, train_accuracy 1, valid accuracy 0.7894
Epoch 237, CIFAR-10 Batch 5:  loss 0.006127, train_accuracy 1, valid accuracy 0.7924
Epoch 238, CIFAR-10 Batch 1:  loss 0.009051, train_accuracy 1, valid accuracy 0.7922
Epoch 238, CIFAR-10 Batch 2:  loss 0.004912, train_accuracy 1, valid accuracy 0.7932
Epoch 238, CIFAR-10 Batch 3:  loss 0.008693, train_accuracy 1, valid accuracy 0.7884
Epoch 238, CIFAR-10 Batch 4:  loss 0.005811, train_accuracy 1, valid accuracy 0.7998
Epoch 238, CIFAR-10 Batch 5:  loss 0.004488, train_accuracy 1, valid accuracy 0.7984
Epoch 239, CIFAR-10 Batch 1:  loss 0.005831, train_accuracy 1, valid accuracy 0.796
Epoch 239, CIFAR-10 Batch 2:  loss 0.009850, train_accuracy 1, valid accuracy 0.7926
Epoch 239, CIFAR-10 Batch 3:  loss 0.014095, train_accuracy 1, valid accuracy 0.7866
Epoch 239, CIFAR-10 Batch 4:  loss 0.006683, train_accuracy 1, valid accuracy 0.796
Epoch 239, CIFAR-10 Batch 5:  loss 0.009608, train_accuracy 1, valid accuracy 0.7966
Epoch 240, CIFAR-10 Batch 1:  loss 0.002836, train_accuracy 1, valid accuracy 0.801
Epoch 240, CIFAR-10 Batch 2:  loss 0.003680, train_accuracy 1, valid accuracy 0.8008
Epoch 240, CIFAR-10 Batch 3:  loss 0.013345, train_accuracy 1, valid accuracy 0.7896
Epoch 240, CIFAR-10 Batch 4:  loss 0.006605, train_accuracy 1, valid accuracy 0.7944
Epoch 240, CIFAR-10 Batch 5:  loss 0.007937, train_accuracy 1, valid accuracy 0.7906
Epoch 241, CIFAR-10 Batch 1:  loss 0.007459, train_accuracy 1, valid accuracy 0.7976
Epoch 241, CIFAR-10 Batch 2:  loss 0.005688, train_accuracy 1, valid accuracy 0.8008
Epoch 241, CIFAR-10 Batch 3:  loss 0.007846, train_accuracy 1, valid accuracy 0.7828
Epoch 241, CIFAR-10 Batch 4:  loss 0.007755, train_accuracy 1, valid accuracy 0.7944
Epoch 241, CIFAR-10 Batch 5:  loss 0.025264, train_accuracy 1, valid accuracy 0.7696
Epoch 242, CIFAR-10 Batch 1:  loss 0.008215, train_accuracy 1, valid accuracy 0.7936
Epoch 242, CIFAR-10 Batch 2:  loss 0.003010, train_accuracy 1, valid accuracy 0.7968
Epoch 242, CIFAR-10 Batch 3:  loss 0.013690, train_accuracy 1, valid accuracy 0.7866
Epoch 242, CIFAR-10 Batch 4:  loss 0.003534, train_accuracy 1, valid accuracy 0.8
Epoch 242, CIFAR-10 Batch 5:  loss 0.017567, train_accuracy 1, valid accuracy 0.7822
Epoch 243, CIFAR-10 Batch 1:  loss 0.005637, train_accuracy 1, valid accuracy 0.7982
Epoch 243, CIFAR-10 Batch 2:  loss 0.018143, train_accuracy 1, valid accuracy 0.7926
Epoch 243, CIFAR-10 Batch 3:  loss 0.010276, train_accuracy 1, valid accuracy 0.7916
Epoch 243, CIFAR-10 Batch 4:  loss 0.002960, train_accuracy 1, valid accuracy 0.7996
Epoch 243, CIFAR-10 Batch 5:  loss 0.006071, train_accuracy 1, valid accuracy 0.7992
Epoch 244, CIFAR-10 Batch 1:  loss 0.003633, train_accuracy 1, valid accuracy 0.798
Epoch 244, CIFAR-10 Batch 2:  loss 0.002820, train_accuracy 1, valid accuracy 0.7932
Epoch 244, CIFAR-10 Batch 3:  loss 0.006547, train_accuracy 1, valid accuracy 0.798
Epoch 244, CIFAR-10 Batch 4:  loss 0.003222, train_accuracy 1, valid accuracy 0.7858
Epoch 244, CIFAR-10 Batch 5:  loss 0.004037, train_accuracy 1, valid accuracy 0.7968
Epoch 245, CIFAR-10 Batch 1:  loss 0.007323, train_accuracy 1, valid accuracy 0.799
Epoch 245, CIFAR-10 Batch 2:  loss 0.004845, train_accuracy 1, valid accuracy 0.7984
Epoch 245, CIFAR-10 Batch 3:  loss 0.010048, train_accuracy 1, valid accuracy 0.7768
Epoch 245, CIFAR-10 Batch 4:  loss 0.004402, train_accuracy 1, valid accuracy 0.8016
Epoch 245, CIFAR-10 Batch 5:  loss 0.005615, train_accuracy 1, valid accuracy 0.7862
Epoch 246, CIFAR-10 Batch 1:  loss 0.003429, train_accuracy 1, valid accuracy 0.7964
Epoch 246, CIFAR-10 Batch 2:  loss 0.005633, train_accuracy 1, valid accuracy 0.7988
Epoch 246, CIFAR-10 Batch 3:  loss 0.007697, train_accuracy 1, valid accuracy 0.796
Epoch 246, CIFAR-10 Batch 4:  loss 0.006220, train_accuracy 1, valid accuracy 0.7906
Epoch 246, CIFAR-10 Batch 5:  loss 0.004322, train_accuracy 1, valid accuracy 0.7784
Epoch 247, CIFAR-10 Batch 1:  loss 0.006324, train_accuracy 1, valid accuracy 0.7944
Epoch 247, CIFAR-10 Batch 2:  loss 0.002239, train_accuracy 1, valid accuracy 0.805
Epoch 247, CIFAR-10 Batch 3:  loss 0.010528, train_accuracy 1, valid accuracy 0.807
Epoch 247, CIFAR-10 Batch 4:  loss 0.008308, train_accuracy 1, valid accuracy 0.8046
Epoch 247, CIFAR-10 Batch 5:  loss 0.005701, train_accuracy 1, valid accuracy 0.8034
Epoch 248, CIFAR-10 Batch 1:  loss 0.011584, train_accuracy 1, valid accuracy 0.7894
Epoch 248, CIFAR-10 Batch 2:  loss 0.007129, train_accuracy 1, valid accuracy 0.7926
Epoch 248, CIFAR-10 Batch 3:  loss 0.010261, train_accuracy 1, valid accuracy 0.798
Epoch 248, CIFAR-10 Batch 4:  loss 0.002781, train_accuracy 1, valid accuracy 0.8014
Epoch 248, CIFAR-10 Batch 5:  loss 0.007034, train_accuracy 1, valid accuracy 0.7998
Epoch 249, CIFAR-10 Batch 1:  loss 0.003895, train_accuracy 1, valid accuracy 0.8076
Epoch 249, CIFAR-10 Batch 2:  loss 0.009963, train_accuracy 1, valid accuracy 0.7944
Epoch 249, CIFAR-10 Batch 3:  loss 0.008382, train_accuracy 1, valid accuracy 0.8012
Epoch 249, CIFAR-10 Batch 4:  loss 0.005027, train_accuracy 1, valid accuracy 0.7986
Epoch 249, CIFAR-10 Batch 5:  loss 0.002859, train_accuracy 1, valid accuracy 0.8024
Epoch 250, CIFAR-10 Batch 1:  loss 0.003276, train_accuracy 1, valid accuracy 0.7972
Epoch 250, CIFAR-10 Batch 2:  loss 0.005267, train_accuracy 1, valid accuracy 0.7962
Epoch 250, CIFAR-10 Batch 3:  loss 0.006534, train_accuracy 1, valid accuracy 0.7756
Epoch 250, CIFAR-10 Batch 4:  loss 0.003019, train_accuracy 1, valid accuracy 0.799
Epoch 250, CIFAR-10 Batch 5:  loss 0.003970, train_accuracy 1, valid accuracy 0.7932
Epoch 251, CIFAR-10 Batch 1:  loss 0.004527, train_accuracy 1, valid accuracy 0.8068
Epoch 251, CIFAR-10 Batch 2:  loss 0.002281, train_accuracy 1, valid accuracy 0.7946
Epoch 251, CIFAR-10 Batch 3:  loss 0.007804, train_accuracy 1, valid accuracy 0.7916
Epoch 251, CIFAR-10 Batch 4:  loss 0.011874, train_accuracy 1, valid accuracy 0.7986
Epoch 251, CIFAR-10 Batch 5:  loss 0.015506, train_accuracy 1, valid accuracy 0.781
Epoch 252, CIFAR-10 Batch 1:  loss 0.005943, train_accuracy 1, valid accuracy 0.7932
Epoch 252, CIFAR-10 Batch 2:  loss 0.008019, train_accuracy 1, valid accuracy 0.7934
Epoch 252, CIFAR-10 Batch 3:  loss 0.007399, train_accuracy 1, valid accuracy 0.7854
Epoch 252, CIFAR-10 Batch 4:  loss 0.002959, train_accuracy 1, valid accuracy 0.7926
Epoch 252, CIFAR-10 Batch 5:  loss 0.022994, train_accuracy 1, valid accuracy 0.7744
Epoch 253, CIFAR-10 Batch 1:  loss 0.005579, train_accuracy 1, valid accuracy 0.7976
Epoch 253, CIFAR-10 Batch 2:  loss 0.006365, train_accuracy 1, valid accuracy 0.7954
Epoch 253, CIFAR-10 Batch 3:  loss 0.006480, train_accuracy 1, valid accuracy 0.7904
Epoch 253, CIFAR-10 Batch 4:  loss 0.005236, train_accuracy 1, valid accuracy 0.7984
Epoch 253, CIFAR-10 Batch 5:  loss 0.010050, train_accuracy 1, valid accuracy 0.7856
Epoch 254, CIFAR-10 Batch 1:  loss 0.006715, train_accuracy 1, valid accuracy 0.7978
Epoch 254, CIFAR-10 Batch 2:  loss 0.005588, train_accuracy 1, valid accuracy 0.7934
Epoch 254, CIFAR-10 Batch 3:  loss 0.004706, train_accuracy 1, valid accuracy 0.7868
Epoch 254, CIFAR-10 Batch 4:  loss 0.006711, train_accuracy 1, valid accuracy 0.7914
Epoch 254, CIFAR-10 Batch 5:  loss 0.007918, train_accuracy 1, valid accuracy 0.7916
Epoch 255, CIFAR-10 Batch 1:  loss 0.004618, train_accuracy 1, valid accuracy 0.791
Epoch 255, CIFAR-10 Batch 2:  loss 0.302290, train_accuracy 0.95, valid accuracy 0.6868
Epoch 255, CIFAR-10 Batch 3:  loss 0.014686, train_accuracy 1, valid accuracy 0.7924
Epoch 255, CIFAR-10 Batch 4:  loss 0.018079, train_accuracy 1, valid accuracy 0.783
Epoch 255, CIFAR-10 Batch 5:  loss 0.019938, train_accuracy 1, valid accuracy 0.776
Epoch 256, CIFAR-10 Batch 1:  loss 0.004401, train_accuracy 1, valid accuracy 0.7922
Epoch 256, CIFAR-10 Batch 2:  loss 0.004885, train_accuracy 1, valid accuracy 0.799
Epoch 256, CIFAR-10 Batch 3:  loss 0.005276, train_accuracy 1, valid accuracy 0.7912
Epoch 256, CIFAR-10 Batch 4:  loss 0.001968, train_accuracy 1, valid accuracy 0.801
Epoch 256, CIFAR-10 Batch 5:  loss 0.013652, train_accuracy 1, valid accuracy 0.7836
Epoch 257, CIFAR-10 Batch 1:  loss 0.002710, train_accuracy 1, valid accuracy 0.7982
Epoch 257, CIFAR-10 Batch 2:  loss 0.003147, train_accuracy 1, valid accuracy 0.7908
Epoch 257, CIFAR-10 Batch 3:  loss 0.005942, train_accuracy 1, valid accuracy 0.7862
Epoch 257, CIFAR-10 Batch 4:  loss 0.004083, train_accuracy 1, valid accuracy 0.7922
Epoch 257, CIFAR-10 Batch 5:  loss 0.009339, train_accuracy 1, valid accuracy 0.7926
Epoch 258, CIFAR-10 Batch 1:  loss 0.002461, train_accuracy 1, valid accuracy 0.7914
Epoch 258, CIFAR-10 Batch 2:  loss 0.002954, train_accuracy 1, valid accuracy 0.7996
Epoch 258, CIFAR-10 Batch 3:  loss 0.007255, train_accuracy 1, valid accuracy 0.7928
Epoch 258, CIFAR-10 Batch 4:  loss 0.006713, train_accuracy 1, valid accuracy 0.788
Epoch 258, CIFAR-10 Batch 5:  loss 0.004564, train_accuracy 1, valid accuracy 0.7966
Epoch 259, CIFAR-10 Batch 1:  loss 0.004381, train_accuracy 1, valid accuracy 0.8032
Epoch 259, CIFAR-10 Batch 2:  loss 0.003492, train_accuracy 1, valid accuracy 0.8016
Epoch 259, CIFAR-10 Batch 3:  loss 0.012967, train_accuracy 1, valid accuracy 0.7866
Epoch 259, CIFAR-10 Batch 4:  loss 0.005202, train_accuracy 1, valid accuracy 0.7988
Epoch 259, CIFAR-10 Batch 5:  loss 0.010670, train_accuracy 1, valid accuracy 0.7916
Epoch 260, CIFAR-10 Batch 1:  loss 0.002863, train_accuracy 1, valid accuracy 0.795
Epoch 260, CIFAR-10 Batch 2:  loss 0.003065, train_accuracy 1, valid accuracy 0.7968
Epoch 260, CIFAR-10 Batch 3:  loss 0.006599, train_accuracy 1, valid accuracy 0.7854
Epoch 260, CIFAR-10 Batch 4:  loss 0.005129, train_accuracy 1, valid accuracy 0.796
Epoch 260, CIFAR-10 Batch 5:  loss 0.007810, train_accuracy 1, valid accuracy 0.799
Epoch 261, CIFAR-10 Batch 1:  loss 0.001754, train_accuracy 1, valid accuracy 0.803
Epoch 261, CIFAR-10 Batch 2:  loss 0.002262, train_accuracy 1, valid accuracy 0.81
Epoch 261, CIFAR-10 Batch 3:  loss 0.009517, train_accuracy 1, valid accuracy 0.7944
Epoch 261, CIFAR-10 Batch 4:  loss 0.004899, train_accuracy 1, valid accuracy 0.8018
Epoch 261, CIFAR-10 Batch 5:  loss 0.003041, train_accuracy 1, valid accuracy 0.8016
Epoch 262, CIFAR-10 Batch 1:  loss 0.003549, train_accuracy 1, valid accuracy 0.7998
Epoch 262, CIFAR-10 Batch 2:  loss 0.003627, train_accuracy 1, valid accuracy 0.7958
Epoch 262, CIFAR-10 Batch 3:  loss 0.008949, train_accuracy 1, valid accuracy 0.7962
Epoch 262, CIFAR-10 Batch 4:  loss 0.007378, train_accuracy 1, valid accuracy 0.7924
Epoch 262, CIFAR-10 Batch 5:  loss 0.008971, train_accuracy 1, valid accuracy 0.7812
Epoch 263, CIFAR-10 Batch 1:  loss 0.004232, train_accuracy 1, valid accuracy 0.7924
Epoch 263, CIFAR-10 Batch 2:  loss 0.003940, train_accuracy 1, valid accuracy 0.7958
Epoch 263, CIFAR-10 Batch 3:  loss 0.006807, train_accuracy 1, valid accuracy 0.7916
Epoch 263, CIFAR-10 Batch 4:  loss 0.015491, train_accuracy 1, valid accuracy 0.7956
Epoch 263, CIFAR-10 Batch 5:  loss 0.003343, train_accuracy 1, valid accuracy 0.7958
Epoch 264, CIFAR-10 Batch 1:  loss 0.003680, train_accuracy 1, valid accuracy 0.791
Epoch 264, CIFAR-10 Batch 2:  loss 0.006757, train_accuracy 1, valid accuracy 0.7912
Epoch 264, CIFAR-10 Batch 3:  loss 0.014176, train_accuracy 1, valid accuracy 0.7928
Epoch 264, CIFAR-10 Batch 4:  loss 0.009943, train_accuracy 1, valid accuracy 0.8012
Epoch 264, CIFAR-10 Batch 5:  loss 0.006472, train_accuracy 1, valid accuracy 0.7864
Epoch 265, CIFAR-10 Batch 1:  loss 0.004852, train_accuracy 1, valid accuracy 0.7986
Epoch 265, CIFAR-10 Batch 2:  loss 0.003113, train_accuracy 1, valid accuracy 0.7904
Epoch 265, CIFAR-10 Batch 3:  loss 0.013226, train_accuracy 1, valid accuracy 0.7952
Epoch 265, CIFAR-10 Batch 4:  loss 0.007391, train_accuracy 1, valid accuracy 0.7918
Epoch 265, CIFAR-10 Batch 5:  loss 0.002689, train_accuracy 1, valid accuracy 0.7922
Epoch 266, CIFAR-10 Batch 1:  loss 0.002954, train_accuracy 1, valid accuracy 0.7976
Epoch 266, CIFAR-10 Batch 2:  loss 0.004246, train_accuracy 1, valid accuracy 0.7988
Epoch 266, CIFAR-10 Batch 3:  loss 0.008772, train_accuracy 1, valid accuracy 0.7912
Epoch 266, CIFAR-10 Batch 4:  loss 0.012804, train_accuracy 1, valid accuracy 0.7848
Epoch 266, CIFAR-10 Batch 5:  loss 0.001736, train_accuracy 1, valid accuracy 0.7966
Epoch 267, CIFAR-10 Batch 1:  loss 0.002005, train_accuracy 1, valid accuracy 0.7988
Epoch 267, CIFAR-10 Batch 2:  loss 0.006315, train_accuracy 1, valid accuracy 0.8008
Epoch 267, CIFAR-10 Batch 3:  loss 0.002961, train_accuracy 1, valid accuracy 0.7998
Epoch 267, CIFAR-10 Batch 4:  loss 0.004228, train_accuracy 1, valid accuracy 0.7996
Epoch 267, CIFAR-10 Batch 5:  loss 0.002868, train_accuracy 1, valid accuracy 0.7934
Epoch 268, CIFAR-10 Batch 1:  loss 0.006895, train_accuracy 1, valid accuracy 0.8002
Epoch 268, CIFAR-10 Batch 2:  loss 0.005426, train_accuracy 1, valid accuracy 0.7782
Epoch 268, CIFAR-10 Batch 3:  loss 0.004754, train_accuracy 1, valid accuracy 0.797
Epoch 268, CIFAR-10 Batch 4:  loss 0.002349, train_accuracy 1, valid accuracy 0.797
Epoch 268, CIFAR-10 Batch 5:  loss 0.007663, train_accuracy 1, valid accuracy 0.7798
Epoch 269, CIFAR-10 Batch 1:  loss 0.007454, train_accuracy 1, valid accuracy 0.7992
Epoch 269, CIFAR-10 Batch 2:  loss 0.002827, train_accuracy 1, valid accuracy 0.7948
Epoch 269, CIFAR-10 Batch 3:  loss 0.009348, train_accuracy 1, valid accuracy 0.7868
Epoch 269, CIFAR-10 Batch 4:  loss 0.005343, train_accuracy 1, valid accuracy 0.7912
Epoch 269, CIFAR-10 Batch 5:  loss 0.001812, train_accuracy 1, valid accuracy 0.8012
Epoch 270, CIFAR-10 Batch 1:  loss 0.004295, train_accuracy 1, valid accuracy 0.7976
Epoch 270, CIFAR-10 Batch 2:  loss 0.005398, train_accuracy 1, valid accuracy 0.7918
Epoch 270, CIFAR-10 Batch 3:  loss 0.002119, train_accuracy 1, valid accuracy 0.7892
Epoch 270, CIFAR-10 Batch 4:  loss 0.004449, train_accuracy 1, valid accuracy 0.7992
Epoch 270, CIFAR-10 Batch 5:  loss 0.004162, train_accuracy 1, valid accuracy 0.7952
Epoch 271, CIFAR-10 Batch 1:  loss 0.006403, train_accuracy 1, valid accuracy 0.795
Epoch 271, CIFAR-10 Batch 2:  loss 0.004564, train_accuracy 1, valid accuracy 0.791
Epoch 271, CIFAR-10 Batch 3:  loss 0.005282, train_accuracy 1, valid accuracy 0.7942
Epoch 271, CIFAR-10 Batch 4:  loss 0.003873, train_accuracy 1, valid accuracy 0.7988
Epoch 271, CIFAR-10 Batch 5:  loss 0.003321, train_accuracy 1, valid accuracy 0.8016
Epoch 272, CIFAR-10 Batch 1:  loss 0.006888, train_accuracy 1, valid accuracy 0.7774
Epoch 272, CIFAR-10 Batch 2:  loss 0.004139, train_accuracy 1, valid accuracy 0.7962
Epoch 272, CIFAR-10 Batch 3:  loss 0.011524, train_accuracy 1, valid accuracy 0.7788
Epoch 272, CIFAR-10 Batch 4:  loss 0.005966, train_accuracy 1, valid accuracy 0.7884
Epoch 272, CIFAR-10 Batch 5:  loss 0.003953, train_accuracy 1, valid accuracy 0.787
Epoch 273, CIFAR-10 Batch 1:  loss 0.010871, train_accuracy 1, valid accuracy 0.7918
Epoch 273, CIFAR-10 Batch 2:  loss 0.002867, train_accuracy 1, valid accuracy 0.8072
Epoch 273, CIFAR-10 Batch 3:  loss 0.002937, train_accuracy 1, valid accuracy 0.791
Epoch 273, CIFAR-10 Batch 4:  loss 0.005027, train_accuracy 1, valid accuracy 0.7894
Epoch 273, CIFAR-10 Batch 5:  loss 0.004018, train_accuracy 1, valid accuracy 0.7866
Epoch 274, CIFAR-10 Batch 1:  loss 0.009636, train_accuracy 1, valid accuracy 0.7936
Epoch 274, CIFAR-10 Batch 2:  loss 0.010037, train_accuracy 1, valid accuracy 0.7922
Epoch 274, CIFAR-10 Batch 3:  loss 0.004246, train_accuracy 1, valid accuracy 0.7964
Epoch 274, CIFAR-10 Batch 4:  loss 0.007105, train_accuracy 1, valid accuracy 0.7968
Epoch 274, CIFAR-10 Batch 5:  loss 0.001970, train_accuracy 1, valid accuracy 0.7978
Epoch 275, CIFAR-10 Batch 1:  loss 0.003770, train_accuracy 1, valid accuracy 0.8014
Epoch 275, CIFAR-10 Batch 2:  loss 0.002059, train_accuracy 1, valid accuracy 0.7942
Epoch 275, CIFAR-10 Batch 3:  loss 0.008010, train_accuracy 1, valid accuracy 0.787
Epoch 275, CIFAR-10 Batch 4:  loss 0.003802, train_accuracy 1, valid accuracy 0.8
Epoch 275, CIFAR-10 Batch 5:  loss 0.009989, train_accuracy 1, valid accuracy 0.7934
Epoch 276, CIFAR-10 Batch 1:  loss 0.005759, train_accuracy 1, valid accuracy 0.7962
Epoch 276, CIFAR-10 Batch 2:  loss 0.002973, train_accuracy 1, valid accuracy 0.7974
Epoch 276, CIFAR-10 Batch 3:  loss 0.003792, train_accuracy 1, valid accuracy 0.7924
Epoch 276, CIFAR-10 Batch 4:  loss 0.008732, train_accuracy 1, valid accuracy 0.7988
Epoch 276, CIFAR-10 Batch 5:  loss 0.009361, train_accuracy 1, valid accuracy 0.785
Epoch 277, CIFAR-10 Batch 1:  loss 0.003298, train_accuracy 1, valid accuracy 0.807
Epoch 277, CIFAR-10 Batch 2:  loss 0.003368, train_accuracy 1, valid accuracy 0.8034
Epoch 277, CIFAR-10 Batch 3:  loss 0.003798, train_accuracy 1, valid accuracy 0.8026
Epoch 277, CIFAR-10 Batch 4:  loss 0.007120, train_accuracy 1, valid accuracy 0.7932
Epoch 277, CIFAR-10 Batch 5:  loss 0.006930, train_accuracy 1, valid accuracy 0.7822
Epoch 278, CIFAR-10 Batch 1:  loss 0.002398, train_accuracy 1, valid accuracy 0.8098
Epoch 278, CIFAR-10 Batch 2:  loss 0.002778, train_accuracy 1, valid accuracy 0.8022
Epoch 278, CIFAR-10 Batch 3:  loss 0.004464, train_accuracy 1, valid accuracy 0.794
Epoch 278, CIFAR-10 Batch 4:  loss 0.005731, train_accuracy 1, valid accuracy 0.8016
Epoch 278, CIFAR-10 Batch 5:  loss 0.003457, train_accuracy 1, valid accuracy 0.8004
Epoch 279, CIFAR-10 Batch 1:  loss 0.001664, train_accuracy 1, valid accuracy 0.8014
Epoch 279, CIFAR-10 Batch 2:  loss 0.001554, train_accuracy 1, valid accuracy 0.7964
Epoch 279, CIFAR-10 Batch 3:  loss 0.003241, train_accuracy 1, valid accuracy 0.7896
Epoch 279, CIFAR-10 Batch 4:  loss 0.005073, train_accuracy 1, valid accuracy 0.8022
Epoch 279, CIFAR-10 Batch 5:  loss 0.001312, train_accuracy 1, valid accuracy 0.7974
Epoch 280, CIFAR-10 Batch 1:  loss 0.005771, train_accuracy 1, valid accuracy 0.7924
Epoch 280, CIFAR-10 Batch 2:  loss 0.003304, train_accuracy 1, valid accuracy 0.7924
Epoch 280, CIFAR-10 Batch 3:  loss 0.011272, train_accuracy 1, valid accuracy 0.7966
Epoch 280, CIFAR-10 Batch 4:  loss 0.001947, train_accuracy 1, valid accuracy 0.8062
Epoch 280, CIFAR-10 Batch 5:  loss 0.002044, train_accuracy 1, valid accuracy 0.7922
Epoch 281, CIFAR-10 Batch 1:  loss 0.005790, train_accuracy 1, valid accuracy 0.7914
Epoch 281, CIFAR-10 Batch 2:  loss 0.005231, train_accuracy 1, valid accuracy 0.7924
Epoch 281, CIFAR-10 Batch 3:  loss 0.004874, train_accuracy 1, valid accuracy 0.793
Epoch 281, CIFAR-10 Batch 4:  loss 0.005496, train_accuracy 1, valid accuracy 0.7794
Epoch 281, CIFAR-10 Batch 5:  loss 0.005988, train_accuracy 1, valid accuracy 0.7942
Epoch 282, CIFAR-10 Batch 1:  loss 0.015373, train_accuracy 1, valid accuracy 0.7942
Epoch 282, CIFAR-10 Batch 2:  loss 0.002494, train_accuracy 1, valid accuracy 0.789
Epoch 282, CIFAR-10 Batch 3:  loss 0.002182, train_accuracy 1, valid accuracy 0.7982
Epoch 282, CIFAR-10 Batch 4:  loss 0.001840, train_accuracy 1, valid accuracy 0.805
Epoch 282, CIFAR-10 Batch 5:  loss 0.004875, train_accuracy 1, valid accuracy 0.799
Epoch 283, CIFAR-10 Batch 1:  loss 0.006490, train_accuracy 1, valid accuracy 0.8012
Epoch 283, CIFAR-10 Batch 2:  loss 0.001970, train_accuracy 1, valid accuracy 0.8056
Epoch 283, CIFAR-10 Batch 3:  loss 0.005088, train_accuracy 1, valid accuracy 0.788
Epoch 283, CIFAR-10 Batch 4:  loss 0.011316, train_accuracy 1, valid accuracy 0.8048
Epoch 283, CIFAR-10 Batch 5:  loss 0.011265, train_accuracy 1, valid accuracy 0.7814
Epoch 284, CIFAR-10 Batch 1:  loss 0.007790, train_accuracy 1, valid accuracy 0.8014
Epoch 284, CIFAR-10 Batch 2:  loss 0.009117, train_accuracy 1, valid accuracy 0.7954
Epoch 284, CIFAR-10 Batch 3:  loss 0.003025, train_accuracy 1, valid accuracy 0.7952
Epoch 284, CIFAR-10 Batch 4:  loss 0.010196, train_accuracy 1, valid accuracy 0.7868
Epoch 284, CIFAR-10 Batch 5:  loss 0.003321, train_accuracy 1, valid accuracy 0.7914
Epoch 285, CIFAR-10 Batch 1:  loss 0.003867, train_accuracy 1, valid accuracy 0.7994
Epoch 285, CIFAR-10 Batch 2:  loss 0.011906, train_accuracy 1, valid accuracy 0.787
Epoch 285, CIFAR-10 Batch 3:  loss 0.002520, train_accuracy 1, valid accuracy 0.8008
Epoch 285, CIFAR-10 Batch 4:  loss 0.005304, train_accuracy 1, valid accuracy 0.7976
Epoch 285, CIFAR-10 Batch 5:  loss 0.004500, train_accuracy 1, valid accuracy 0.7984
Epoch 286, CIFAR-10 Batch 1:  loss 0.001701, train_accuracy 1, valid accuracy 0.7998
Epoch 286, CIFAR-10 Batch 2:  loss 0.003953, train_accuracy 1, valid accuracy 0.8
Epoch 286, CIFAR-10 Batch 3:  loss 0.003138, train_accuracy 1, valid accuracy 0.7972
Epoch 286, CIFAR-10 Batch 4:  loss 0.009211, train_accuracy 1, valid accuracy 0.8002
Epoch 286, CIFAR-10 Batch 5:  loss 0.002492, train_accuracy 1, valid accuracy 0.7924
Epoch 287, CIFAR-10 Batch 1:  loss 0.004541, train_accuracy 1, valid accuracy 0.7974
Epoch 287, CIFAR-10 Batch 2:  loss 0.002554, train_accuracy 1, valid accuracy 0.8008
Epoch 287, CIFAR-10 Batch 3:  loss 0.003501, train_accuracy 1, valid accuracy 0.7922
Epoch 287, CIFAR-10 Batch 4:  loss 0.009469, train_accuracy 1, valid accuracy 0.7972
Epoch 287, CIFAR-10 Batch 5:  loss 0.001900, train_accuracy 1, valid accuracy 0.7958
Epoch 288, CIFAR-10 Batch 1:  loss 0.004049, train_accuracy 1, valid accuracy 0.7962
Epoch 288, CIFAR-10 Batch 2:  loss 0.003269, train_accuracy 1, valid accuracy 0.804
Epoch 288, CIFAR-10 Batch 3:  loss 0.002518, train_accuracy 1, valid accuracy 0.7924
Epoch 288, CIFAR-10 Batch 4:  loss 0.010463, train_accuracy 1, valid accuracy 0.7904
Epoch 288, CIFAR-10 Batch 5:  loss 0.004331, train_accuracy 1, valid accuracy 0.791
Epoch 289, CIFAR-10 Batch 1:  loss 0.004313, train_accuracy 1, valid accuracy 0.811
Epoch 289, CIFAR-10 Batch 2:  loss 0.002897, train_accuracy 1, valid accuracy 0.8002
Epoch 289, CIFAR-10 Batch 3:  loss 0.001747, train_accuracy 1, valid accuracy 0.7966
Epoch 289, CIFAR-10 Batch 4:  loss 0.004181, train_accuracy 1, valid accuracy 0.804
Epoch 289, CIFAR-10 Batch 5:  loss 0.002581, train_accuracy 1, valid accuracy 0.7898
Epoch 290, CIFAR-10 Batch 1:  loss 0.001601, train_accuracy 1, valid accuracy 0.7956
Epoch 290, CIFAR-10 Batch 2:  loss 0.004271, train_accuracy 1, valid accuracy 0.7988
Epoch 290, CIFAR-10 Batch 3:  loss 0.006244, train_accuracy 1, valid accuracy 0.7918
Epoch 290, CIFAR-10 Batch 4:  loss 0.004590, train_accuracy 1, valid accuracy 0.7946
Epoch 290, CIFAR-10 Batch 5:  loss 0.003973, train_accuracy 1, valid accuracy 0.7988
Epoch 291, CIFAR-10 Batch 1:  loss 0.002912, train_accuracy 1, valid accuracy 0.797
Epoch 291, CIFAR-10 Batch 2:  loss 0.003211, train_accuracy 1, valid accuracy 0.7966
Epoch 291, CIFAR-10 Batch 3:  loss 0.001866, train_accuracy 1, valid accuracy 0.7918
Epoch 291, CIFAR-10 Batch 4:  loss 0.005113, train_accuracy 1, valid accuracy 0.7938
Epoch 291, CIFAR-10 Batch 5:  loss 0.004462, train_accuracy 1, valid accuracy 0.7874
Epoch 292, CIFAR-10 Batch 1:  loss 0.002418, train_accuracy 1, valid accuracy 0.798
Epoch 292, CIFAR-10 Batch 2:  loss 0.001885, train_accuracy 1, valid accuracy 0.8014
Epoch 292, CIFAR-10 Batch 3:  loss 0.006024, train_accuracy 1, valid accuracy 0.7814
Epoch 292, CIFAR-10 Batch 4:  loss 0.003201, train_accuracy 1, valid accuracy 0.7996
Epoch 292, CIFAR-10 Batch 5:  loss 0.004094, train_accuracy 1, valid accuracy 0.7766
Epoch 293, CIFAR-10 Batch 1:  loss 0.002328, train_accuracy 1, valid accuracy 0.801
Epoch 293, CIFAR-10 Batch 2:  loss 0.002199, train_accuracy 1, valid accuracy 0.8002
Epoch 293, CIFAR-10 Batch 3:  loss 0.002776, train_accuracy 1, valid accuracy 0.7942
Epoch 293, CIFAR-10 Batch 4:  loss 0.007693, train_accuracy 1, valid accuracy 0.7938
Epoch 293, CIFAR-10 Batch 5:  loss 0.002206, train_accuracy 1, valid accuracy 0.7988
Epoch 294, CIFAR-10 Batch 1:  loss 0.006111, train_accuracy 1, valid accuracy 0.7974
Epoch 294, CIFAR-10 Batch 2:  loss 0.001826, train_accuracy 1, valid accuracy 0.803
Epoch 294, CIFAR-10 Batch 3:  loss 0.008373, train_accuracy 1, valid accuracy 0.7926
Epoch 294, CIFAR-10 Batch 4:  loss 0.006087, train_accuracy 1, valid accuracy 0.7982
Epoch 294, CIFAR-10 Batch 5:  loss 0.001998, train_accuracy 1, valid accuracy 0.7958
Epoch 295, CIFAR-10 Batch 1:  loss 0.002246, train_accuracy 1, valid accuracy 0.7942
Epoch 295, CIFAR-10 Batch 2:  loss 0.002790, train_accuracy 1, valid accuracy 0.7974
Epoch 295, CIFAR-10 Batch 3:  loss 0.001664, train_accuracy 1, valid accuracy 0.8004
Epoch 295, CIFAR-10 Batch 4:  loss 0.003861, train_accuracy 1, valid accuracy 0.8076
Epoch 295, CIFAR-10 Batch 5:  loss 0.005666, train_accuracy 1, valid accuracy 0.7898
Epoch 296, CIFAR-10 Batch 1:  loss 0.002371, train_accuracy 1, valid accuracy 0.8022
Epoch 296, CIFAR-10 Batch 2:  loss 0.002954, train_accuracy 1, valid accuracy 0.7962
Epoch 296, CIFAR-10 Batch 3:  loss 0.001293, train_accuracy 1, valid accuracy 0.7928
Epoch 296, CIFAR-10 Batch 4:  loss 0.003811, train_accuracy 1, valid accuracy 0.7978
Epoch 296, CIFAR-10 Batch 5:  loss 0.004888, train_accuracy 1, valid accuracy 0.7868
Epoch 297, CIFAR-10 Batch 1:  loss 0.001120, train_accuracy 1, valid accuracy 0.7972
Epoch 297, CIFAR-10 Batch 2:  loss 0.002058, train_accuracy 1, valid accuracy 0.8026
Epoch 297, CIFAR-10 Batch 3:  loss 0.002068, train_accuracy 1, valid accuracy 0.7974
Epoch 297, CIFAR-10 Batch 4:  loss 0.006388, train_accuracy 1, valid accuracy 0.7924
Epoch 297, CIFAR-10 Batch 5:  loss 0.005917, train_accuracy 1, valid accuracy 0.7896
Epoch 298, CIFAR-10 Batch 1:  loss 0.003974, train_accuracy 1, valid accuracy 0.8006
Epoch 298, CIFAR-10 Batch 2:  loss 0.001370, train_accuracy 1, valid accuracy 0.7994
Epoch 298, CIFAR-10 Batch 3:  loss 0.005301, train_accuracy 1, valid accuracy 0.7902
Epoch 298, CIFAR-10 Batch 4:  loss 0.002489, train_accuracy 1, valid accuracy 0.7958
Epoch 298, CIFAR-10 Batch 5:  loss 0.002900, train_accuracy 1, valid accuracy 0.7994
Epoch 299, CIFAR-10 Batch 1:  loss 0.001150, train_accuracy 1, valid accuracy 0.8048
Epoch 299, CIFAR-10 Batch 2:  loss 0.002958, train_accuracy 1, valid accuracy 0.797
Epoch 299, CIFAR-10 Batch 3:  loss 0.004397, train_accuracy 1, valid accuracy 0.7928
Epoch 299, CIFAR-10 Batch 4:  loss 0.003707, train_accuracy 1, valid accuracy 0.798
Epoch 299, CIFAR-10 Batch 5:  loss 0.002471, train_accuracy 1, valid accuracy 0.7954
Epoch 300, CIFAR-10 Batch 1:  loss 0.000769, train_accuracy 1, valid accuracy 0.8042
Epoch 300, CIFAR-10 Batch 2:  loss 0.002421, train_accuracy 1, valid accuracy 0.783
Epoch 300, CIFAR-10 Batch 3:  loss 0.018824, train_accuracy 1, valid accuracy 0.7798
Epoch 300, CIFAR-10 Batch 4:  loss 0.003055, train_accuracy 1, valid accuracy 0.7976
Epoch 300, CIFAR-10 Batch 5:  loss 0.002541, train_accuracy 1, valid accuracy 0.8008
Epoch 301, CIFAR-10 Batch 1:  loss 0.001717, train_accuracy 1, valid accuracy 0.7984
Epoch 301, CIFAR-10 Batch 2:  loss 0.001124, train_accuracy 1, valid accuracy 0.8034
Epoch 301, CIFAR-10 Batch 3:  loss 0.001477, train_accuracy 1, valid accuracy 0.7932
Epoch 301, CIFAR-10 Batch 4:  loss 0.002549, train_accuracy 1, valid accuracy 0.7952
Epoch 301, CIFAR-10 Batch 5:  loss 0.002175, train_accuracy 1, valid accuracy 0.7954
Epoch 302, CIFAR-10 Batch 1:  loss 0.000902, train_accuracy 1, valid accuracy 0.8006
Epoch 302, CIFAR-10 Batch 2:  loss 0.005063, train_accuracy 1, valid accuracy 0.784
Epoch 302, CIFAR-10 Batch 3:  loss 0.003988, train_accuracy 1, valid accuracy 0.8022
Epoch 302, CIFAR-10 Batch 4:  loss 0.009220, train_accuracy 1, valid accuracy 0.7994
Epoch 302, CIFAR-10 Batch 5:  loss 0.004951, train_accuracy 1, valid accuracy 0.795
Epoch 303, CIFAR-10 Batch 1:  loss 0.001324, train_accuracy 1, valid accuracy 0.8002
Epoch 303, CIFAR-10 Batch 2:  loss 0.004937, train_accuracy 1, valid accuracy 0.7972
Epoch 303, CIFAR-10 Batch 3:  loss 0.002791, train_accuracy 1, valid accuracy 0.7944
Epoch 303, CIFAR-10 Batch 4:  loss 0.002281, train_accuracy 1, valid accuracy 0.793
Epoch 303, CIFAR-10 Batch 5:  loss 0.002786, train_accuracy 1, valid accuracy 0.797
Epoch 304, CIFAR-10 Batch 1:  loss 0.004474, train_accuracy 1, valid accuracy 0.789
Epoch 304, CIFAR-10 Batch 2:  loss 0.002260, train_accuracy 1, valid accuracy 0.7988
Epoch 304, CIFAR-10 Batch 3:  loss 0.003370, train_accuracy 1, valid accuracy 0.7686
Epoch 304, CIFAR-10 Batch 4:  loss 0.003702, train_accuracy 1, valid accuracy 0.7846
Epoch 304, CIFAR-10 Batch 5:  loss 0.008709, train_accuracy 1, valid accuracy 0.788
Epoch 305, CIFAR-10 Batch 1:  loss 0.006407, train_accuracy 1, valid accuracy 0.7952
Epoch 305, CIFAR-10 Batch 2:  loss 0.005959, train_accuracy 1, valid accuracy 0.796
Epoch 305, CIFAR-10 Batch 3:  loss 0.001400, train_accuracy 1, valid accuracy 0.7752
Epoch 305, CIFAR-10 Batch 4:  loss 0.002213, train_accuracy 1, valid accuracy 0.7976
Epoch 305, CIFAR-10 Batch 5:  loss 0.002233, train_accuracy 1, valid accuracy 0.7998
Epoch 306, CIFAR-10 Batch 1:  loss 0.002985, train_accuracy 1, valid accuracy 0.7964
Epoch 306, CIFAR-10 Batch 2:  loss 0.004626, train_accuracy 1, valid accuracy 0.7952
Epoch 306, CIFAR-10 Batch 3:  loss 0.000857, train_accuracy 1, valid accuracy 0.7954
Epoch 306, CIFAR-10 Batch 4:  loss 0.002705, train_accuracy 1, valid accuracy 0.803
Epoch 306, CIFAR-10 Batch 5:  loss 0.000908, train_accuracy 1, valid accuracy 0.795
Epoch 307, CIFAR-10 Batch 1:  loss 0.005556, train_accuracy 1, valid accuracy 0.8038
Epoch 307, CIFAR-10 Batch 2:  loss 0.001809, train_accuracy 1, valid accuracy 0.8058
Epoch 307, CIFAR-10 Batch 3:  loss 0.000705, train_accuracy 1, valid accuracy 0.7962
Epoch 307, CIFAR-10 Batch 4:  loss 0.002483, train_accuracy 1, valid accuracy 0.802
Epoch 307, CIFAR-10 Batch 5:  loss 0.000464, train_accuracy 1, valid accuracy 0.8034
Epoch 308, CIFAR-10 Batch 1:  loss 0.004731, train_accuracy 1, valid accuracy 0.7998
Epoch 308, CIFAR-10 Batch 2:  loss 0.004362, train_accuracy 1, valid accuracy 0.8052
Epoch 308, CIFAR-10 Batch 3:  loss 0.002120, train_accuracy 1, valid accuracy 0.7914
Epoch 308, CIFAR-10 Batch 4:  loss 0.003373, train_accuracy 1, valid accuracy 0.806
Epoch 308, CIFAR-10 Batch 5:  loss 0.006828, train_accuracy 1, valid accuracy 0.7792
Epoch 309, CIFAR-10 Batch 1:  loss 0.002780, train_accuracy 1, valid accuracy 0.7962
Epoch 309, CIFAR-10 Batch 2:  loss 0.003379, train_accuracy 1, valid accuracy 0.7896
Epoch 309, CIFAR-10 Batch 3:  loss 0.002478, train_accuracy 1, valid accuracy 0.7958
Epoch 309, CIFAR-10 Batch 4:  loss 0.003771, train_accuracy 1, valid accuracy 0.7998
Epoch 309, CIFAR-10 Batch 5:  loss 0.005978, train_accuracy 1, valid accuracy 0.7846
Epoch 310, CIFAR-10 Batch 1:  loss 0.003129, train_accuracy 1, valid accuracy 0.7966
Epoch 310, CIFAR-10 Batch 2:  loss 0.002788, train_accuracy 1, valid accuracy 0.8008
Epoch 310, CIFAR-10 Batch 3:  loss 0.004070, train_accuracy 1, valid accuracy 0.7928
Epoch 310, CIFAR-10 Batch 4:  loss 0.008327, train_accuracy 1, valid accuracy 0.8016
Epoch 310, CIFAR-10 Batch 5:  loss 0.000772, train_accuracy 1, valid accuracy 0.8004
Epoch 311, CIFAR-10 Batch 1:  loss 0.001306, train_accuracy 1, valid accuracy 0.7966
Epoch 311, CIFAR-10 Batch 2:  loss 0.001475, train_accuracy 1, valid accuracy 0.8092
Epoch 311, CIFAR-10 Batch 3:  loss 0.001738, train_accuracy 1, valid accuracy 0.803
Epoch 311, CIFAR-10 Batch 4:  loss 0.003314, train_accuracy 1, valid accuracy 0.8058
Epoch 311, CIFAR-10 Batch 5:  loss 0.002312, train_accuracy 1, valid accuracy 0.7986
Epoch 312, CIFAR-10 Batch 1:  loss 0.002904, train_accuracy 1, valid accuracy 0.801
Epoch 312, CIFAR-10 Batch 2:  loss 0.000900, train_accuracy 1, valid accuracy 0.8066
Epoch 312, CIFAR-10 Batch 3:  loss 0.004399, train_accuracy 1, valid accuracy 0.79
Epoch 312, CIFAR-10 Batch 4:  loss 0.008625, train_accuracy 1, valid accuracy 0.7924
Epoch 312, CIFAR-10 Batch 5:  loss 0.001028, train_accuracy 1, valid accuracy 0.8
Epoch 313, CIFAR-10 Batch 1:  loss 0.000929, train_accuracy 1, valid accuracy 0.805
Epoch 313, CIFAR-10 Batch 2:  loss 0.002883, train_accuracy 1, valid accuracy 0.8046
Epoch 313, CIFAR-10 Batch 3:  loss 0.003360, train_accuracy 1, valid accuracy 0.7984
Epoch 313, CIFAR-10 Batch 4:  loss 0.014576, train_accuracy 1, valid accuracy 0.7874
Epoch 313, CIFAR-10 Batch 5:  loss 0.001416, train_accuracy 1, valid accuracy 0.8
Epoch 314, CIFAR-10 Batch 1:  loss 0.001658, train_accuracy 1, valid accuracy 0.8074
Epoch 314, CIFAR-10 Batch 2:  loss 0.001225, train_accuracy 1, valid accuracy 0.801
Epoch 314, CIFAR-10 Batch 3:  loss 0.001880, train_accuracy 1, valid accuracy 0.7976
Epoch 314, CIFAR-10 Batch 4:  loss 0.003454, train_accuracy 1, valid accuracy 0.798
Epoch 314, CIFAR-10 Batch 5:  loss 0.001558, train_accuracy 1, valid accuracy 0.805
Epoch 315, CIFAR-10 Batch 1:  loss 0.000892, train_accuracy 1, valid accuracy 0.8
Epoch 315, CIFAR-10 Batch 2:  loss 0.003571, train_accuracy 1, valid accuracy 0.797
Epoch 315, CIFAR-10 Batch 3:  loss 0.002853, train_accuracy 1, valid accuracy 0.8012
Epoch 315, CIFAR-10 Batch 4:  loss 0.011891, train_accuracy 1, valid accuracy 0.805
Epoch 315, CIFAR-10 Batch 5:  loss 0.001860, train_accuracy 1, valid accuracy 0.7986
Epoch 316, CIFAR-10 Batch 1:  loss 0.001502, train_accuracy 1, valid accuracy 0.8004
Epoch 316, CIFAR-10 Batch 2:  loss 0.021604, train_accuracy 1, valid accuracy 0.798
Epoch 316, CIFAR-10 Batch 3:  loss 0.002072, train_accuracy 1, valid accuracy 0.7982
Epoch 316, CIFAR-10 Batch 4:  loss 0.003948, train_accuracy 1, valid accuracy 0.7922
Epoch 316, CIFAR-10 Batch 5:  loss 0.001861, train_accuracy 1, valid accuracy 0.802
Epoch 317, CIFAR-10 Batch 1:  loss 0.001898, train_accuracy 1, valid accuracy 0.8064
Epoch 317, CIFAR-10 Batch 2:  loss 0.002490, train_accuracy 1, valid accuracy 0.8086
Epoch 317, CIFAR-10 Batch 3:  loss 0.002400, train_accuracy 1, valid accuracy 0.7908
Epoch 317, CIFAR-10 Batch 4:  loss 0.004469, train_accuracy 1, valid accuracy 0.7986
Epoch 317, CIFAR-10 Batch 5:  loss 0.000820, train_accuracy 1, valid accuracy 0.8028
Epoch 318, CIFAR-10 Batch 1:  loss 0.002156, train_accuracy 1, valid accuracy 0.8028
Epoch 318, CIFAR-10 Batch 2:  loss 0.001603, train_accuracy 1, valid accuracy 0.7974
Epoch 318, CIFAR-10 Batch 3:  loss 0.005135, train_accuracy 1, valid accuracy 0.8022
Epoch 318, CIFAR-10 Batch 4:  loss 0.003335, train_accuracy 1, valid accuracy 0.8012
Epoch 318, CIFAR-10 Batch 5:  loss 0.003186, train_accuracy 1, valid accuracy 0.803
Epoch 319, CIFAR-10 Batch 1:  loss 0.000938, train_accuracy 1, valid accuracy 0.8122
Epoch 319, CIFAR-10 Batch 2:  loss 0.001348, train_accuracy 1, valid accuracy 0.8008
Epoch 319, CIFAR-10 Batch 3:  loss 0.002774, train_accuracy 1, valid accuracy 0.7936
Epoch 319, CIFAR-10 Batch 4:  loss 0.012506, train_accuracy 1, valid accuracy 0.8044
Epoch 319, CIFAR-10 Batch 5:  loss 0.002831, train_accuracy 1, valid accuracy 0.814
Epoch 320, CIFAR-10 Batch 1:  loss 0.004123, train_accuracy 1, valid accuracy 0.8014
Epoch 320, CIFAR-10 Batch 2:  loss 0.001710, train_accuracy 1, valid accuracy 0.7994
Epoch 320, CIFAR-10 Batch 3:  loss 0.001970, train_accuracy 1, valid accuracy 0.7922
Epoch 320, CIFAR-10 Batch 4:  loss 0.004576, train_accuracy 1, valid accuracy 0.7988
Epoch 320, CIFAR-10 Batch 5:  loss 0.006923, train_accuracy 1, valid accuracy 0.8
Epoch 321, CIFAR-10 Batch 1:  loss 0.001557, train_accuracy 1, valid accuracy 0.8122
Epoch 321, CIFAR-10 Batch 2:  loss 0.004311, train_accuracy 1, valid accuracy 0.7968
Epoch 321, CIFAR-10 Batch 3:  loss 0.002549, train_accuracy 1, valid accuracy 0.8012
Epoch 321, CIFAR-10 Batch 4:  loss 0.004070, train_accuracy 1, valid accuracy 0.8004
Epoch 321, CIFAR-10 Batch 5:  loss 0.001635, train_accuracy 1, valid accuracy 0.7996
Epoch 322, CIFAR-10 Batch 1:  loss 0.002500, train_accuracy 1, valid accuracy 0.8066
Epoch 322, CIFAR-10 Batch 2:  loss 0.003780, train_accuracy 1, valid accuracy 0.8002
Epoch 322, CIFAR-10 Batch 3:  loss 0.003050, train_accuracy 1, valid accuracy 0.7914
Epoch 322, CIFAR-10 Batch 4:  loss 0.004891, train_accuracy 1, valid accuracy 0.8042
Epoch 322, CIFAR-10 Batch 5:  loss 0.002273, train_accuracy 1, valid accuracy 0.794
Epoch 323, CIFAR-10 Batch 1:  loss 0.004401, train_accuracy 1, valid accuracy 0.8046
Epoch 323, CIFAR-10 Batch 2:  loss 0.006961, train_accuracy 1, valid accuracy 0.7966
Epoch 323, CIFAR-10 Batch 3:  loss 0.002368, train_accuracy 1, valid accuracy 0.7978
Epoch 323, CIFAR-10 Batch 4:  loss 0.005093, train_accuracy 1, valid accuracy 0.7906
Epoch 323, CIFAR-10 Batch 5:  loss 0.000777, train_accuracy 1, valid accuracy 0.8086
Epoch 324, CIFAR-10 Batch 1:  loss 0.003193, train_accuracy 1, valid accuracy 0.8062
Epoch 324, CIFAR-10 Batch 2:  loss 0.002684, train_accuracy 1, valid accuracy 0.81
Epoch 324, CIFAR-10 Batch 3:  loss 0.003087, train_accuracy 1, valid accuracy 0.8008
Epoch 324, CIFAR-10 Batch 4:  loss 0.009938, train_accuracy 1, valid accuracy 0.8062
Epoch 324, CIFAR-10 Batch 5:  loss 0.001866, train_accuracy 1, valid accuracy 0.8082
Epoch 325, CIFAR-10 Batch 1:  loss 0.002587, train_accuracy 1, valid accuracy 0.8068
Epoch 325, CIFAR-10 Batch 2:  loss 0.002132, train_accuracy 1, valid accuracy 0.8066
Epoch 325, CIFAR-10 Batch 3:  loss 0.002315, train_accuracy 1, valid accuracy 0.8024
Epoch 325, CIFAR-10 Batch 4:  loss 0.006921, train_accuracy 1, valid accuracy 0.7918
Epoch 325, CIFAR-10 Batch 5:  loss 0.002135, train_accuracy 1, valid accuracy 0.7984
Epoch 326, CIFAR-10 Batch 1:  loss 0.002073, train_accuracy 1, valid accuracy 0.8028
Epoch 326, CIFAR-10 Batch 2:  loss 0.005975, train_accuracy 1, valid accuracy 0.785
Epoch 326, CIFAR-10 Batch 3:  loss 0.001362, train_accuracy 1, valid accuracy 0.8042
Epoch 326, CIFAR-10 Batch 4:  loss 0.001918, train_accuracy 1, valid accuracy 0.8004
Epoch 326, CIFAR-10 Batch 5:  loss 0.000912, train_accuracy 1, valid accuracy 0.804
Epoch 327, CIFAR-10 Batch 1:  loss 0.003977, train_accuracy 1, valid accuracy 0.801
Epoch 327, CIFAR-10 Batch 2:  loss 0.001289, train_accuracy 1, valid accuracy 0.803
Epoch 327, CIFAR-10 Batch 3:  loss 0.002310, train_accuracy 1, valid accuracy 0.8026
Epoch 327, CIFAR-10 Batch 4:  loss 0.002554, train_accuracy 1, valid accuracy 0.8028
Epoch 327, CIFAR-10 Batch 5:  loss 0.001557, train_accuracy 1, valid accuracy 0.8016
Epoch 328, CIFAR-10 Batch 1:  loss 0.002678, train_accuracy 1, valid accuracy 0.802
Epoch 328, CIFAR-10 Batch 2:  loss 0.007600, train_accuracy 1, valid accuracy 0.7976
Epoch 328, CIFAR-10 Batch 3:  loss 0.003808, train_accuracy 1, valid accuracy 0.8074
Epoch 328, CIFAR-10 Batch 4:  loss 0.002386, train_accuracy 1, valid accuracy 0.8036
Epoch 328, CIFAR-10 Batch 5:  loss 0.000988, train_accuracy 1, valid accuracy 0.8078
Epoch 329, CIFAR-10 Batch 1:  loss 0.011776, train_accuracy 1, valid accuracy 0.787
Epoch 329, CIFAR-10 Batch 2:  loss 0.001320, train_accuracy 1, valid accuracy 0.798
Epoch 329, CIFAR-10 Batch 3:  loss 0.002309, train_accuracy 1, valid accuracy 0.7964
Epoch 329, CIFAR-10 Batch 4:  loss 0.004171, train_accuracy 1, valid accuracy 0.7878
Epoch 329, CIFAR-10 Batch 5:  loss 0.002334, train_accuracy 1, valid accuracy 0.8024
Epoch 330, CIFAR-10 Batch 1:  loss 0.002157, train_accuracy 1, valid accuracy 0.7984
Epoch 330, CIFAR-10 Batch 2:  loss 0.006828, train_accuracy 1, valid accuracy 0.7882
Epoch 330, CIFAR-10 Batch 3:  loss 0.002724, train_accuracy 1, valid accuracy 0.7968
Epoch 330, CIFAR-10 Batch 4:  loss 0.002798, train_accuracy 1, valid accuracy 0.8008
Epoch 330, CIFAR-10 Batch 5:  loss 0.000712, train_accuracy 1, valid accuracy 0.7986
Epoch 331, CIFAR-10 Batch 1:  loss 0.001299, train_accuracy 1, valid accuracy 0.803
Epoch 331, CIFAR-10 Batch 2:  loss 0.002927, train_accuracy 1, valid accuracy 0.7992
Epoch 331, CIFAR-10 Batch 3:  loss 0.002149, train_accuracy 1, valid accuracy 0.797
Epoch 331, CIFAR-10 Batch 4:  loss 0.003133, train_accuracy 1, valid accuracy 0.8096
Epoch 331, CIFAR-10 Batch 5:  loss 0.002435, train_accuracy 1, valid accuracy 0.8036
Epoch 332, CIFAR-10 Batch 1:  loss 0.001262, train_accuracy 1, valid accuracy 0.8098
Epoch 332, CIFAR-10 Batch 2:  loss 0.003357, train_accuracy 1, valid accuracy 0.8004
Epoch 332, CIFAR-10 Batch 3:  loss 0.003459, train_accuracy 1, valid accuracy 0.7936
Epoch 332, CIFAR-10 Batch 4:  loss 0.003125, train_accuracy 1, valid accuracy 0.7942
Epoch 332, CIFAR-10 Batch 5:  loss 0.001341, train_accuracy 1, valid accuracy 0.8048
Epoch 333, CIFAR-10 Batch 1:  loss 0.001993, train_accuracy 1, valid accuracy 0.7986
Epoch 333, CIFAR-10 Batch 2:  loss 0.001768, train_accuracy 1, valid accuracy 0.7988
Epoch 333, CIFAR-10 Batch 3:  loss 0.002010, train_accuracy 1, valid accuracy 0.7974
Epoch 333, CIFAR-10 Batch 4:  loss 0.001774, train_accuracy 1, valid accuracy 0.7976
Epoch 333, CIFAR-10 Batch 5:  loss 0.002353, train_accuracy 1, valid accuracy 0.7948
Epoch 334, CIFAR-10 Batch 1:  loss 0.000871, train_accuracy 1, valid accuracy 0.8032
Epoch 334, CIFAR-10 Batch 2:  loss 0.003065, train_accuracy 1, valid accuracy 0.7962
Epoch 334, CIFAR-10 Batch 3:  loss 0.005678, train_accuracy 1, valid accuracy 0.7986
Epoch 334, CIFAR-10 Batch 4:  loss 0.002658, train_accuracy 1, valid accuracy 0.797
Epoch 334, CIFAR-10 Batch 5:  loss 0.000684, train_accuracy 1, valid accuracy 0.8036
Epoch 335, CIFAR-10 Batch 1:  loss 0.000933, train_accuracy 1, valid accuracy 0.8104
Epoch 335, CIFAR-10 Batch 2:  loss 0.001573, train_accuracy 1, valid accuracy 0.804
Epoch 335, CIFAR-10 Batch 3:  loss 0.003166, train_accuracy 1, valid accuracy 0.8006
Epoch 335, CIFAR-10 Batch 4:  loss 0.002764, train_accuracy 1, valid accuracy 0.806
Epoch 335, CIFAR-10 Batch 5:  loss 0.001558, train_accuracy 1, valid accuracy 0.8018
Epoch 336, CIFAR-10 Batch 1:  loss 0.001107, train_accuracy 1, valid accuracy 0.802
Epoch 336, CIFAR-10 Batch 2:  loss 0.000903, train_accuracy 1, valid accuracy 0.8112
Epoch 336, CIFAR-10 Batch 3:  loss 0.001483, train_accuracy 1, valid accuracy 0.7946
Epoch 336, CIFAR-10 Batch 4:  loss 0.003586, train_accuracy 1, valid accuracy 0.7848
Epoch 336, CIFAR-10 Batch 5:  loss 0.001149, train_accuracy 1, valid accuracy 0.8014
Epoch 337, CIFAR-10 Batch 1:  loss 0.007973, train_accuracy 1, valid accuracy 0.7938
Epoch 337, CIFAR-10 Batch 2:  loss 0.001259, train_accuracy 1, valid accuracy 0.8034
Epoch 337, CIFAR-10 Batch 3:  loss 0.003370, train_accuracy 1, valid accuracy 0.8054
Epoch 337, CIFAR-10 Batch 4:  loss 0.002597, train_accuracy 1, valid accuracy 0.8
Epoch 337, CIFAR-10 Batch 5:  loss 0.002618, train_accuracy 1, valid accuracy 0.789
Epoch 338, CIFAR-10 Batch 1:  loss 0.000819, train_accuracy 1, valid accuracy 0.8104
Epoch 338, CIFAR-10 Batch 2:  loss 0.003686, train_accuracy 1, valid accuracy 0.7938
Epoch 338, CIFAR-10 Batch 3:  loss 0.004608, train_accuracy 1, valid accuracy 0.8108
Epoch 338, CIFAR-10 Batch 4:  loss 0.001127, train_accuracy 1, valid accuracy 0.8006
Epoch 338, CIFAR-10 Batch 5:  loss 0.000987, train_accuracy 1, valid accuracy 0.7982
Epoch 339, CIFAR-10 Batch 1:  loss 0.001506, train_accuracy 1, valid accuracy 0.8036
Epoch 339, CIFAR-10 Batch 2:  loss 0.001064, train_accuracy 1, valid accuracy 0.8078
Epoch 339, CIFAR-10 Batch 3:  loss 0.002060, train_accuracy 1, valid accuracy 0.7976
Epoch 339, CIFAR-10 Batch 4:  loss 0.002212, train_accuracy 1, valid accuracy 0.8068
Epoch 339, CIFAR-10 Batch 5:  loss 0.000831, train_accuracy 1, valid accuracy 0.8026
Epoch 340, CIFAR-10 Batch 1:  loss 0.001616, train_accuracy 1, valid accuracy 0.804
Epoch 340, CIFAR-10 Batch 2:  loss 0.002675, train_accuracy 1, valid accuracy 0.8048
Epoch 340, CIFAR-10 Batch 3:  loss 0.003052, train_accuracy 1, valid accuracy 0.7876
Epoch 340, CIFAR-10 Batch 4:  loss 0.001966, train_accuracy 1, valid accuracy 0.8012
Epoch 340, CIFAR-10 Batch 5:  loss 0.000774, train_accuracy 1, valid accuracy 0.8098
Epoch 341, CIFAR-10 Batch 1:  loss 0.001832, train_accuracy 1, valid accuracy 0.803
Epoch 341, CIFAR-10 Batch 2:  loss 0.001835, train_accuracy 1, valid accuracy 0.8022
Epoch 341, CIFAR-10 Batch 3:  loss 0.003119, train_accuracy 1, valid accuracy 0.793
Epoch 341, CIFAR-10 Batch 4:  loss 0.000602, train_accuracy 1, valid accuracy 0.7994
Epoch 341, CIFAR-10 Batch 5:  loss 0.001197, train_accuracy 1, valid accuracy 0.798
Epoch 342, CIFAR-10 Batch 1:  loss 0.002540, train_accuracy 1, valid accuracy 0.8076
Epoch 342, CIFAR-10 Batch 2:  loss 0.001222, train_accuracy 1, valid accuracy 0.8062
Epoch 342, CIFAR-10 Batch 3:  loss 0.002542, train_accuracy 1, valid accuracy 0.7994
Epoch 342, CIFAR-10 Batch 4:  loss 0.001403, train_accuracy 1, valid accuracy 0.8054
Epoch 342, CIFAR-10 Batch 5:  loss 0.001160, train_accuracy 1, valid accuracy 0.7986
Epoch 343, CIFAR-10 Batch 1:  loss 0.001504, train_accuracy 1, valid accuracy 0.8092
Epoch 343, CIFAR-10 Batch 2:  loss 0.001702, train_accuracy 1, valid accuracy 0.808
Epoch 343, CIFAR-10 Batch 3:  loss 0.001308, train_accuracy 1, valid accuracy 0.8082
Epoch 343, CIFAR-10 Batch 4:  loss 0.001548, train_accuracy 1, valid accuracy 0.8052
Epoch 343, CIFAR-10 Batch 5:  loss 0.001879, train_accuracy 1, valid accuracy 0.8116
Epoch 344, CIFAR-10 Batch 1:  loss 0.002362, train_accuracy 1, valid accuracy 0.8132
Epoch 344, CIFAR-10 Batch 2:  loss 0.001179, train_accuracy 1, valid accuracy 0.8038
Epoch 344, CIFAR-10 Batch 3:  loss 0.002844, train_accuracy 1, valid accuracy 0.8036
Epoch 344, CIFAR-10 Batch 4:  loss 0.001992, train_accuracy 1, valid accuracy 0.81
Epoch 344, CIFAR-10 Batch 5:  loss 0.000424, train_accuracy 1, valid accuracy 0.806
Epoch 345, CIFAR-10 Batch 1:  loss 0.000847, train_accuracy 1, valid accuracy 0.8104
Epoch 345, CIFAR-10 Batch 2:  loss 0.000782, train_accuracy 1, valid accuracy 0.813
Epoch 345, CIFAR-10 Batch 3:  loss 0.001235, train_accuracy 1, valid accuracy 0.7998
Epoch 345, CIFAR-10 Batch 4:  loss 0.001603, train_accuracy 1, valid accuracy 0.801
Epoch 345, CIFAR-10 Batch 5:  loss 0.001218, train_accuracy 1, valid accuracy 0.8058
Epoch 346, CIFAR-10 Batch 1:  loss 0.001856, train_accuracy 1, valid accuracy 0.8064
Epoch 346, CIFAR-10 Batch 2:  loss 0.001273, train_accuracy 1, valid accuracy 0.7976
Epoch 346, CIFAR-10 Batch 3:  loss 0.002792, train_accuracy 1, valid accuracy 0.7982
Epoch 346, CIFAR-10 Batch 4:  loss 0.003140, train_accuracy 1, valid accuracy 0.7974
Epoch 346, CIFAR-10 Batch 5:  loss 0.001480, train_accuracy 1, valid accuracy 0.8102
Epoch 347, CIFAR-10 Batch 1:  loss 0.003129, train_accuracy 1, valid accuracy 0.8026
Epoch 347, CIFAR-10 Batch 2:  loss 0.003517, train_accuracy 1, valid accuracy 0.8078
Epoch 347, CIFAR-10 Batch 3:  loss 0.003017, train_accuracy 1, valid accuracy 0.8068
Epoch 347, CIFAR-10 Batch 4:  loss 0.003704, train_accuracy 1, valid accuracy 0.7914
Epoch 347, CIFAR-10 Batch 5:  loss 0.001823, train_accuracy 1, valid accuracy 0.8002
Epoch 348, CIFAR-10 Batch 1:  loss 0.000973, train_accuracy 1, valid accuracy 0.8034
Epoch 348, CIFAR-10 Batch 2:  loss 0.002540, train_accuracy 1, valid accuracy 0.8034
Epoch 348, CIFAR-10 Batch 3:  loss 0.001488, train_accuracy 1, valid accuracy 0.7988
Epoch 348, CIFAR-10 Batch 4:  loss 0.002983, train_accuracy 1, valid accuracy 0.8102
Epoch 348, CIFAR-10 Batch 5:  loss 0.002236, train_accuracy 1, valid accuracy 0.794
Epoch 349, CIFAR-10 Batch 1:  loss 0.002571, train_accuracy 1, valid accuracy 0.808
Epoch 349, CIFAR-10 Batch 2:  loss 0.002150, train_accuracy 1, valid accuracy 0.7798
Epoch 349, CIFAR-10 Batch 3:  loss 0.000958, train_accuracy 1, valid accuracy 0.7958
Epoch 349, CIFAR-10 Batch 4:  loss 0.004445, train_accuracy 1, valid accuracy 0.8078
Epoch 349, CIFAR-10 Batch 5:  loss 0.002456, train_accuracy 1, valid accuracy 0.797
Epoch 350, CIFAR-10 Batch 1:  loss 0.002417, train_accuracy 1, valid accuracy 0.8018
Epoch 350, CIFAR-10 Batch 2:  loss 0.008382, train_accuracy 1, valid accuracy 0.8128
Epoch 350, CIFAR-10 Batch 3:  loss 0.002422, train_accuracy 1, valid accuracy 0.8036
Epoch 350, CIFAR-10 Batch 4:  loss 0.002691, train_accuracy 1, valid accuracy 0.8006
Epoch 350, CIFAR-10 Batch 5:  loss 0.001066, train_accuracy 1, valid accuracy 0.8026
Epoch 351, CIFAR-10 Batch 1:  loss 0.000630, train_accuracy 1, valid accuracy 0.8062
Epoch 351, CIFAR-10 Batch 2:  loss 0.001718, train_accuracy 1, valid accuracy 0.8072
Epoch 351, CIFAR-10 Batch 3:  loss 0.001170, train_accuracy 1, valid accuracy 0.8024
Epoch 351, CIFAR-10 Batch 4:  loss 0.001168, train_accuracy 1, valid accuracy 0.8042
Epoch 351, CIFAR-10 Batch 5:  loss 0.003193, train_accuracy 1, valid accuracy 0.7916
Epoch 352, CIFAR-10 Batch 1:  loss 0.000683, train_accuracy 1, valid accuracy 0.8048
Epoch 352, CIFAR-10 Batch 2:  loss 0.001800, train_accuracy 1, valid accuracy 0.8048
Epoch 352, CIFAR-10 Batch 3:  loss 0.003525, train_accuracy 1, valid accuracy 0.7984
Epoch 352, CIFAR-10 Batch 4:  loss 0.002431, train_accuracy 1, valid accuracy 0.8054
Epoch 352, CIFAR-10 Batch 5:  loss 0.000595, train_accuracy 1, valid accuracy 0.8004
Epoch 353, CIFAR-10 Batch 1:  loss 0.001625, train_accuracy 1, valid accuracy 0.8046
Epoch 353, CIFAR-10 Batch 2:  loss 0.001055, train_accuracy 1, valid accuracy 0.8054
Epoch 353, CIFAR-10 Batch 3:  loss 0.004259, train_accuracy 1, valid accuracy 0.8026
Epoch 353, CIFAR-10 Batch 4:  loss 0.001809, train_accuracy 1, valid accuracy 0.7892
Epoch 353, CIFAR-10 Batch 5:  loss 0.001672, train_accuracy 1, valid accuracy 0.8038
Epoch 354, CIFAR-10 Batch 1:  loss 0.000926, train_accuracy 1, valid accuracy 0.8034
Epoch 354, CIFAR-10 Batch 2:  loss 0.000698, train_accuracy 1, valid accuracy 0.803
Epoch 354, CIFAR-10 Batch 3:  loss 0.000978, train_accuracy 1, valid accuracy 0.8064
Epoch 354, CIFAR-10 Batch 4:  loss 0.005532, train_accuracy 1, valid accuracy 0.7926
Epoch 354, CIFAR-10 Batch 5:  loss 0.001098, train_accuracy 1, valid accuracy 0.7918
Epoch 355, CIFAR-10 Batch 1:  loss 0.001643, train_accuracy 1, valid accuracy 0.8092
Epoch 355, CIFAR-10 Batch 2:  loss 0.000595, train_accuracy 1, valid accuracy 0.8038
Epoch 355, CIFAR-10 Batch 3:  loss 0.002083, train_accuracy 1, valid accuracy 0.8004
Epoch 355, CIFAR-10 Batch 4:  loss 0.003872, train_accuracy 1, valid accuracy 0.8026
Epoch 355, CIFAR-10 Batch 5:  loss 0.001630, train_accuracy 1, valid accuracy 0.7838
Epoch 356, CIFAR-10 Batch 1:  loss 0.001448, train_accuracy 1, valid accuracy 0.8052
Epoch 356, CIFAR-10 Batch 2:  loss 0.002180, train_accuracy 1, valid accuracy 0.7988
Epoch 356, CIFAR-10 Batch 3:  loss 0.001583, train_accuracy 1, valid accuracy 0.8036
Epoch 356, CIFAR-10 Batch 4:  loss 0.002404, train_accuracy 1, valid accuracy 0.8034
Epoch 356, CIFAR-10 Batch 5:  loss 0.005833, train_accuracy 1, valid accuracy 0.782
Epoch 357, CIFAR-10 Batch 1:  loss 0.001449, train_accuracy 1, valid accuracy 0.8108
Epoch 357, CIFAR-10 Batch 2:  loss 0.003120, train_accuracy 1, valid accuracy 0.8036
Epoch 357, CIFAR-10 Batch 3:  loss 0.001011, train_accuracy 1, valid accuracy 0.8044
Epoch 357, CIFAR-10 Batch 4:  loss 0.003328, train_accuracy 1, valid accuracy 0.802
Epoch 357, CIFAR-10 Batch 5:  loss 0.001300, train_accuracy 1, valid accuracy 0.7918
Epoch 358, CIFAR-10 Batch 1:  loss 0.000977, train_accuracy 1, valid accuracy 0.8074
Epoch 358, CIFAR-10 Batch 2:  loss 0.006350, train_accuracy 1, valid accuracy 0.7794
Epoch 358, CIFAR-10 Batch 3:  loss 0.001251, train_accuracy 1, valid accuracy 0.804
Epoch 358, CIFAR-10 Batch 4:  loss 0.002030, train_accuracy 1, valid accuracy 0.8044
Epoch 358, CIFAR-10 Batch 5:  loss 0.000526, train_accuracy 1, valid accuracy 0.8066
Epoch 359, CIFAR-10 Batch 1:  loss 0.001093, train_accuracy 1, valid accuracy 0.8052
Epoch 359, CIFAR-10 Batch 2:  loss 0.002689, train_accuracy 1, valid accuracy 0.7974
Epoch 359, CIFAR-10 Batch 3:  loss 0.015738, train_accuracy 1, valid accuracy 0.774
Epoch 359, CIFAR-10 Batch 4:  loss 0.001777, train_accuracy 1, valid accuracy 0.797
Epoch 359, CIFAR-10 Batch 5:  loss 0.001238, train_accuracy 1, valid accuracy 0.7946
Epoch 360, CIFAR-10 Batch 1:  loss 0.000590, train_accuracy 1, valid accuracy 0.8068
Epoch 360, CIFAR-10 Batch 2:  loss 0.002822, train_accuracy 1, valid accuracy 0.7944
Epoch 360, CIFAR-10 Batch 3:  loss 0.000755, train_accuracy 1, valid accuracy 0.8006
Epoch 360, CIFAR-10 Batch 4:  loss 0.000820, train_accuracy 1, valid accuracy 0.8152
Epoch 360, CIFAR-10 Batch 5:  loss 0.002141, train_accuracy 1, valid accuracy 0.8018
Epoch 361, CIFAR-10 Batch 1:  loss 0.001187, train_accuracy 1, valid accuracy 0.8104
Epoch 361, CIFAR-10 Batch 2:  loss 0.000881, train_accuracy 1, valid accuracy 0.796
Epoch 361, CIFAR-10 Batch 3:  loss 0.002196, train_accuracy 1, valid accuracy 0.7956
Epoch 361, CIFAR-10 Batch 4:  loss 0.000387, train_accuracy 1, valid accuracy 0.8018
Epoch 361, CIFAR-10 Batch 5:  loss 0.001003, train_accuracy 1, valid accuracy 0.793
Epoch 362, CIFAR-10 Batch 1:  loss 0.001249, train_accuracy 1, valid accuracy 0.8064
Epoch 362, CIFAR-10 Batch 2:  loss 0.001127, train_accuracy 1, valid accuracy 0.8098
Epoch 362, CIFAR-10 Batch 3:  loss 0.002722, train_accuracy 1, valid accuracy 0.7968
Epoch 362, CIFAR-10 Batch 4:  loss 0.002265, train_accuracy 1, valid accuracy 0.8038
Epoch 362, CIFAR-10 Batch 5:  loss 0.001424, train_accuracy 1, valid accuracy 0.8014
Epoch 363, CIFAR-10 Batch 1:  loss 0.001128, train_accuracy 1, valid accuracy 0.8032
Epoch 363, CIFAR-10 Batch 2:  loss 0.001198, train_accuracy 1, valid accuracy 0.7964
Epoch 363, CIFAR-10 Batch 3:  loss 0.001022, train_accuracy 1, valid accuracy 0.8032
Epoch 363, CIFAR-10 Batch 4:  loss 0.003821, train_accuracy 1, valid accuracy 0.7922
Epoch 363, CIFAR-10 Batch 5:  loss 0.001804, train_accuracy 1, valid accuracy 0.802
Epoch 364, CIFAR-10 Batch 1:  loss 0.000798, train_accuracy 1, valid accuracy 0.8012
Epoch 364, CIFAR-10 Batch 2:  loss 0.001194, train_accuracy 1, valid accuracy 0.802
Epoch 364, CIFAR-10 Batch 3:  loss 0.000576, train_accuracy 1, valid accuracy 0.7986
Epoch 364, CIFAR-10 Batch 4:  loss 0.001582, train_accuracy 1, valid accuracy 0.805
Epoch 364, CIFAR-10 Batch 5:  loss 0.004348, train_accuracy 1, valid accuracy 0.7956
Epoch 365, CIFAR-10 Batch 1:  loss 0.003890, train_accuracy 1, valid accuracy 0.7958
Epoch 365, CIFAR-10 Batch 2:  loss 0.003250, train_accuracy 1, valid accuracy 0.8012
Epoch 365, CIFAR-10 Batch 3:  loss 0.001596, train_accuracy 1, valid accuracy 0.8092
Epoch 365, CIFAR-10 Batch 4:  loss 0.001640, train_accuracy 1, valid accuracy 0.8058
Epoch 365, CIFAR-10 Batch 5:  loss 0.000931, train_accuracy 1, valid accuracy 0.8036
Epoch 366, CIFAR-10 Batch 1:  loss 0.001320, train_accuracy 1, valid accuracy 0.8032
Epoch 366, CIFAR-10 Batch 2:  loss 0.001849, train_accuracy 1, valid accuracy 0.7932
Epoch 366, CIFAR-10 Batch 3:  loss 0.001745, train_accuracy 1, valid accuracy 0.7786
Epoch 366, CIFAR-10 Batch 4:  loss 0.001647, train_accuracy 1, valid accuracy 0.8026
Epoch 366, CIFAR-10 Batch 5:  loss 0.000453, train_accuracy 1, valid accuracy 0.8078
Epoch 367, CIFAR-10 Batch 1:  loss 0.000647, train_accuracy 1, valid accuracy 0.8056
Epoch 367, CIFAR-10 Batch 2:  loss 0.004358, train_accuracy 1, valid accuracy 0.7864
Epoch 367, CIFAR-10 Batch 3:  loss 0.001196, train_accuracy 1, valid accuracy 0.8052
Epoch 367, CIFAR-10 Batch 4:  loss 0.003313, train_accuracy 1, valid accuracy 0.7992
Epoch 367, CIFAR-10 Batch 5:  loss 0.000537, train_accuracy 1, valid accuracy 0.8048
Epoch 368, CIFAR-10 Batch 1:  loss 0.000744, train_accuracy 1, valid accuracy 0.8064
Epoch 368, CIFAR-10 Batch 2:  loss 0.000599, train_accuracy 1, valid accuracy 0.805
Epoch 368, CIFAR-10 Batch 3:  loss 0.000892, train_accuracy 1, valid accuracy 0.809
Epoch 368, CIFAR-10 Batch 4:  loss 0.002171, train_accuracy 1, valid accuracy 0.798
Epoch 368, CIFAR-10 Batch 5:  loss 0.001365, train_accuracy 1, valid accuracy 0.8096
Epoch 369, CIFAR-10 Batch 1:  loss 0.000693, train_accuracy 1, valid accuracy 0.8112
Epoch 369, CIFAR-10 Batch 2:  loss 0.002661, train_accuracy 1, valid accuracy 0.807
Epoch 369, CIFAR-10 Batch 3:  loss 0.001380, train_accuracy 1, valid accuracy 0.8116
Epoch 369, CIFAR-10 Batch 4:  loss 0.002227, train_accuracy 1, valid accuracy 0.8034
Epoch 369, CIFAR-10 Batch 5:  loss 0.004325, train_accuracy 1, valid accuracy 0.7848
Epoch 370, CIFAR-10 Batch 1:  loss 0.000224, train_accuracy 1, valid accuracy 0.805
Epoch 370, CIFAR-10 Batch 2:  loss 0.001797, train_accuracy 1, valid accuracy 0.8036
Epoch 370, CIFAR-10 Batch 3:  loss 0.000579, train_accuracy 1, valid accuracy 0.8086
Epoch 370, CIFAR-10 Batch 4:  loss 0.000813, train_accuracy 1, valid accuracy 0.8054
Epoch 370, CIFAR-10 Batch 5:  loss 0.007627, train_accuracy 1, valid accuracy 0.7964
Epoch 371, CIFAR-10 Batch 1:  loss 0.000299, train_accuracy 1, valid accuracy 0.8166
Epoch 371, CIFAR-10 Batch 2:  loss 0.001739, train_accuracy 1, valid accuracy 0.7966
Epoch 371, CIFAR-10 Batch 3:  loss 0.000670, train_accuracy 1, valid accuracy 0.7988
Epoch 371, CIFAR-10 Batch 4:  loss 0.001229, train_accuracy 1, valid accuracy 0.8058
Epoch 371, CIFAR-10 Batch 5:  loss 0.000743, train_accuracy 1, valid accuracy 0.7934
Epoch 372, CIFAR-10 Batch 1:  loss 0.000480, train_accuracy 1, valid accuracy 0.806
Epoch 372, CIFAR-10 Batch 2:  loss 0.001994, train_accuracy 1, valid accuracy 0.8002
Epoch 372, CIFAR-10 Batch 3:  loss 0.001136, train_accuracy 1, valid accuracy 0.8042
Epoch 372, CIFAR-10 Batch 4:  loss 0.002272, train_accuracy 1, valid accuracy 0.8104
Epoch 372, CIFAR-10 Batch 5:  loss 0.001313, train_accuracy 1, valid accuracy 0.804
Epoch 373, CIFAR-10 Batch 1:  loss 0.000378, train_accuracy 1, valid accuracy 0.8116
Epoch 373, CIFAR-10 Batch 2:  loss 0.007029, train_accuracy 1, valid accuracy 0.7986
Epoch 373, CIFAR-10 Batch 3:  loss 0.002063, train_accuracy 1, valid accuracy 0.8076
Epoch 373, CIFAR-10 Batch 4:  loss 0.000945, train_accuracy 1, valid accuracy 0.8038
Epoch 373, CIFAR-10 Batch 5:  loss 0.000639, train_accuracy 1, valid accuracy 0.815
Epoch 374, CIFAR-10 Batch 1:  loss 0.001400, train_accuracy 1, valid accuracy 0.8098
Epoch 374, CIFAR-10 Batch 2:  loss 0.000739, train_accuracy 1, valid accuracy 0.7956
Epoch 374, CIFAR-10 Batch 3:  loss 0.002670, train_accuracy 1, valid accuracy 0.8144
Epoch 374, CIFAR-10 Batch 4:  loss 0.001582, train_accuracy 1, valid accuracy 0.8032
Epoch 374, CIFAR-10 Batch 5:  loss 0.000505, train_accuracy 1, valid accuracy 0.8012
Epoch 375, CIFAR-10 Batch 1:  loss 0.000730, train_accuracy 1, valid accuracy 0.8058
Epoch 375, CIFAR-10 Batch 2:  loss 0.001274, train_accuracy 1, valid accuracy 0.8026
Epoch 375, CIFAR-10 Batch 3:  loss 0.000909, train_accuracy 1, valid accuracy 0.806
Epoch 375, CIFAR-10 Batch 4:  loss 0.002208, train_accuracy 1, valid accuracy 0.8026
Epoch 375, CIFAR-10 Batch 5:  loss 0.000577, train_accuracy 1, valid accuracy 0.804
Epoch 376, CIFAR-10 Batch 1:  loss 0.001070, train_accuracy 1, valid accuracy 0.8084
Epoch 376, CIFAR-10 Batch 2:  loss 0.001355, train_accuracy 1, valid accuracy 0.8082
Epoch 376, CIFAR-10 Batch 3:  loss 0.001276, train_accuracy 1, valid accuracy 0.7974
Epoch 376, CIFAR-10 Batch 4:  loss 0.001064, train_accuracy 1, valid accuracy 0.7928
Epoch 376, CIFAR-10 Batch 5:  loss 0.003417, train_accuracy 1, valid accuracy 0.7902
Epoch 377, CIFAR-10 Batch 1:  loss 0.000651, train_accuracy 1, valid accuracy 0.803
Epoch 377, CIFAR-10 Batch 2:  loss 0.002309, train_accuracy 1, valid accuracy 0.799
Epoch 377, CIFAR-10 Batch 3:  loss 0.000260, train_accuracy 1, valid accuracy 0.8048
Epoch 377, CIFAR-10 Batch 4:  loss 0.000302, train_accuracy 1, valid accuracy 0.8072
Epoch 377, CIFAR-10 Batch 5:  loss 0.000425, train_accuracy 1, valid accuracy 0.8038
Epoch 378, CIFAR-10 Batch 1:  loss 0.000863, train_accuracy 1, valid accuracy 0.8054
Epoch 378, CIFAR-10 Batch 2:  loss 0.007873, train_accuracy 1, valid accuracy 0.7998
Epoch 378, CIFAR-10 Batch 3:  loss 0.000667, train_accuracy 1, valid accuracy 0.7984
Epoch 378, CIFAR-10 Batch 4:  loss 0.002745, train_accuracy 1, valid accuracy 0.8074
Epoch 378, CIFAR-10 Batch 5:  loss 0.000424, train_accuracy 1, valid accuracy 0.8026
Epoch 379, CIFAR-10 Batch 1:  loss 0.000598, train_accuracy 1, valid accuracy 0.798
Epoch 379, CIFAR-10 Batch 2:  loss 0.001031, train_accuracy 1, valid accuracy 0.8042
Epoch 379, CIFAR-10 Batch 3:  loss 0.002254, train_accuracy 1, valid accuracy 0.7926
Epoch 379, CIFAR-10 Batch 4:  loss 0.002511, train_accuracy 1, valid accuracy 0.8022
Epoch 379, CIFAR-10 Batch 5:  loss 0.000758, train_accuracy 1, valid accuracy 0.8062
Epoch 380, CIFAR-10 Batch 1:  loss 0.000795, train_accuracy 1, valid accuracy 0.8064
Epoch 380, CIFAR-10 Batch 2:  loss 0.004044, train_accuracy 1, valid accuracy 0.8006
Epoch 380, CIFAR-10 Batch 3:  loss 0.001328, train_accuracy 1, valid accuracy 0.7968
Epoch 380, CIFAR-10 Batch 4:  loss 0.002217, train_accuracy 1, valid accuracy 0.8038
Epoch 380, CIFAR-10 Batch 5:  loss 0.003779, train_accuracy 1, valid accuracy 0.7944
Epoch 381, CIFAR-10 Batch 1:  loss 0.001117, train_accuracy 1, valid accuracy 0.801
Epoch 381, CIFAR-10 Batch 2:  loss 0.001746, train_accuracy 1, valid accuracy 0.7876
Epoch 381, CIFAR-10 Batch 3:  loss 0.000897, train_accuracy 1, valid accuracy 0.8006
Epoch 381, CIFAR-10 Batch 4:  loss 0.001175, train_accuracy 1, valid accuracy 0.8058
Epoch 381, CIFAR-10 Batch 5:  loss 0.003854, train_accuracy 1, valid accuracy 0.7934
Epoch 382, CIFAR-10 Batch 1:  loss 0.001377, train_accuracy 1, valid accuracy 0.8012
Epoch 382, CIFAR-10 Batch 2:  loss 0.002545, train_accuracy 1, valid accuracy 0.797
Epoch 382, CIFAR-10 Batch 3:  loss 0.000334, train_accuracy 1, valid accuracy 0.8066
Epoch 382, CIFAR-10 Batch 4:  loss 0.001119, train_accuracy 1, valid accuracy 0.799
Epoch 382, CIFAR-10 Batch 5:  loss 0.000449, train_accuracy 1, valid accuracy 0.8054
Epoch 383, CIFAR-10 Batch 1:  loss 0.000342, train_accuracy 1, valid accuracy 0.804
Epoch 383, CIFAR-10 Batch 2:  loss 0.000771, train_accuracy 1, valid accuracy 0.8018
Epoch 383, CIFAR-10 Batch 3:  loss 0.000294, train_accuracy 1, valid accuracy 0.8032
Epoch 383, CIFAR-10 Batch 4:  loss 0.001296, train_accuracy 1, valid accuracy 0.7998
Epoch 383, CIFAR-10 Batch 5:  loss 0.001225, train_accuracy 1, valid accuracy 0.7976
Epoch 384, CIFAR-10 Batch 1:  loss 0.000649, train_accuracy 1, valid accuracy 0.8066
Epoch 384, CIFAR-10 Batch 2:  loss 0.001036, train_accuracy 1, valid accuracy 0.7952
Epoch 384, CIFAR-10 Batch 3:  loss 0.001162, train_accuracy 1, valid accuracy 0.8064
Epoch 384, CIFAR-10 Batch 4:  loss 0.001838, train_accuracy 1, valid accuracy 0.8098
Epoch 384, CIFAR-10 Batch 5:  loss 0.002108, train_accuracy 1, valid accuracy 0.7988
Epoch 385, CIFAR-10 Batch 1:  loss 0.000851, train_accuracy 1, valid accuracy 0.806
Epoch 385, CIFAR-10 Batch 2:  loss 0.002127, train_accuracy 1, valid accuracy 0.8014
Epoch 385, CIFAR-10 Batch 3:  loss 0.001148, train_accuracy 1, valid accuracy 0.8062
Epoch 385, CIFAR-10 Batch 4:  loss 0.001162, train_accuracy 1, valid accuracy 0.802
Epoch 385, CIFAR-10 Batch 5:  loss 0.018321, train_accuracy 1, valid accuracy 0.7728
Epoch 386, CIFAR-10 Batch 1:  loss 0.000481, train_accuracy 1, valid accuracy 0.8028
Epoch 386, CIFAR-10 Batch 2:  loss 0.000794, train_accuracy 1, valid accuracy 0.7968
Epoch 386, CIFAR-10 Batch 3:  loss 0.001132, train_accuracy 1, valid accuracy 0.7996
Epoch 386, CIFAR-10 Batch 4:  loss 0.001368, train_accuracy 1, valid accuracy 0.8044
Epoch 386, CIFAR-10 Batch 5:  loss 0.000721, train_accuracy 1, valid accuracy 0.7966
Epoch 387, CIFAR-10 Batch 1:  loss 0.001079, train_accuracy 1, valid accuracy 0.8044
Epoch 387, CIFAR-10 Batch 2:  loss 0.002011, train_accuracy 1, valid accuracy 0.7932
Epoch 387, CIFAR-10 Batch 3:  loss 0.000308, train_accuracy 1, valid accuracy 0.8042
Epoch 387, CIFAR-10 Batch 4:  loss 0.001377, train_accuracy 1, valid accuracy 0.8044
Epoch 387, CIFAR-10 Batch 5:  loss 0.001465, train_accuracy 1, valid accuracy 0.8004
Epoch 388, CIFAR-10 Batch 1:  loss 0.000723, train_accuracy 1, valid accuracy 0.8062
Epoch 388, CIFAR-10 Batch 2:  loss 0.000327, train_accuracy 1, valid accuracy 0.8062
Epoch 388, CIFAR-10 Batch 3:  loss 0.000330, train_accuracy 1, valid accuracy 0.7958
Epoch 388, CIFAR-10 Batch 4:  loss 0.000979, train_accuracy 1, valid accuracy 0.8094
Epoch 388, CIFAR-10 Batch 5:  loss 0.001558, train_accuracy 1, valid accuracy 0.8018
Epoch 389, CIFAR-10 Batch 1:  loss 0.001154, train_accuracy 1, valid accuracy 0.802
Epoch 389, CIFAR-10 Batch 2:  loss 0.000201, train_accuracy 1, valid accuracy 0.8074
Epoch 389, CIFAR-10 Batch 3:  loss 0.000205, train_accuracy 1, valid accuracy 0.806
Epoch 389, CIFAR-10 Batch 4:  loss 0.001734, train_accuracy 1, valid accuracy 0.805
Epoch 389, CIFAR-10 Batch 5:  loss 0.000769, train_accuracy 1, valid accuracy 0.7926
Epoch 390, CIFAR-10 Batch 1:  loss 0.000387, train_accuracy 1, valid accuracy 0.8062
Epoch 390, CIFAR-10 Batch 2:  loss 0.001827, train_accuracy 1, valid accuracy 0.7982
Epoch 390, CIFAR-10 Batch 3:  loss 0.000558, train_accuracy 1, valid accuracy 0.8006
Epoch 390, CIFAR-10 Batch 4:  loss 0.000979, train_accuracy 1, valid accuracy 0.8026
Epoch 390, CIFAR-10 Batch 5:  loss 0.001734, train_accuracy 1, valid accuracy 0.7966
Epoch 391, CIFAR-10 Batch 1:  loss 0.000402, train_accuracy 1, valid accuracy 0.8074
Epoch 391, CIFAR-10 Batch 2:  loss 0.000512, train_accuracy 1, valid accuracy 0.8058
Epoch 391, CIFAR-10 Batch 3:  loss 0.000420, train_accuracy 1, valid accuracy 0.8066
Epoch 391, CIFAR-10 Batch 4:  loss 0.001541, train_accuracy 1, valid accuracy 0.8078
Epoch 391, CIFAR-10 Batch 5:  loss 0.000411, train_accuracy 1, valid accuracy 0.8102
Epoch 392, CIFAR-10 Batch 1:  loss 0.000739, train_accuracy 1, valid accuracy 0.7952
Epoch 392, CIFAR-10 Batch 2:  loss 0.000697, train_accuracy 1, valid accuracy 0.804
Epoch 392, CIFAR-10 Batch 3:  loss 0.000829, train_accuracy 1, valid accuracy 0.8056
Epoch 392, CIFAR-10 Batch 4:  loss 0.001583, train_accuracy 1, valid accuracy 0.8034
Epoch 392, CIFAR-10 Batch 5:  loss 0.000353, train_accuracy 1, valid accuracy 0.8066
Epoch 393, CIFAR-10 Batch 1:  loss 0.000990, train_accuracy 1, valid accuracy 0.7992
Epoch 393, CIFAR-10 Batch 2:  loss 0.000881, train_accuracy 1, valid accuracy 0.7992
Epoch 393, CIFAR-10 Batch 3:  loss 0.000910, train_accuracy 1, valid accuracy 0.8018
Epoch 393, CIFAR-10 Batch 4:  loss 0.001681, train_accuracy 1, valid accuracy 0.8032
Epoch 393, CIFAR-10 Batch 5:  loss 0.000242, train_accuracy 1, valid accuracy 0.8056
Epoch 394, CIFAR-10 Batch 1:  loss 0.000524, train_accuracy 1, valid accuracy 0.8098
Epoch 394, CIFAR-10 Batch 2:  loss 0.001264, train_accuracy 1, valid accuracy 0.808
Epoch 394, CIFAR-10 Batch 3:  loss 0.001144, train_accuracy 1, valid accuracy 0.7992
Epoch 394, CIFAR-10 Batch 4:  loss 0.001961, train_accuracy 1, valid accuracy 0.7936
Epoch 394, CIFAR-10 Batch 5:  loss 0.002525, train_accuracy 1, valid accuracy 0.7972
Epoch 395, CIFAR-10 Batch 1:  loss 0.000679, train_accuracy 1, valid accuracy 0.8074
Epoch 395, CIFAR-10 Batch 2:  loss 0.004278, train_accuracy 1, valid accuracy 0.7924
Epoch 395, CIFAR-10 Batch 3:  loss 0.000528, train_accuracy 1, valid accuracy 0.7956
Epoch 395, CIFAR-10 Batch 4:  loss 0.002812, train_accuracy 1, valid accuracy 0.797
Epoch 395, CIFAR-10 Batch 5:  loss 0.000427, train_accuracy 1, valid accuracy 0.8004
Epoch 396, CIFAR-10 Batch 1:  loss 0.000291, train_accuracy 1, valid accuracy 0.8054
Epoch 396, CIFAR-10 Batch 2:  loss 0.000769, train_accuracy 1, valid accuracy 0.7912
Epoch 396, CIFAR-10 Batch 3:  loss 0.000581, train_accuracy 1, valid accuracy 0.7952
Epoch 396, CIFAR-10 Batch 4:  loss 0.000639, train_accuracy 1, valid accuracy 0.7968
Epoch 396, CIFAR-10 Batch 5:  loss 0.000705, train_accuracy 1, valid accuracy 0.793
Epoch 397, CIFAR-10 Batch 1:  loss 0.000650, train_accuracy 1, valid accuracy 0.808
Epoch 397, CIFAR-10 Batch 2:  loss 0.001522, train_accuracy 1, valid accuracy 0.8014
Epoch 397, CIFAR-10 Batch 3:  loss 0.000175, train_accuracy 1, valid accuracy 0.7962
Epoch 397, CIFAR-10 Batch 4:  loss 0.001365, train_accuracy 1, valid accuracy 0.7988
Epoch 397, CIFAR-10 Batch 5:  loss 0.002032, train_accuracy 1, valid accuracy 0.8082
Epoch 398, CIFAR-10 Batch 1:  loss 0.000624, train_accuracy 1, valid accuracy 0.809
Epoch 398, CIFAR-10 Batch 2:  loss 0.000414, train_accuracy 1, valid accuracy 0.7994
Epoch 398, CIFAR-10 Batch 3:  loss 0.000495, train_accuracy 1, valid accuracy 0.792
Epoch 398, CIFAR-10 Batch 4:  loss 0.000710, train_accuracy 1, valid accuracy 0.8044
Epoch 398, CIFAR-10 Batch 5:  loss 0.000595, train_accuracy 1, valid accuracy 0.8104
Epoch 399, CIFAR-10 Batch 1:  loss 0.001179, train_accuracy 1, valid accuracy 0.8096
Epoch 399, CIFAR-10 Batch 2:  loss 0.001976, train_accuracy 1, valid accuracy 0.7942
Epoch 399, CIFAR-10 Batch 3:  loss 0.000210, train_accuracy 1, valid accuracy 0.8054
Epoch 399, CIFAR-10 Batch 4:  loss 0.000944, train_accuracy 1, valid accuracy 0.7974
Epoch 399, CIFAR-10 Batch 5:  loss 0.001107, train_accuracy 1, valid accuracy 0.7986
Epoch 400, CIFAR-10 Batch 1:  loss 0.000529, train_accuracy 1, valid accuracy 0.8064
Epoch 400, CIFAR-10 Batch 2:  loss 0.000414, train_accuracy 1, valid accuracy 0.8088
Epoch 400, CIFAR-10 Batch 3:  loss 0.001068, train_accuracy 1, valid accuracy 0.8026
Epoch 400, CIFAR-10 Batch 4:  loss 0.001821, train_accuracy 1, valid accuracy 0.8004
Epoch 400, CIFAR-10 Batch 5:  loss 0.001128, train_accuracy 1, valid accuracy 0.8068
Epoch 401, CIFAR-10 Batch 1:  loss 0.000690, train_accuracy 1, valid accuracy 0.8068
Epoch 401, CIFAR-10 Batch 2:  loss 0.000609, train_accuracy 1, valid accuracy 0.807
Epoch 401, CIFAR-10 Batch 3:  loss 0.002669, train_accuracy 1, valid accuracy 0.7952
Epoch 401, CIFAR-10 Batch 4:  loss 0.002475, train_accuracy 1, valid accuracy 0.797
Epoch 401, CIFAR-10 Batch 5:  loss 0.001004, train_accuracy 1, valid accuracy 0.7938
Epoch 402, CIFAR-10 Batch 1:  loss 0.000697, train_accuracy 1, valid accuracy 0.8018
Epoch 402, CIFAR-10 Batch 2:  loss 0.002274, train_accuracy 1, valid accuracy 0.7964
Epoch 402, CIFAR-10 Batch 3:  loss 0.020076, train_accuracy 0.975, valid accuracy 0.7936
Epoch 402, CIFAR-10 Batch 4:  loss 0.005178, train_accuracy 1, valid accuracy 0.8038
Epoch 402, CIFAR-10 Batch 5:  loss 0.000736, train_accuracy 1, valid accuracy 0.802
Epoch 403, CIFAR-10 Batch 1:  loss 0.002028, train_accuracy 1, valid accuracy 0.8098
Epoch 403, CIFAR-10 Batch 2:  loss 0.000407, train_accuracy 1, valid accuracy 0.8026
Epoch 403, CIFAR-10 Batch 3:  loss 0.000595, train_accuracy 1, valid accuracy 0.8032
Epoch 403, CIFAR-10 Batch 4:  loss 0.001172, train_accuracy 1, valid accuracy 0.7952
Epoch 403, CIFAR-10 Batch 5:  loss 0.001435, train_accuracy 1, valid accuracy 0.7918
Epoch 404, CIFAR-10 Batch 1:  loss 0.001880, train_accuracy 1, valid accuracy 0.7932
Epoch 404, CIFAR-10 Batch 2:  loss 0.001239, train_accuracy 1, valid accuracy 0.8102
Epoch 404, CIFAR-10 Batch 3:  loss 0.000672, train_accuracy 1, valid accuracy 0.8004
Epoch 404, CIFAR-10 Batch 4:  loss 0.000648, train_accuracy 1, valid accuracy 0.8042
Epoch 404, CIFAR-10 Batch 5:  loss 0.000590, train_accuracy 1, valid accuracy 0.811
Epoch 405, CIFAR-10 Batch 1:  loss 0.002005, train_accuracy 1, valid accuracy 0.8024
Epoch 405, CIFAR-10 Batch 2:  loss 0.000959, train_accuracy 1, valid accuracy 0.7976
Epoch 405, CIFAR-10 Batch 3:  loss 0.000518, train_accuracy 1, valid accuracy 0.8052
Epoch 405, CIFAR-10 Batch 4:  loss 0.001151, train_accuracy 1, valid accuracy 0.8054
Epoch 405, CIFAR-10 Batch 5:  loss 0.002045, train_accuracy 1, valid accuracy 0.7986
Epoch 406, CIFAR-10 Batch 1:  loss 0.000651, train_accuracy 1, valid accuracy 0.807
Epoch 406, CIFAR-10 Batch 2:  loss 0.001643, train_accuracy 1, valid accuracy 0.7964
Epoch 406, CIFAR-10 Batch 3:  loss 0.000982, train_accuracy 1, valid accuracy 0.8018
Epoch 406, CIFAR-10 Batch 4:  loss 0.001279, train_accuracy 1, valid accuracy 0.7968
Epoch 406, CIFAR-10 Batch 5:  loss 0.000668, train_accuracy 1, valid accuracy 0.8044
Epoch 407, CIFAR-10 Batch 1:  loss 0.000817, train_accuracy 1, valid accuracy 0.8034
Epoch 407, CIFAR-10 Batch 2:  loss 0.001301, train_accuracy 1, valid accuracy 0.8042
Epoch 407, CIFAR-10 Batch 3:  loss 0.000295, train_accuracy 1, valid accuracy 0.81
Epoch 407, CIFAR-10 Batch 4:  loss 0.001787, train_accuracy 1, valid accuracy 0.8032
Epoch 407, CIFAR-10 Batch 5:  loss 0.000944, train_accuracy 1, valid accuracy 0.806
Epoch 408, CIFAR-10 Batch 1:  loss 0.000534, train_accuracy 1, valid accuracy 0.8112
Epoch 408, CIFAR-10 Batch 2:  loss 0.002888, train_accuracy 1, valid accuracy 0.792
Epoch 408, CIFAR-10 Batch 3:  loss 0.001842, train_accuracy 1, valid accuracy 0.7994
Epoch 408, CIFAR-10 Batch 4:  loss 0.000912, train_accuracy 1, valid accuracy 0.8112
Epoch 408, CIFAR-10 Batch 5:  loss 0.000363, train_accuracy 1, valid accuracy 0.8026
Epoch 409, CIFAR-10 Batch 1:  loss 0.000450, train_accuracy 1, valid accuracy 0.7972
Epoch 409, CIFAR-10 Batch 2:  loss 0.000517, train_accuracy 1, valid accuracy 0.8078
Epoch 409, CIFAR-10 Batch 3:  loss 0.001701, train_accuracy 1, valid accuracy 0.8038
Epoch 409, CIFAR-10 Batch 4:  loss 0.001052, train_accuracy 1, valid accuracy 0.795
Epoch 409, CIFAR-10 Batch 5:  loss 0.000747, train_accuracy 1, valid accuracy 0.7972
Epoch 410, CIFAR-10 Batch 1:  loss 0.000680, train_accuracy 1, valid accuracy 0.8058
Epoch 410, CIFAR-10 Batch 2:  loss 0.000467, train_accuracy 1, valid accuracy 0.8078
Epoch 410, CIFAR-10 Batch 3:  loss 0.002402, train_accuracy 1, valid accuracy 0.802
Epoch 410, CIFAR-10 Batch 4:  loss 0.001578, train_accuracy 1, valid accuracy 0.8106
Epoch 410, CIFAR-10 Batch 5:  loss 0.000671, train_accuracy 1, valid accuracy 0.7974
Epoch 411, CIFAR-10 Batch 1:  loss 0.000663, train_accuracy 1, valid accuracy 0.8128
Epoch 411, CIFAR-10 Batch 2:  loss 0.000626, train_accuracy 1, valid accuracy 0.806
Epoch 411, CIFAR-10 Batch 3:  loss 0.001102, train_accuracy 1, valid accuracy 0.8036
Epoch 411, CIFAR-10 Batch 4:  loss 0.001425, train_accuracy 1, valid accuracy 0.8042
Epoch 411, CIFAR-10 Batch 5:  loss 0.000235, train_accuracy 1, valid accuracy 0.8082
Epoch 412, CIFAR-10 Batch 1:  loss 0.001335, train_accuracy 1, valid accuracy 0.8036
Epoch 412, CIFAR-10 Batch 2:  loss 0.000216, train_accuracy 1, valid accuracy 0.8064
Epoch 412, CIFAR-10 Batch 3:  loss 0.001251, train_accuracy 1, valid accuracy 0.797
Epoch 412, CIFAR-10 Batch 4:  loss 0.001038, train_accuracy 1, valid accuracy 0.8086
Epoch 412, CIFAR-10 Batch 5:  loss 0.000401, train_accuracy 1, valid accuracy 0.7998
Epoch 413, CIFAR-10 Batch 1:  loss 0.000518, train_accuracy 1, valid accuracy 0.8068
Epoch 413, CIFAR-10 Batch 2:  loss 0.001029, train_accuracy 1, valid accuracy 0.7956
Epoch 413, CIFAR-10 Batch 3:  loss 0.001265, train_accuracy 1, valid accuracy 0.8
Epoch 413, CIFAR-10 Batch 4:  loss 0.002791, train_accuracy 1, valid accuracy 0.8078
Epoch 413, CIFAR-10 Batch 5:  loss 0.000481, train_accuracy 1, valid accuracy 0.8058
Epoch 414, CIFAR-10 Batch 1:  loss 0.000496, train_accuracy 1, valid accuracy 0.8058
Epoch 414, CIFAR-10 Batch 2:  loss 0.006153, train_accuracy 1, valid accuracy 0.791
Epoch 414, CIFAR-10 Batch 3:  loss 0.000356, train_accuracy 1, valid accuracy 0.8036
Epoch 414, CIFAR-10 Batch 4:  loss 0.000919, train_accuracy 1, valid accuracy 0.8052
Epoch 414, CIFAR-10 Batch 5:  loss 0.000388, train_accuracy 1, valid accuracy 0.8014
Epoch 415, CIFAR-10 Batch 1:  loss 0.000262, train_accuracy 1, valid accuracy 0.8038
Epoch 415, CIFAR-10 Batch 2:  loss 0.000392, train_accuracy 1, valid accuracy 0.8074
Epoch 415, CIFAR-10 Batch 3:  loss 0.001485, train_accuracy 1, valid accuracy 0.7914
Epoch 415, CIFAR-10 Batch 4:  loss 0.000895, train_accuracy 1, valid accuracy 0.8026
Epoch 415, CIFAR-10 Batch 5:  loss 0.002265, train_accuracy 1, valid accuracy 0.7992
Epoch 416, CIFAR-10 Batch 1:  loss 0.000873, train_accuracy 1, valid accuracy 0.805
Epoch 416, CIFAR-10 Batch 2:  loss 0.000542, train_accuracy 1, valid accuracy 0.8058
Epoch 416, CIFAR-10 Batch 3:  loss 0.000129, train_accuracy 1, valid accuracy 0.8058
Epoch 416, CIFAR-10 Batch 4:  loss 0.001432, train_accuracy 1, valid accuracy 0.7936
Epoch 416, CIFAR-10 Batch 5:  loss 0.000564, train_accuracy 1, valid accuracy 0.8066
Epoch 417, CIFAR-10 Batch 1:  loss 0.001010, train_accuracy 1, valid accuracy 0.8002
Epoch 417, CIFAR-10 Batch 2:  loss 0.001182, train_accuracy 1, valid accuracy 0.8014
Epoch 417, CIFAR-10 Batch 3:  loss 0.000298, train_accuracy 1, valid accuracy 0.812
Epoch 417, CIFAR-10 Batch 4:  loss 0.000782, train_accuracy 1, valid accuracy 0.8092
Epoch 417, CIFAR-10 Batch 5:  loss 0.000569, train_accuracy 1, valid accuracy 0.805
Epoch 418, CIFAR-10 Batch 1:  loss 0.001166, train_accuracy 1, valid accuracy 0.79
Epoch 418, CIFAR-10 Batch 2:  loss 0.000187, train_accuracy 1, valid accuracy 0.7984
Epoch 418, CIFAR-10 Batch 3:  loss 0.000500, train_accuracy 1, valid accuracy 0.8022
Epoch 418, CIFAR-10 Batch 4:  loss 0.000517, train_accuracy 1, valid accuracy 0.8052
Epoch 418, CIFAR-10 Batch 5:  loss 0.000215, train_accuracy 1, valid accuracy 0.8078
Epoch 419, CIFAR-10 Batch 1:  loss 0.000302, train_accuracy 1, valid accuracy 0.8108
Epoch 419, CIFAR-10 Batch 2:  loss 0.001472, train_accuracy 1, valid accuracy 0.7962
Epoch 419, CIFAR-10 Batch 3:  loss 0.000479, train_accuracy 1, valid accuracy 0.805
Epoch 419, CIFAR-10 Batch 4:  loss 0.004737, train_accuracy 1, valid accuracy 0.8048
Epoch 419, CIFAR-10 Batch 5:  loss 0.000091, train_accuracy 1, valid accuracy 0.8038
Epoch 420, CIFAR-10 Batch 1:  loss 0.001515, train_accuracy 1, valid accuracy 0.7996
Epoch 420, CIFAR-10 Batch 2:  loss 0.001321, train_accuracy 1, valid accuracy 0.797
Epoch 420, CIFAR-10 Batch 3:  loss 0.000608, train_accuracy 1, valid accuracy 0.7994
Epoch 420, CIFAR-10 Batch 4:  loss 0.000913, train_accuracy 1, valid accuracy 0.8082
Epoch 420, CIFAR-10 Batch 5:  loss 0.000452, train_accuracy 1, valid accuracy 0.799
Epoch 421, CIFAR-10 Batch 1:  loss 0.001024, train_accuracy 1, valid accuracy 0.8092
Epoch 421, CIFAR-10 Batch 2:  loss 0.000634, train_accuracy 1, valid accuracy 0.8064
Epoch 421, CIFAR-10 Batch 3:  loss 0.000551, train_accuracy 1, valid accuracy 0.8066
Epoch 421, CIFAR-10 Batch 4:  loss 0.001356, train_accuracy 1, valid accuracy 0.8032
Epoch 421, CIFAR-10 Batch 5:  loss 0.000428, train_accuracy 1, valid accuracy 0.8096
Epoch 422, CIFAR-10 Batch 1:  loss 0.000612, train_accuracy 1, valid accuracy 0.814
Epoch 422, CIFAR-10 Batch 2:  loss 0.001959, train_accuracy 1, valid accuracy 0.7858
Epoch 422, CIFAR-10 Batch 3:  loss 0.006481, train_accuracy 1, valid accuracy 0.8034
Epoch 422, CIFAR-10 Batch 4:  loss 0.011520, train_accuracy 1, valid accuracy 0.7934
Epoch 422, CIFAR-10 Batch 5:  loss 0.005725, train_accuracy 1, valid accuracy 0.7862
Epoch 423, CIFAR-10 Batch 1:  loss 0.000902, train_accuracy 1, valid accuracy 0.8026
Epoch 423, CIFAR-10 Batch 2:  loss 0.000601, train_accuracy 1, valid accuracy 0.7948
Epoch 423, CIFAR-10 Batch 3:  loss 0.001071, train_accuracy 1, valid accuracy 0.804
Epoch 423, CIFAR-10 Batch 4:  loss 0.001017, train_accuracy 1, valid accuracy 0.804
Epoch 423, CIFAR-10 Batch 5:  loss 0.000950, train_accuracy 1, valid accuracy 0.8088
Epoch 424, CIFAR-10 Batch 1:  loss 0.002431, train_accuracy 1, valid accuracy 0.8028
Epoch 424, CIFAR-10 Batch 2:  loss 0.000682, train_accuracy 1, valid accuracy 0.8046
Epoch 424, CIFAR-10 Batch 3:  loss 0.000233, train_accuracy 1, valid accuracy 0.806
Epoch 424, CIFAR-10 Batch 4:  loss 0.000695, train_accuracy 1, valid accuracy 0.8052
Epoch 424, CIFAR-10 Batch 5:  loss 0.000844, train_accuracy 1, valid accuracy 0.8012
Epoch 425, CIFAR-10 Batch 1:  loss 0.000592, train_accuracy 1, valid accuracy 0.806
Epoch 425, CIFAR-10 Batch 2:  loss 0.000721, train_accuracy 1, valid accuracy 0.8066
Epoch 425, CIFAR-10 Batch 3:  loss 0.000969, train_accuracy 1, valid accuracy 0.8002
Epoch 425, CIFAR-10 Batch 4:  loss 0.001084, train_accuracy 1, valid accuracy 0.8108
Epoch 425, CIFAR-10 Batch 5:  loss 0.000270, train_accuracy 1, valid accuracy 0.8074
Epoch 426, CIFAR-10 Batch 1:  loss 0.000417, train_accuracy 1, valid accuracy 0.8116
Epoch 426, CIFAR-10 Batch 2:  loss 0.000670, train_accuracy 1, valid accuracy 0.808
Epoch 426, CIFAR-10 Batch 3:  loss 0.000714, train_accuracy 1, valid accuracy 0.8026
Epoch 426, CIFAR-10 Batch 4:  loss 0.000838, train_accuracy 1, valid accuracy 0.8054
Epoch 426, CIFAR-10 Batch 5:  loss 0.000369, train_accuracy 1, valid accuracy 0.807
Epoch 427, CIFAR-10 Batch 1:  loss 0.000578, train_accuracy 1, valid accuracy 0.8098
Epoch 427, CIFAR-10 Batch 2:  loss 0.000499, train_accuracy 1, valid accuracy 0.8004
Epoch 427, CIFAR-10 Batch 3:  loss 0.000200, train_accuracy 1, valid accuracy 0.8052
Epoch 427, CIFAR-10 Batch 4:  loss 0.000679, train_accuracy 1, valid accuracy 0.8054
Epoch 427, CIFAR-10 Batch 5:  loss 0.000230, train_accuracy 1, valid accuracy 0.8048
Epoch 428, CIFAR-10 Batch 1:  loss 0.000866, train_accuracy 1, valid accuracy 0.8058
Epoch 428, CIFAR-10 Batch 2:  loss 0.000277, train_accuracy 1, valid accuracy 0.8034
Epoch 428, CIFAR-10 Batch 3:  loss 0.001010, train_accuracy 1, valid accuracy 0.796
Epoch 428, CIFAR-10 Batch 4:  loss 0.000355, train_accuracy 1, valid accuracy 0.8032
Epoch 428, CIFAR-10 Batch 5:  loss 0.000302, train_accuracy 1, valid accuracy 0.801
Epoch 429, CIFAR-10 Batch 1:  loss 0.001441, train_accuracy 1, valid accuracy 0.7938
Epoch 429, CIFAR-10 Batch 2:  loss 0.000559, train_accuracy 1, valid accuracy 0.8006
Epoch 429, CIFAR-10 Batch 3:  loss 0.000321, train_accuracy 1, valid accuracy 0.8008
Epoch 429, CIFAR-10 Batch 4:  loss 0.001180, train_accuracy 1, valid accuracy 0.807
Epoch 429, CIFAR-10 Batch 5:  loss 0.001507, train_accuracy 1, valid accuracy 0.8
Epoch 430, CIFAR-10 Batch 1:  loss 0.000835, train_accuracy 1, valid accuracy 0.806
Epoch 430, CIFAR-10 Batch 2:  loss 0.000811, train_accuracy 1, valid accuracy 0.7876
Epoch 430, CIFAR-10 Batch 3:  loss 0.000274, train_accuracy 1, valid accuracy 0.803
Epoch 430, CIFAR-10 Batch 4:  loss 0.000458, train_accuracy 1, valid accuracy 0.8042
Epoch 430, CIFAR-10 Batch 5:  loss 0.001870, train_accuracy 1, valid accuracy 0.7952
Epoch 431, CIFAR-10 Batch 1:  loss 0.000563, train_accuracy 1, valid accuracy 0.805
Epoch 431, CIFAR-10 Batch 2:  loss 0.000518, train_accuracy 1, valid accuracy 0.8058
Epoch 431, CIFAR-10 Batch 3:  loss 0.001143, train_accuracy 1, valid accuracy 0.812
Epoch 431, CIFAR-10 Batch 4:  loss 0.000427, train_accuracy 1, valid accuracy 0.815
Epoch 431, CIFAR-10 Batch 5:  loss 0.000575, train_accuracy 1, valid accuracy 0.7998
Epoch 432, CIFAR-10 Batch 1:  loss 0.000283, train_accuracy 1, valid accuracy 0.8
Epoch 432, CIFAR-10 Batch 2:  loss 0.002934, train_accuracy 1, valid accuracy 0.796
Epoch 432, CIFAR-10 Batch 3:  loss 0.000763, train_accuracy 1, valid accuracy 0.802
Epoch 432, CIFAR-10 Batch 4:  loss 0.001022, train_accuracy 1, valid accuracy 0.7978
Epoch 432, CIFAR-10 Batch 5:  loss 0.000150, train_accuracy 1, valid accuracy 0.8072
Epoch 433, CIFAR-10 Batch 1:  loss 0.000560, train_accuracy 1, valid accuracy 0.8054
Epoch 433, CIFAR-10 Batch 2:  loss 0.001241, train_accuracy 1, valid accuracy 0.8092
Epoch 433, CIFAR-10 Batch 3:  loss 0.000850, train_accuracy 1, valid accuracy 0.8056
Epoch 433, CIFAR-10 Batch 4:  loss 0.000570, train_accuracy 1, valid accuracy 0.8068
Epoch 433, CIFAR-10 Batch 5:  loss 0.000482, train_accuracy 1, valid accuracy 0.807
Epoch 434, CIFAR-10 Batch 1:  loss 0.000803, train_accuracy 1, valid accuracy 0.801
Epoch 434, CIFAR-10 Batch 2:  loss 0.002409, train_accuracy 1, valid accuracy 0.8016
Epoch 434, CIFAR-10 Batch 3:  loss 0.000615, train_accuracy 1, valid accuracy 0.8032
Epoch 434, CIFAR-10 Batch 4:  loss 0.000409, train_accuracy 1, valid accuracy 0.8116
Epoch 434, CIFAR-10 Batch 5:  loss 0.001604, train_accuracy 1, valid accuracy 0.8026
Epoch 435, CIFAR-10 Batch 1:  loss 0.000212, train_accuracy 1, valid accuracy 0.8104
Epoch 435, CIFAR-10 Batch 2:  loss 0.001303, train_accuracy 1, valid accuracy 0.7926
Epoch 435, CIFAR-10 Batch 3:  loss 0.000958, train_accuracy 1, valid accuracy 0.8014
Epoch 435, CIFAR-10 Batch 4:  loss 0.000406, train_accuracy 1, valid accuracy 0.8078
Epoch 435, CIFAR-10 Batch 5:  loss 0.001369, train_accuracy 1, valid accuracy 0.7806
Epoch 436, CIFAR-10 Batch 1:  loss 0.000935, train_accuracy 1, valid accuracy 0.8048
Epoch 436, CIFAR-10 Batch 2:  loss 0.000451, train_accuracy 1, valid accuracy 0.7982
Epoch 436, CIFAR-10 Batch 3:  loss 0.000682, train_accuracy 1, valid accuracy 0.793
Epoch 436, CIFAR-10 Batch 4:  loss 0.001037, train_accuracy 1, valid accuracy 0.7952
Epoch 436, CIFAR-10 Batch 5:  loss 0.000286, train_accuracy 1, valid accuracy 0.805
Epoch 437, CIFAR-10 Batch 1:  loss 0.000528, train_accuracy 1, valid accuracy 0.807
Epoch 437, CIFAR-10 Batch 2:  loss 0.001077, train_accuracy 1, valid accuracy 0.8012
Epoch 437, CIFAR-10 Batch 3:  loss 0.000644, train_accuracy 1, valid accuracy 0.7952
Epoch 437, CIFAR-10 Batch 4:  loss 0.000247, train_accuracy 1, valid accuracy 0.8046
Epoch 437, CIFAR-10 Batch 5:  loss 0.000509, train_accuracy 1, valid accuracy 0.7846
Epoch 438, CIFAR-10 Batch 1:  loss 0.000407, train_accuracy 1, valid accuracy 0.8012
Epoch 438, CIFAR-10 Batch 2:  loss 0.000647, train_accuracy 1, valid accuracy 0.8022
Epoch 438, CIFAR-10 Batch 3:  loss 0.000911, train_accuracy 1, valid accuracy 0.7946
Epoch 438, CIFAR-10 Batch 4:  loss 0.000393, train_accuracy 1, valid accuracy 0.8034
Epoch 438, CIFAR-10 Batch 5:  loss 0.001223, train_accuracy 1, valid accuracy 0.789
Epoch 439, CIFAR-10 Batch 1:  loss 0.000493, train_accuracy 1, valid accuracy 0.808
Epoch 439, CIFAR-10 Batch 2:  loss 0.000109, train_accuracy 1, valid accuracy 0.8048
Epoch 439, CIFAR-10 Batch 3:  loss 0.000231, train_accuracy 1, valid accuracy 0.8054
Epoch 439, CIFAR-10 Batch 4:  loss 0.000700, train_accuracy 1, valid accuracy 0.7998
Epoch 439, CIFAR-10 Batch 5:  loss 0.000326, train_accuracy 1, valid accuracy 0.8052
Epoch 440, CIFAR-10 Batch 1:  loss 0.000295, train_accuracy 1, valid accuracy 0.8012
Epoch 440, CIFAR-10 Batch 2:  loss 0.000328, train_accuracy 1, valid accuracy 0.8068
Epoch 440, CIFAR-10 Batch 3:  loss 0.000405, train_accuracy 1, valid accuracy 0.7944
Epoch 440, CIFAR-10 Batch 4:  loss 0.000843, train_accuracy 1, valid accuracy 0.7984
Epoch 440, CIFAR-10 Batch 5:  loss 0.000272, train_accuracy 1, valid accuracy 0.799
Epoch 441, CIFAR-10 Batch 1:  loss 0.000665, train_accuracy 1, valid accuracy 0.8014
Epoch 441, CIFAR-10 Batch 2:  loss 0.000445, train_accuracy 1, valid accuracy 0.7984
Epoch 441, CIFAR-10 Batch 3:  loss 0.001021, train_accuracy 1, valid accuracy 0.7962
Epoch 441, CIFAR-10 Batch 4:  loss 0.000421, train_accuracy 1, valid accuracy 0.8044
Epoch 441, CIFAR-10 Batch 5:  loss 0.000840, train_accuracy 1, valid accuracy 0.802
Epoch 442, CIFAR-10 Batch 1:  loss 0.000284, train_accuracy 1, valid accuracy 0.805
Epoch 442, CIFAR-10 Batch 2:  loss 0.000149, train_accuracy 1, valid accuracy 0.8044
Epoch 442, CIFAR-10 Batch 3:  loss 0.000307, train_accuracy 1, valid accuracy 0.8028
Epoch 442, CIFAR-10 Batch 4:  loss 0.000701, train_accuracy 1, valid accuracy 0.8056
Epoch 442, CIFAR-10 Batch 5:  loss 0.000416, train_accuracy 1, valid accuracy 0.8004
Epoch 443, CIFAR-10 Batch 1:  loss 0.000727, train_accuracy 1, valid accuracy 0.8
Epoch 443, CIFAR-10 Batch 2:  loss 0.000369, train_accuracy 1, valid accuracy 0.8038
Epoch 443, CIFAR-10 Batch 3:  loss 0.000548, train_accuracy 1, valid accuracy 0.799
Epoch 443, CIFAR-10 Batch 4:  loss 0.000371, train_accuracy 1, valid accuracy 0.8058
Epoch 443, CIFAR-10 Batch 5:  loss 0.000251, train_accuracy 1, valid accuracy 0.8004
Epoch 444, CIFAR-10 Batch 1:  loss 0.000341, train_accuracy 1, valid accuracy 0.811
Epoch 444, CIFAR-10 Batch 2:  loss 0.000624, train_accuracy 1, valid accuracy 0.8022
Epoch 444, CIFAR-10 Batch 3:  loss 0.003491, train_accuracy 1, valid accuracy 0.792
Epoch 444, CIFAR-10 Batch 4:  loss 0.007713, train_accuracy 1, valid accuracy 0.7872
Epoch 444, CIFAR-10 Batch 5:  loss 0.000401, train_accuracy 1, valid accuracy 0.8074
Epoch 445, CIFAR-10 Batch 1:  loss 0.001077, train_accuracy 1, valid accuracy 0.8004
Epoch 445, CIFAR-10 Batch 2:  loss 0.002994, train_accuracy 1, valid accuracy 0.7892
Epoch 445, CIFAR-10 Batch 3:  loss 0.000391, train_accuracy 1, valid accuracy 0.8
Epoch 445, CIFAR-10 Batch 4:  loss 0.000261, train_accuracy 1, valid accuracy 0.8032
Epoch 445, CIFAR-10 Batch 5:  loss 0.000259, train_accuracy 1, valid accuracy 0.7978
Epoch 446, CIFAR-10 Batch 1:  loss 0.000957, train_accuracy 1, valid accuracy 0.7974
Epoch 446, CIFAR-10 Batch 2:  loss 0.000297, train_accuracy 1, valid accuracy 0.7952
Epoch 446, CIFAR-10 Batch 3:  loss 0.001971, train_accuracy 1, valid accuracy 0.7944
Epoch 446, CIFAR-10 Batch 4:  loss 0.000337, train_accuracy 1, valid accuracy 0.802
Epoch 446, CIFAR-10 Batch 5:  loss 0.000328, train_accuracy 1, valid accuracy 0.8068
Epoch 447, CIFAR-10 Batch 1:  loss 0.000378, train_accuracy 1, valid accuracy 0.803
Epoch 447, CIFAR-10 Batch 2:  loss 0.001038, train_accuracy 1, valid accuracy 0.7938
Epoch 447, CIFAR-10 Batch 3:  loss 0.000287, train_accuracy 1, valid accuracy 0.801
Epoch 447, CIFAR-10 Batch 4:  loss 0.000388, train_accuracy 1, valid accuracy 0.8098
Epoch 447, CIFAR-10 Batch 5:  loss 0.000354, train_accuracy 1, valid accuracy 0.8114
Epoch 448, CIFAR-10 Batch 1:  loss 0.001350, train_accuracy 1, valid accuracy 0.7986
Epoch 448, CIFAR-10 Batch 2:  loss 0.000489, train_accuracy 1, valid accuracy 0.7976
Epoch 448, CIFAR-10 Batch 3:  loss 0.001375, train_accuracy 1, valid accuracy 0.8004
Epoch 448, CIFAR-10 Batch 4:  loss 0.000295, train_accuracy 1, valid accuracy 0.8104
Epoch 448, CIFAR-10 Batch 5:  loss 0.003021, train_accuracy 1, valid accuracy 0.8052
Epoch 449, CIFAR-10 Batch 1:  loss 0.000361, train_accuracy 1, valid accuracy 0.8086
Epoch 449, CIFAR-10 Batch 2:  loss 0.000103, train_accuracy 1, valid accuracy 0.8082
Epoch 449, CIFAR-10 Batch 3:  loss 0.000536, train_accuracy 1, valid accuracy 0.8052
Epoch 449, CIFAR-10 Batch 4:  loss 0.000138, train_accuracy 1, valid accuracy 0.804
Epoch 449, CIFAR-10 Batch 5:  loss 0.000315, train_accuracy 1, valid accuracy 0.81
Epoch 450, CIFAR-10 Batch 1:  loss 0.000275, train_accuracy 1, valid accuracy 0.8126
Epoch 450, CIFAR-10 Batch 2:  loss 0.000259, train_accuracy 1, valid accuracy 0.8022
Epoch 450, CIFAR-10 Batch 3:  loss 0.000435, train_accuracy 1, valid accuracy 0.808
Epoch 450, CIFAR-10 Batch 4:  loss 0.000181, train_accuracy 1, valid accuracy 0.8074
Epoch 450, CIFAR-10 Batch 5:  loss 0.000384, train_accuracy 1, valid accuracy 0.79
Epoch 451, CIFAR-10 Batch 1:  loss 0.000283, train_accuracy 1, valid accuracy 0.8068
Epoch 451, CIFAR-10 Batch 2:  loss 0.000290, train_accuracy 1, valid accuracy 0.8046
Epoch 451, CIFAR-10 Batch 3:  loss 0.000850, train_accuracy 1, valid accuracy 0.7992
Epoch 451, CIFAR-10 Batch 4:  loss 0.000537, train_accuracy 1, valid accuracy 0.789
Epoch 451, CIFAR-10 Batch 5:  loss 0.000369, train_accuracy 1, valid accuracy 0.7964
Epoch 452, CIFAR-10 Batch 1:  loss 0.000400, train_accuracy 1, valid accuracy 0.8056
Epoch 452, CIFAR-10 Batch 2:  loss 0.001063, train_accuracy 1, valid accuracy 0.7918
Epoch 452, CIFAR-10 Batch 3:  loss 0.002266, train_accuracy 1, valid accuracy 0.7964
Epoch 452, CIFAR-10 Batch 4:  loss 0.000667, train_accuracy 1, valid accuracy 0.7992
Epoch 452, CIFAR-10 Batch 5:  loss 0.000095, train_accuracy 1, valid accuracy 0.8056
Epoch 453, CIFAR-10 Batch 1:  loss 0.001625, train_accuracy 1, valid accuracy 0.8022
Epoch 453, CIFAR-10 Batch 2:  loss 0.001545, train_accuracy 1, valid accuracy 0.8034
Epoch 453, CIFAR-10 Batch 3:  loss 0.000446, train_accuracy 1, valid accuracy 0.8018
Epoch 453, CIFAR-10 Batch 4:  loss 0.000126, train_accuracy 1, valid accuracy 0.8018
Epoch 453, CIFAR-10 Batch 5:  loss 0.001247, train_accuracy 1, valid accuracy 0.7914
Epoch 454, CIFAR-10 Batch 1:  loss 0.000454, train_accuracy 1, valid accuracy 0.7956
Epoch 454, CIFAR-10 Batch 2:  loss 0.000342, train_accuracy 1, valid accuracy 0.798
Epoch 454, CIFAR-10 Batch 3:  loss 0.001678, train_accuracy 1, valid accuracy 0.7962
Epoch 454, CIFAR-10 Batch 4:  loss 0.000314, train_accuracy 1, valid accuracy 0.796
Epoch 454, CIFAR-10 Batch 5:  loss 0.002219, train_accuracy 1, valid accuracy 0.7936
Epoch 455, CIFAR-10 Batch 1:  loss 0.000653, train_accuracy 1, valid accuracy 0.796
Epoch 455, CIFAR-10 Batch 2:  loss 0.000451, train_accuracy 1, valid accuracy 0.7976
Epoch 455, CIFAR-10 Batch 3:  loss 0.002190, train_accuracy 1, valid accuracy 0.8008
Epoch 455, CIFAR-10 Batch 4:  loss 0.000425, train_accuracy 1, valid accuracy 0.7992
Epoch 455, CIFAR-10 Batch 5:  loss 0.001291, train_accuracy 1, valid accuracy 0.8006
Epoch 456, CIFAR-10 Batch 1:  loss 0.000491, train_accuracy 1, valid accuracy 0.8014
Epoch 456, CIFAR-10 Batch 2:  loss 0.041548, train_accuracy 0.975, valid accuracy 0.7724
Epoch 456, CIFAR-10 Batch 3:  loss 0.006766, train_accuracy 1, valid accuracy 0.7814
Epoch 456, CIFAR-10 Batch 4:  loss 0.002069, train_accuracy 1, valid accuracy 0.7858
Epoch 456, CIFAR-10 Batch 5:  loss 0.001423, train_accuracy 1, valid accuracy 0.8
Epoch 457, CIFAR-10 Batch 1:  loss 0.001198, train_accuracy 1, valid accuracy 0.7936
Epoch 457, CIFAR-10 Batch 2:  loss 0.002636, train_accuracy 1, valid accuracy 0.8066
Epoch 457, CIFAR-10 Batch 3:  loss 0.000836, train_accuracy 1, valid accuracy 0.799
Epoch 457, CIFAR-10 Batch 4:  loss 0.000389, train_accuracy 1, valid accuracy 0.7918
Epoch 457, CIFAR-10 Batch 5:  loss 0.000594, train_accuracy 1, valid accuracy 0.8034
Epoch 458, CIFAR-10 Batch 1:  loss 0.000233, train_accuracy 1, valid accuracy 0.8066
Epoch 458, CIFAR-10 Batch 2:  loss 0.000317, train_accuracy 1, valid accuracy 0.8012
Epoch 458, CIFAR-10 Batch 3:  loss 0.002126, train_accuracy 1, valid accuracy 0.7932
Epoch 458, CIFAR-10 Batch 4:  loss 0.000238, train_accuracy 1, valid accuracy 0.8002
Epoch 458, CIFAR-10 Batch 5:  loss 0.000457, train_accuracy 1, valid accuracy 0.8068
Epoch 459, CIFAR-10 Batch 1:  loss 0.000744, train_accuracy 1, valid accuracy 0.809
Epoch 459, CIFAR-10 Batch 2:  loss 0.001899, train_accuracy 1, valid accuracy 0.8018
Epoch 459, CIFAR-10 Batch 3:  loss 0.000277, train_accuracy 1, valid accuracy 0.8018
Epoch 459, CIFAR-10 Batch 4:  loss 0.000316, train_accuracy 1, valid accuracy 0.801
Epoch 459, CIFAR-10 Batch 5:  loss 0.000399, train_accuracy 1, valid accuracy 0.798
Epoch 460, CIFAR-10 Batch 1:  loss 0.000225, train_accuracy 1, valid accuracy 0.8044
Epoch 460, CIFAR-10 Batch 2:  loss 0.000412, train_accuracy 1, valid accuracy 0.7954
Epoch 460, CIFAR-10 Batch 3:  loss 0.000704, train_accuracy 1, valid accuracy 0.8
Epoch 460, CIFAR-10 Batch 4:  loss 0.000328, train_accuracy 1, valid accuracy 0.7934
Epoch 460, CIFAR-10 Batch 5:  loss 0.000908, train_accuracy 1, valid accuracy 0.7912
Epoch 461, CIFAR-10 Batch 1:  loss 0.000220, train_accuracy 1, valid accuracy 0.8076
Epoch 461, CIFAR-10 Batch 2:  loss 0.000765, train_accuracy 1, valid accuracy 0.7994
Epoch 461, CIFAR-10 Batch 3:  loss 0.000320, train_accuracy 1, valid accuracy 0.8032
Epoch 461, CIFAR-10 Batch 4:  loss 0.000933, train_accuracy 1, valid accuracy 0.801
Epoch 461, CIFAR-10 Batch 5:  loss 0.000302, train_accuracy 1, valid accuracy 0.8042
Epoch 462, CIFAR-10 Batch 1:  loss 0.000379, train_accuracy 1, valid accuracy 0.8032
Epoch 462, CIFAR-10 Batch 2:  loss 0.000073, train_accuracy 1, valid accuracy 0.8012
Epoch 462, CIFAR-10 Batch 3:  loss 0.000289, train_accuracy 1, valid accuracy 0.8012
Epoch 462, CIFAR-10 Batch 4:  loss 0.000204, train_accuracy 1, valid accuracy 0.8122
Epoch 462, CIFAR-10 Batch 5:  loss 0.000118, train_accuracy 1, valid accuracy 0.802
Epoch 463, CIFAR-10 Batch 1:  loss 0.000788, train_accuracy 1, valid accuracy 0.8072
Epoch 463, CIFAR-10 Batch 2:  loss 0.000096, train_accuracy 1, valid accuracy 0.8028
Epoch 463, CIFAR-10 Batch 3:  loss 0.001333, train_accuracy 1, valid accuracy 0.7936
Epoch 463, CIFAR-10 Batch 4:  loss 0.000194, train_accuracy 1, valid accuracy 0.8054
Epoch 463, CIFAR-10 Batch 5:  loss 0.000089, train_accuracy 1, valid accuracy 0.8022
Epoch 464, CIFAR-10 Batch 1:  loss 0.000254, train_accuracy 1, valid accuracy 0.8068
Epoch 464, CIFAR-10 Batch 2:  loss 0.000246, train_accuracy 1, valid accuracy 0.8088
Epoch 464, CIFAR-10 Batch 3:  loss 0.000437, train_accuracy 1, valid accuracy 0.8004
Epoch 464, CIFAR-10 Batch 4:  loss 0.000397, train_accuracy 1, valid accuracy 0.803
Epoch 464, CIFAR-10 Batch 5:  loss 0.000714, train_accuracy 1, valid accuracy 0.8084
Epoch 465, CIFAR-10 Batch 1:  loss 0.000317, train_accuracy 1, valid accuracy 0.8068
Epoch 465, CIFAR-10 Batch 2:  loss 0.000238, train_accuracy 1, valid accuracy 0.7992
Epoch 465, CIFAR-10 Batch 3:  loss 0.000432, train_accuracy 1, valid accuracy 0.7984
Epoch 465, CIFAR-10 Batch 4:  loss 0.000639, train_accuracy 1, valid accuracy 0.806
Epoch 465, CIFAR-10 Batch 5:  loss 0.000374, train_accuracy 1, valid accuracy 0.8026
Epoch 466, CIFAR-10 Batch 1:  loss 0.000807, train_accuracy 1, valid accuracy 0.8064
Epoch 466, CIFAR-10 Batch 2:  loss 0.000108, train_accuracy 1, valid accuracy 0.8016
Epoch 466, CIFAR-10 Batch 3:  loss 0.000161, train_accuracy 1, valid accuracy 0.801
Epoch 466, CIFAR-10 Batch 4:  loss 0.010699, train_accuracy 1, valid accuracy 0.791
Epoch 466, CIFAR-10 Batch 5:  loss 0.000288, train_accuracy 1, valid accuracy 0.8
Epoch 467, CIFAR-10 Batch 1:  loss 0.000105, train_accuracy 1, valid accuracy 0.8088
Epoch 467, CIFAR-10 Batch 2:  loss 0.000254, train_accuracy 1, valid accuracy 0.8002
Epoch 467, CIFAR-10 Batch 3:  loss 0.001017, train_accuracy 1, valid accuracy 0.8072
Epoch 467, CIFAR-10 Batch 4:  loss 0.000541, train_accuracy 1, valid accuracy 0.8024
Epoch 467, CIFAR-10 Batch 5:  loss 0.000874, train_accuracy 1, valid accuracy 0.7988
Epoch 468, CIFAR-10 Batch 1:  loss 0.001042, train_accuracy 1, valid accuracy 0.7994
Epoch 468, CIFAR-10 Batch 2:  loss 0.007858, train_accuracy 1, valid accuracy 0.7842
Epoch 468, CIFAR-10 Batch 3:  loss 0.000321, train_accuracy 1, valid accuracy 0.8
Epoch 468, CIFAR-10 Batch 4:  loss 0.000203, train_accuracy 1, valid accuracy 0.7954
Epoch 468, CIFAR-10 Batch 5:  loss 0.003228, train_accuracy 1, valid accuracy 0.7944
Epoch 469, CIFAR-10 Batch 1:  loss 0.000325, train_accuracy 1, valid accuracy 0.799
Epoch 469, CIFAR-10 Batch 2:  loss 0.000583, train_accuracy 1, valid accuracy 0.7882
Epoch 469, CIFAR-10 Batch 3:  loss 0.001213, train_accuracy 1, valid accuracy 0.796
Epoch 469, CIFAR-10 Batch 4:  loss 0.000199, train_accuracy 1, valid accuracy 0.8024
Epoch 469, CIFAR-10 Batch 5:  loss 0.000331, train_accuracy 1, valid accuracy 0.8036
Epoch 470, CIFAR-10 Batch 1:  loss 0.000440, train_accuracy 1, valid accuracy 0.7924
Epoch 470, CIFAR-10 Batch 2:  loss 0.000438, train_accuracy 1, valid accuracy 0.8
Epoch 470, CIFAR-10 Batch 3:  loss 0.000150, train_accuracy 1, valid accuracy 0.7982
Epoch 470, CIFAR-10 Batch 4:  loss 0.000741, train_accuracy 1, valid accuracy 0.8008
Epoch 470, CIFAR-10 Batch 5:  loss 0.000197, train_accuracy 1, valid accuracy 0.8036
Epoch 471, CIFAR-10 Batch 1:  loss 0.000428, train_accuracy 1, valid accuracy 0.7994
Epoch 471, CIFAR-10 Batch 2:  loss 0.000133, train_accuracy 1, valid accuracy 0.791
Epoch 471, CIFAR-10 Batch 3:  loss 0.000152, train_accuracy 1, valid accuracy 0.7998
Epoch 471, CIFAR-10 Batch 4:  loss 0.000712, train_accuracy 1, valid accuracy 0.7862
Epoch 471, CIFAR-10 Batch 5:  loss 0.000898, train_accuracy 1, valid accuracy 0.791
Epoch 472, CIFAR-10 Batch 1:  loss 0.000212, train_accuracy 1, valid accuracy 0.8052
Epoch 472, CIFAR-10 Batch 2:  loss 0.000231, train_accuracy 1, valid accuracy 0.8028
Epoch 472, CIFAR-10 Batch 3:  loss 0.000517, train_accuracy 1, valid accuracy 0.796
Epoch 472, CIFAR-10 Batch 4:  loss 0.000671, train_accuracy 1, valid accuracy 0.7978
Epoch 472, CIFAR-10 Batch 5:  loss 0.000652, train_accuracy 1, valid accuracy 0.805
Epoch 473, CIFAR-10 Batch 1:  loss 0.000177, train_accuracy 1, valid accuracy 0.7954
Epoch 473, CIFAR-10 Batch 2:  loss 0.000375, train_accuracy 1, valid accuracy 0.7952
Epoch 473, CIFAR-10 Batch 3:  loss 0.000480, train_accuracy 1, valid accuracy 0.7998
Epoch 473, CIFAR-10 Batch 4:  loss 0.000261, train_accuracy 1, valid accuracy 0.7966
Epoch 473, CIFAR-10 Batch 5:  loss 0.000672, train_accuracy 1, valid accuracy 0.801
Epoch 474, CIFAR-10 Batch 1:  loss 0.000291, train_accuracy 1, valid accuracy 0.8052
Epoch 474, CIFAR-10 Batch 2:  loss 0.000179, train_accuracy 1, valid accuracy 0.7998
Epoch 474, CIFAR-10 Batch 3:  loss 0.000644, train_accuracy 1, valid accuracy 0.8014
Epoch 474, CIFAR-10 Batch 4:  loss 0.000234, train_accuracy 1, valid accuracy 0.7978
Epoch 474, CIFAR-10 Batch 5:  loss 0.000541, train_accuracy 1, valid accuracy 0.8006
Epoch 475, CIFAR-10 Batch 1:  loss 0.000192, train_accuracy 1, valid accuracy 0.8026
Epoch 475, CIFAR-10 Batch 2:  loss 0.000322, train_accuracy 1, valid accuracy 0.8006
Epoch 475, CIFAR-10 Batch 3:  loss 0.001986, train_accuracy 1, valid accuracy 0.786
Epoch 475, CIFAR-10 Batch 4:  loss 0.000434, train_accuracy 1, valid accuracy 0.7938
Epoch 475, CIFAR-10 Batch 5:  loss 0.000415, train_accuracy 1, valid accuracy 0.8016
Epoch 476, CIFAR-10 Batch 1:  loss 0.000426, train_accuracy 1, valid accuracy 0.807
Epoch 476, CIFAR-10 Batch 2:  loss 0.001592, train_accuracy 1, valid accuracy 0.7952
Epoch 476, CIFAR-10 Batch 3:  loss 0.000590, train_accuracy 1, valid accuracy 0.798
Epoch 476, CIFAR-10 Batch 4:  loss 0.011954, train_accuracy 1, valid accuracy 0.7786
Epoch 476, CIFAR-10 Batch 5:  loss 0.001215, train_accuracy 1, valid accuracy 0.794
Epoch 477, CIFAR-10 Batch 1:  loss 0.000469, train_accuracy 1, valid accuracy 0.807
Epoch 477, CIFAR-10 Batch 2:  loss 0.001800, train_accuracy 1, valid accuracy 0.7924
Epoch 477, CIFAR-10 Batch 3:  loss 0.000359, train_accuracy 1, valid accuracy 0.8036
Epoch 477, CIFAR-10 Batch 4:  loss 0.000388, train_accuracy 1, valid accuracy 0.8046
Epoch 477, CIFAR-10 Batch 5:  loss 0.000176, train_accuracy 1, valid accuracy 0.7994
Epoch 478, CIFAR-10 Batch 1:  loss 0.000752, train_accuracy 1, valid accuracy 0.8
Epoch 478, CIFAR-10 Batch 2:  loss 0.001363, train_accuracy 1, valid accuracy 0.7894
Epoch 478, CIFAR-10 Batch 3:  loss 0.000278, train_accuracy 1, valid accuracy 0.7992
Epoch 478, CIFAR-10 Batch 4:  loss 0.000406, train_accuracy 1, valid accuracy 0.7954
Epoch 478, CIFAR-10 Batch 5:  loss 0.000709, train_accuracy 1, valid accuracy 0.8024
Epoch 479, CIFAR-10 Batch 1:  loss 0.000282, train_accuracy 1, valid accuracy 0.804
Epoch 479, CIFAR-10 Batch 2:  loss 0.000605, train_accuracy 1, valid accuracy 0.7924
Epoch 479, CIFAR-10 Batch 3:  loss 0.000576, train_accuracy 1, valid accuracy 0.8048
Epoch 479, CIFAR-10 Batch 4:  loss 0.000227, train_accuracy 1, valid accuracy 0.806
Epoch 479, CIFAR-10 Batch 5:  loss 0.000285, train_accuracy 1, valid accuracy 0.808
Epoch 480, CIFAR-10 Batch 1:  loss 0.000434, train_accuracy 1, valid accuracy 0.8052
Epoch 480, CIFAR-10 Batch 2:  loss 0.001070, train_accuracy 1, valid accuracy 0.8006
Epoch 480, CIFAR-10 Batch 3:  loss 0.000408, train_accuracy 1, valid accuracy 0.8014
Epoch 480, CIFAR-10 Batch 4:  loss 0.000744, train_accuracy 1, valid accuracy 0.8054
Epoch 480, CIFAR-10 Batch 5:  loss 0.001671, train_accuracy 1, valid accuracy 0.8002
Epoch 481, CIFAR-10 Batch 1:  loss 0.000201, train_accuracy 1, valid accuracy 0.8054
Epoch 481, CIFAR-10 Batch 2:  loss 0.002813, train_accuracy 1, valid accuracy 0.789
Epoch 481, CIFAR-10 Batch 3:  loss 0.000295, train_accuracy 1, valid accuracy 0.7984
Epoch 481, CIFAR-10 Batch 4:  loss 0.000257, train_accuracy 1, valid accuracy 0.7954
Epoch 481, CIFAR-10 Batch 5:  loss 0.000135, train_accuracy 1, valid accuracy 0.8064
Epoch 482, CIFAR-10 Batch 1:  loss 0.000822, train_accuracy 1, valid accuracy 0.79
Epoch 482, CIFAR-10 Batch 2:  loss 0.000684, train_accuracy 1, valid accuracy 0.7894
Epoch 482, CIFAR-10 Batch 3:  loss 0.001564, train_accuracy 1, valid accuracy 0.797
Epoch 482, CIFAR-10 Batch 4:  loss 0.000389, train_accuracy 1, valid accuracy 0.8028
Epoch 482, CIFAR-10 Batch 5:  loss 0.000873, train_accuracy 1, valid accuracy 0.804
Epoch 483, CIFAR-10 Batch 1:  loss 0.000195, train_accuracy 1, valid accuracy 0.801
Epoch 483, CIFAR-10 Batch 2:  loss 0.000476, train_accuracy 1, valid accuracy 0.789
Epoch 483, CIFAR-10 Batch 3:  loss 0.000121, train_accuracy 1, valid accuracy 0.8018
Epoch 483, CIFAR-10 Batch 4:  loss 0.000196, train_accuracy 1, valid accuracy 0.8058
Epoch 483, CIFAR-10 Batch 5:  loss 0.001458, train_accuracy 1, valid accuracy 0.795
Epoch 484, CIFAR-10 Batch 1:  loss 0.000197, train_accuracy 1, valid accuracy 0.806
Epoch 484, CIFAR-10 Batch 2:  loss 0.000329, train_accuracy 1, valid accuracy 0.8058
Epoch 484, CIFAR-10 Batch 3:  loss 0.001170, train_accuracy 1, valid accuracy 0.7962
Epoch 484, CIFAR-10 Batch 4:  loss 0.000174, train_accuracy 1, valid accuracy 0.801
Epoch 484, CIFAR-10 Batch 5:  loss 0.000799, train_accuracy 1, valid accuracy 0.7944
Epoch 485, CIFAR-10 Batch 1:  loss 0.000836, train_accuracy 1, valid accuracy 0.7906
Epoch 485, CIFAR-10 Batch 2:  loss 0.000109, train_accuracy 1, valid accuracy 0.8046
Epoch 485, CIFAR-10 Batch 3:  loss 0.000159, train_accuracy 1, valid accuracy 0.8026
Epoch 485, CIFAR-10 Batch 4:  loss 0.000587, train_accuracy 1, valid accuracy 0.7992
Epoch 485, CIFAR-10 Batch 5:  loss 0.000208, train_accuracy 1, valid accuracy 0.8004
Epoch 486, CIFAR-10 Batch 1:  loss 0.000354, train_accuracy 1, valid accuracy 0.8058
Epoch 486, CIFAR-10 Batch 2:  loss 0.000039, train_accuracy 1, valid accuracy 0.807
Epoch 486, CIFAR-10 Batch 3:  loss 0.000587, train_accuracy 1, valid accuracy 0.809
Epoch 486, CIFAR-10 Batch 4:  loss 0.000064, train_accuracy 1, valid accuracy 0.799
Epoch 486, CIFAR-10 Batch 5:  loss 0.001471, train_accuracy 1, valid accuracy 0.7938
Epoch 487, CIFAR-10 Batch 1:  loss 0.001044, train_accuracy 1, valid accuracy 0.791
Epoch 487, CIFAR-10 Batch 2:  loss 0.001432, train_accuracy 1, valid accuracy 0.784
Epoch 487, CIFAR-10 Batch 3:  loss 0.000557, train_accuracy 1, valid accuracy 0.7904
Epoch 487, CIFAR-10 Batch 4:  loss 0.000213, train_accuracy 1, valid accuracy 0.8024
Epoch 487, CIFAR-10 Batch 5:  loss 0.000327, train_accuracy 1, valid accuracy 0.8102
Epoch 488, CIFAR-10 Batch 1:  loss 0.000370, train_accuracy 1, valid accuracy 0.8086
Epoch 488, CIFAR-10 Batch 2:  loss 0.000363, train_accuracy 1, valid accuracy 0.8008
Epoch 488, CIFAR-10 Batch 3:  loss 0.004039, train_accuracy 1, valid accuracy 0.7852
Epoch 488, CIFAR-10 Batch 4:  loss 0.000295, train_accuracy 1, valid accuracy 0.8006
Epoch 488, CIFAR-10 Batch 5:  loss 0.000527, train_accuracy 1, valid accuracy 0.8096
Epoch 489, CIFAR-10 Batch 1:  loss 0.001133, train_accuracy 1, valid accuracy 0.8058
Epoch 489, CIFAR-10 Batch 2:  loss 0.001027, train_accuracy 1, valid accuracy 0.7968
Epoch 489, CIFAR-10 Batch 3:  loss 0.000240, train_accuracy 1, valid accuracy 0.8058
Epoch 489, CIFAR-10 Batch 4:  loss 0.000465, train_accuracy 1, valid accuracy 0.798
Epoch 489, CIFAR-10 Batch 5:  loss 0.001623, train_accuracy 1, valid accuracy 0.7822
Epoch 490, CIFAR-10 Batch 1:  loss 0.000693, train_accuracy 1, valid accuracy 0.8028
Epoch 490, CIFAR-10 Batch 2:  loss 0.000150, train_accuracy 1, valid accuracy 0.7998
Epoch 490, CIFAR-10 Batch 3:  loss 0.000172, train_accuracy 1, valid accuracy 0.7938
Epoch 490, CIFAR-10 Batch 4:  loss 0.000609, train_accuracy 1, valid accuracy 0.7928
Epoch 490, CIFAR-10 Batch 5:  loss 0.000224, train_accuracy 1, valid accuracy 0.7976
Epoch 491, CIFAR-10 Batch 1:  loss 0.001530, train_accuracy 1, valid accuracy 0.798
Epoch 491, CIFAR-10 Batch 2:  loss 0.003040, train_accuracy 1, valid accuracy 0.794
Epoch 491, CIFAR-10 Batch 3:  loss 0.000396, train_accuracy 1, valid accuracy 0.797
Epoch 491, CIFAR-10 Batch 4:  loss 0.000563, train_accuracy 1, valid accuracy 0.791
Epoch 491, CIFAR-10 Batch 5:  loss 0.000116, train_accuracy 1, valid accuracy 0.8106
Epoch 492, CIFAR-10 Batch 1:  loss 0.000230, train_accuracy 1, valid accuracy 0.8036
Epoch 492, CIFAR-10 Batch 2:  loss 0.000786, train_accuracy 1, valid accuracy 0.7942
Epoch 492, CIFAR-10 Batch 3:  loss 0.000376, train_accuracy 1, valid accuracy 0.8018
Epoch 492, CIFAR-10 Batch 4:  loss 0.000246, train_accuracy 1, valid accuracy 0.8046
Epoch 492, CIFAR-10 Batch 5:  loss 0.000473, train_accuracy 1, valid accuracy 0.7998
Epoch 493, CIFAR-10 Batch 1:  loss 0.000143, train_accuracy 1, valid accuracy 0.8072
Epoch 493, CIFAR-10 Batch 2:  loss 0.000051, train_accuracy 1, valid accuracy 0.8046
Epoch 493, CIFAR-10 Batch 3:  loss 0.000896, train_accuracy 1, valid accuracy 0.8074
Epoch 493, CIFAR-10 Batch 4:  loss 0.000060, train_accuracy 1, valid accuracy 0.807
Epoch 493, CIFAR-10 Batch 5:  loss 0.000508, train_accuracy 1, valid accuracy 0.797
Epoch 494, CIFAR-10 Batch 1:  loss 0.000419, train_accuracy 1, valid accuracy 0.8096
Epoch 494, CIFAR-10 Batch 2:  loss 0.000279, train_accuracy 1, valid accuracy 0.7996
Epoch 494, CIFAR-10 Batch 3:  loss 0.000408, train_accuracy 1, valid accuracy 0.8006
Epoch 494, CIFAR-10 Batch 4:  loss 0.000068, train_accuracy 1, valid accuracy 0.8008
Epoch 494, CIFAR-10 Batch 5:  loss 0.000439, train_accuracy 1, valid accuracy 0.8068
Epoch 495, CIFAR-10 Batch 1:  loss 0.000248, train_accuracy 1, valid accuracy 0.7938
Epoch 495, CIFAR-10 Batch 2:  loss 0.000620, train_accuracy 1, valid accuracy 0.804
Epoch 495, CIFAR-10 Batch 3:  loss 0.000935, train_accuracy 1, valid accuracy 0.8004
Epoch 495, CIFAR-10 Batch 4:  loss 0.000616, train_accuracy 1, valid accuracy 0.7932
Epoch 495, CIFAR-10 Batch 5:  loss 0.000224, train_accuracy 1, valid accuracy 0.8048
Epoch 496, CIFAR-10 Batch 1:  loss 0.000099, train_accuracy 1, valid accuracy 0.7996
Epoch 496, CIFAR-10 Batch 2:  loss 0.000278, train_accuracy 1, valid accuracy 0.7944
Epoch 496, CIFAR-10 Batch 3:  loss 0.000126, train_accuracy 1, valid accuracy 0.7974
Epoch 496, CIFAR-10 Batch 4:  loss 0.000559, train_accuracy 1, valid accuracy 0.7972
Epoch 496, CIFAR-10 Batch 5:  loss 0.000316, train_accuracy 1, valid accuracy 0.7882
Epoch 497, CIFAR-10 Batch 1:  loss 0.001704, train_accuracy 1, valid accuracy 0.7936
Epoch 497, CIFAR-10 Batch 2:  loss 0.000635, train_accuracy 1, valid accuracy 0.7836
Epoch 497, CIFAR-10 Batch 3:  loss 0.001936, train_accuracy 1, valid accuracy 0.7928
Epoch 497, CIFAR-10 Batch 4:  loss 0.001140, train_accuracy 1, valid accuracy 0.7864
Epoch 497, CIFAR-10 Batch 5:  loss 0.000284, train_accuracy 1, valid accuracy 0.8054
Epoch 498, CIFAR-10 Batch 1:  loss 0.001089, train_accuracy 1, valid accuracy 0.804
Epoch 498, CIFAR-10 Batch 2:  loss 0.000651, train_accuracy 1, valid accuracy 0.799
Epoch 498, CIFAR-10 Batch 3:  loss 0.000319, train_accuracy 1, valid accuracy 0.8082
Epoch 498, CIFAR-10 Batch 4:  loss 0.000632, train_accuracy 1, valid accuracy 0.8038
Epoch 498, CIFAR-10 Batch 5:  loss 0.000645, train_accuracy 1, valid accuracy 0.7976
Epoch 499, CIFAR-10 Batch 1:  loss 0.000607, train_accuracy 1, valid accuracy 0.8054
Epoch 499, CIFAR-10 Batch 2:  loss 0.000247, train_accuracy 1, valid accuracy 0.804
Epoch 499, CIFAR-10 Batch 3:  loss 0.000888, train_accuracy 1, valid accuracy 0.7994
Epoch 499, CIFAR-10 Batch 4:  loss 0.000103, train_accuracy 1, valid accuracy 0.8024
Epoch 499, CIFAR-10 Batch 5:  loss 0.000029, train_accuracy 1, valid accuracy 0.8072
Epoch 500, CIFAR-10 Batch 1:  loss 0.001546, train_accuracy 1, valid accuracy 0.7982
Epoch 500, CIFAR-10 Batch 2:  loss 0.000358, train_accuracy 1, valid accuracy 0.8126
Epoch 500, CIFAR-10 Batch 3:  loss 0.001190, train_accuracy 1, valid accuracy 0.8048
Epoch 500, CIFAR-10 Batch 4:  loss 0.000143, train_accuracy 1, valid accuracy 0.8012
Epoch 500, CIFAR-10 Batch 5:  loss 0.000428, train_accuracy 1, valid accuracy 0.8004
Epoch 501, CIFAR-10 Batch 1:  loss 0.001698, train_accuracy 1, valid accuracy 0.7978
Epoch 501, CIFAR-10 Batch 2:  loss 0.000526, train_accuracy 1, valid accuracy 0.7926
Epoch 501, CIFAR-10 Batch 3:  loss 0.000227, train_accuracy 1, valid accuracy 0.8012
Epoch 501, CIFAR-10 Batch 4:  loss 0.000337, train_accuracy 1, valid accuracy 0.7842
Epoch 501, CIFAR-10 Batch 5:  loss 0.000098, train_accuracy 1, valid accuracy 0.8024
Epoch 502, CIFAR-10 Batch 1:  loss 0.001311, train_accuracy 1, valid accuracy 0.7922
Epoch 502, CIFAR-10 Batch 2:  loss 0.000507, train_accuracy 1, valid accuracy 0.805
Epoch 502, CIFAR-10 Batch 3:  loss 0.002871, train_accuracy 1, valid accuracy 0.786
Epoch 502, CIFAR-10 Batch 4:  loss 0.000239, train_accuracy 1, valid accuracy 0.8082
Epoch 502, CIFAR-10 Batch 5:  loss 0.000175, train_accuracy 1, valid accuracy 0.8044
Epoch 503, CIFAR-10 Batch 1:  loss 0.000106, train_accuracy 1, valid accuracy 0.8044
Epoch 503, CIFAR-10 Batch 2:  loss 0.000298, train_accuracy 1, valid accuracy 0.8036
Epoch 503, CIFAR-10 Batch 3:  loss 0.000661, train_accuracy 1, valid accuracy 0.7954
Epoch 503, CIFAR-10 Batch 4:  loss 0.000342, train_accuracy 1, valid accuracy 0.8046
Epoch 503, CIFAR-10 Batch 5:  loss 0.000269, train_accuracy 1, valid accuracy 0.801
Epoch 504, CIFAR-10 Batch 1:  loss 0.000120, train_accuracy 1, valid accuracy 0.8084
Epoch 504, CIFAR-10 Batch 2:  loss 0.001110, train_accuracy 1, valid accuracy 0.791
Epoch 504, CIFAR-10 Batch 3:  loss 0.000286, train_accuracy 1, valid accuracy 0.7998
Epoch 504, CIFAR-10 Batch 4:  loss 0.000185, train_accuracy 1, valid accuracy 0.8018
Epoch 504, CIFAR-10 Batch 5:  loss 0.000425, train_accuracy 1, valid accuracy 0.7874
Epoch 505, CIFAR-10 Batch 1:  loss 0.001195, train_accuracy 1, valid accuracy 0.8016
Epoch 505, CIFAR-10 Batch 2:  loss 0.000194, train_accuracy 1, valid accuracy 0.8
Epoch 505, CIFAR-10 Batch 3:  loss 0.000660, train_accuracy 1, valid accuracy 0.8044
Epoch 505, CIFAR-10 Batch 4:  loss 0.000142, train_accuracy 1, valid accuracy 0.8044
Epoch 505, CIFAR-10 Batch 5:  loss 0.000131, train_accuracy 1, valid accuracy 0.8068
Epoch 506, CIFAR-10 Batch 1:  loss 0.000220, train_accuracy 1, valid accuracy 0.8088
Epoch 506, CIFAR-10 Batch 2:  loss 0.000208, train_accuracy 1, valid accuracy 0.8098
Epoch 506, CIFAR-10 Batch 3:  loss 0.000121, train_accuracy 1, valid accuracy 0.8096
Epoch 506, CIFAR-10 Batch 4:  loss 0.000643, train_accuracy 1, valid accuracy 0.8004
Epoch 506, CIFAR-10 Batch 5:  loss 0.000796, train_accuracy 1, valid accuracy 0.7958
Epoch 507, CIFAR-10 Batch 1:  loss 0.000282, train_accuracy 1, valid accuracy 0.804
Epoch 507, CIFAR-10 Batch 2:  loss 0.000822, train_accuracy 1, valid accuracy 0.7996
Epoch 507, CIFAR-10 Batch 3:  loss 0.000308, train_accuracy 1, valid accuracy 0.7994
Epoch 507, CIFAR-10 Batch 4:  loss 0.000233, train_accuracy 1, valid accuracy 0.8104
Epoch 507, CIFAR-10 Batch 5:  loss 0.000161, train_accuracy 1, valid accuracy 0.804
Epoch 508, CIFAR-10 Batch 1:  loss 0.000643, train_accuracy 1, valid accuracy 0.8002
Epoch 508, CIFAR-10 Batch 2:  loss 0.006860, train_accuracy 1, valid accuracy 0.782
Epoch 508, CIFAR-10 Batch 3:  loss 0.000261, train_accuracy 1, valid accuracy 0.8026
Epoch 508, CIFAR-10 Batch 4:  loss 0.000307, train_accuracy 1, valid accuracy 0.8084
Epoch 508, CIFAR-10 Batch 5:  loss 0.000431, train_accuracy 1, valid accuracy 0.8094
Epoch 509, CIFAR-10 Batch 1:  loss 0.000246, train_accuracy 1, valid accuracy 0.8094
Epoch 509, CIFAR-10 Batch 2:  loss 0.002037, train_accuracy 1, valid accuracy 0.7922
Epoch 509, CIFAR-10 Batch 3:  loss 0.000529, train_accuracy 1, valid accuracy 0.8006
Epoch 509, CIFAR-10 Batch 4:  loss 0.001157, train_accuracy 1, valid accuracy 0.801
Epoch 509, CIFAR-10 Batch 5:  loss 0.000403, train_accuracy 1, valid accuracy 0.8026
Epoch 510, CIFAR-10 Batch 1:  loss 0.000651, train_accuracy 1, valid accuracy 0.8094
Epoch 510, CIFAR-10 Batch 2:  loss 0.000529, train_accuracy 1, valid accuracy 0.8038
Epoch 510, CIFAR-10 Batch 3:  loss 0.003394, train_accuracy 1, valid accuracy 0.7888
Epoch 510, CIFAR-10 Batch 4:  loss 0.000165, train_accuracy 1, valid accuracy 0.8032
Epoch 510, CIFAR-10 Batch 5:  loss 0.000508, train_accuracy 1, valid accuracy 0.8014
Epoch 511, CIFAR-10 Batch 1:  loss 0.000384, train_accuracy 1, valid accuracy 0.8124
Epoch 511, CIFAR-10 Batch 2:  loss 0.000104, train_accuracy 1, valid accuracy 0.8118
Epoch 511, CIFAR-10 Batch 3:  loss 0.000221, train_accuracy 1, valid accuracy 0.8034
Epoch 511, CIFAR-10 Batch 4:  loss 0.017946, train_accuracy 1, valid accuracy 0.7844
Epoch 511, CIFAR-10 Batch 5:  loss 0.000434, train_accuracy 1, valid accuracy 0.8074
Epoch 512, CIFAR-10 Batch 1:  loss 0.000071, train_accuracy 1, valid accuracy 0.8094
Epoch 512, CIFAR-10 Batch 2:  loss 0.000485, train_accuracy 1, valid accuracy 0.785
Epoch 512, CIFAR-10 Batch 3:  loss 0.000158, train_accuracy 1, valid accuracy 0.7942
Epoch 512, CIFAR-10 Batch 4:  loss 0.000170, train_accuracy 1, valid accuracy 0.8042
Epoch 512, CIFAR-10 Batch 5:  loss 0.000122, train_accuracy 1, valid accuracy 0.8016
Epoch 513, CIFAR-10 Batch 1:  loss 0.000878, train_accuracy 1, valid accuracy 0.7984
Epoch 513, CIFAR-10 Batch 2:  loss 0.000188, train_accuracy 1, valid accuracy 0.8042
Epoch 513, CIFAR-10 Batch 3:  loss 0.000542, train_accuracy 1, valid accuracy 0.8082
Epoch 513, CIFAR-10 Batch 4:  loss 0.000316, train_accuracy 1, valid accuracy 0.8092
Epoch 513, CIFAR-10 Batch 5:  loss 0.000057, train_accuracy 1, valid accuracy 0.8062
Epoch 514, CIFAR-10 Batch 1:  loss 0.000402, train_accuracy 1, valid accuracy 0.8078
Epoch 514, CIFAR-10 Batch 2:  loss 0.006459, train_accuracy 1, valid accuracy 0.771
Epoch 514, CIFAR-10 Batch 3:  loss 0.000202, train_accuracy 1, valid accuracy 0.7962
Epoch 514, CIFAR-10 Batch 4:  loss 0.000365, train_accuracy 1, valid accuracy 0.803
Epoch 514, CIFAR-10 Batch 5:  loss 0.000261, train_accuracy 1, valid accuracy 0.8052
Epoch 515, CIFAR-10 Batch 1:  loss 0.000503, train_accuracy 1, valid accuracy 0.803
Epoch 515, CIFAR-10 Batch 2:  loss 0.000283, train_accuracy 1, valid accuracy 0.8002
Epoch 515, CIFAR-10 Batch 3:  loss 0.001964, train_accuracy 1, valid accuracy 0.8036
Epoch 515, CIFAR-10 Batch 4:  loss 0.000172, train_accuracy 1, valid accuracy 0.8036
Epoch 515, CIFAR-10 Batch 5:  loss 0.000515, train_accuracy 1, valid accuracy 0.8064
Epoch 516, CIFAR-10 Batch 1:  loss 0.000538, train_accuracy 1, valid accuracy 0.8064
Epoch 516, CIFAR-10 Batch 2:  loss 0.000326, train_accuracy 1, valid accuracy 0.8066
Epoch 516, CIFAR-10 Batch 3:  loss 0.000094, train_accuracy 1, valid accuracy 0.8032
Epoch 516, CIFAR-10 Batch 4:  loss 0.000299, train_accuracy 1, valid accuracy 0.8062
Epoch 516, CIFAR-10 Batch 5:  loss 0.000046, train_accuracy 1, valid accuracy 0.8082
Epoch 517, CIFAR-10 Batch 1:  loss 0.000567, train_accuracy 1, valid accuracy 0.7972
Epoch 517, CIFAR-10 Batch 2:  loss 0.000087, train_accuracy 1, valid accuracy 0.807
Epoch 517, CIFAR-10 Batch 3:  loss 0.000049, train_accuracy 1, valid accuracy 0.8052
Epoch 517, CIFAR-10 Batch 4:  loss 0.000567, train_accuracy 1, valid accuracy 0.7994
Epoch 517, CIFAR-10 Batch 5:  loss 0.000093, train_accuracy 1, valid accuracy 0.7968
Epoch 518, CIFAR-10 Batch 1:  loss 0.000111, train_accuracy 1, valid accuracy 0.8074
Epoch 518, CIFAR-10 Batch 2:  loss 0.000302, train_accuracy 1, valid accuracy 0.7942
Epoch 518, CIFAR-10 Batch 3:  loss 0.000466, train_accuracy 1, valid accuracy 0.793
Epoch 518, CIFAR-10 Batch 4:  loss 0.001230, train_accuracy 1, valid accuracy 0.8006
Epoch 518, CIFAR-10 Batch 5:  loss 0.000050, train_accuracy 1, valid accuracy 0.8012
Epoch 519, CIFAR-10 Batch 1:  loss 0.001685, train_accuracy 1, valid accuracy 0.7922
Epoch 519, CIFAR-10 Batch 2:  loss 0.001235, train_accuracy 1, valid accuracy 0.789
Epoch 519, CIFAR-10 Batch 3:  loss 0.000082, train_accuracy 1, valid accuracy 0.7992
Epoch 519, CIFAR-10 Batch 4:  loss 0.000245, train_accuracy 1, valid accuracy 0.8062
Epoch 519, CIFAR-10 Batch 5:  loss 0.002398, train_accuracy 1, valid accuracy 0.7928
Epoch 520, CIFAR-10 Batch 1:  loss 0.000079, train_accuracy 1, valid accuracy 0.8068
Epoch 520, CIFAR-10 Batch 2:  loss 0.000358, train_accuracy 1, valid accuracy 0.7924
Epoch 520, CIFAR-10 Batch 3:  loss 0.000170, train_accuracy 1, valid accuracy 0.8018
Epoch 520, CIFAR-10 Batch 4:  loss 0.000192, train_accuracy 1, valid accuracy 0.8058
Epoch 520, CIFAR-10 Batch 5:  loss 0.000777, train_accuracy 1, valid accuracy 0.8016
Epoch 521, CIFAR-10 Batch 1:  loss 0.000400, train_accuracy 1, valid accuracy 0.7914
Epoch 521, CIFAR-10 Batch 2:  loss 0.000951, train_accuracy 1, valid accuracy 0.7968
Epoch 521, CIFAR-10 Batch 3:  loss 0.000178, train_accuracy 1, valid accuracy 0.8016
Epoch 521, CIFAR-10 Batch 4:  loss 0.000841, train_accuracy 1, valid accuracy 0.8032
Epoch 521, CIFAR-10 Batch 5:  loss 0.000097, train_accuracy 1, valid accuracy 0.8048
Epoch 522, CIFAR-10 Batch 1:  loss 0.000825, train_accuracy 1, valid accuracy 0.7972
Epoch 522, CIFAR-10 Batch 2:  loss 0.000150, train_accuracy 1, valid accuracy 0.8094
Epoch 522, CIFAR-10 Batch 3:  loss 0.000224, train_accuracy 1, valid accuracy 0.805
Epoch 522, CIFAR-10 Batch 4:  loss 0.000088, train_accuracy 1, valid accuracy 0.8046
Epoch 522, CIFAR-10 Batch 5:  loss 0.000159, train_accuracy 1, valid accuracy 0.7954
Epoch 523, CIFAR-10 Batch 1:  loss 0.000157, train_accuracy 1, valid accuracy 0.8092
Epoch 523, CIFAR-10 Batch 2:  loss 0.000143, train_accuracy 1, valid accuracy 0.8074
Epoch 523, CIFAR-10 Batch 3:  loss 0.000242, train_accuracy 1, valid accuracy 0.7992
Epoch 523, CIFAR-10 Batch 4:  loss 0.000321, train_accuracy 1, valid accuracy 0.812
Epoch 523, CIFAR-10 Batch 5:  loss 0.000480, train_accuracy 1, valid accuracy 0.807
Epoch 524, CIFAR-10 Batch 1:  loss 0.000270, train_accuracy 1, valid accuracy 0.8078
Epoch 524, CIFAR-10 Batch 2:  loss 0.000472, train_accuracy 1, valid accuracy 0.8026
Epoch 524, CIFAR-10 Batch 3:  loss 0.000099, train_accuracy 1, valid accuracy 0.8038
Epoch 524, CIFAR-10 Batch 4:  loss 0.000544, train_accuracy 1, valid accuracy 0.7988
Epoch 524, CIFAR-10 Batch 5:  loss 0.000726, train_accuracy 1, valid accuracy 0.8032
Epoch 525, CIFAR-10 Batch 1:  loss 0.000309, train_accuracy 1, valid accuracy 0.8096
Epoch 525, CIFAR-10 Batch 2:  loss 0.000144, train_accuracy 1, valid accuracy 0.7992
Epoch 525, CIFAR-10 Batch 3:  loss 0.000099, train_accuracy 1, valid accuracy 0.807
Epoch 525, CIFAR-10 Batch 4:  loss 0.000170, train_accuracy 1, valid accuracy 0.8024
Epoch 525, CIFAR-10 Batch 5:  loss 0.000279, train_accuracy 1, valid accuracy 0.8108
Epoch 526, CIFAR-10 Batch 1:  loss 0.000290, train_accuracy 1, valid accuracy 0.8038
Epoch 526, CIFAR-10 Batch 2:  loss 0.000741, train_accuracy 1, valid accuracy 0.8048
Epoch 526, CIFAR-10 Batch 3:  loss 0.000157, train_accuracy 1, valid accuracy 0.8054
Epoch 526, CIFAR-10 Batch 4:  loss 0.000943, train_accuracy 1, valid accuracy 0.8078
Epoch 526, CIFAR-10 Batch 5:  loss 0.001103, train_accuracy 1, valid accuracy 0.8004
Epoch 527, CIFAR-10 Batch 1:  loss 0.000562, train_accuracy 1, valid accuracy 0.8102
Epoch 527, CIFAR-10 Batch 2:  loss 0.002187, train_accuracy 1, valid accuracy 0.8088
Epoch 527, CIFAR-10 Batch 3:  loss 0.000052, train_accuracy 1, valid accuracy 0.806
Epoch 527, CIFAR-10 Batch 4:  loss 0.003233, train_accuracy 1, valid accuracy 0.8008
Epoch 527, CIFAR-10 Batch 5:  loss 0.000239, train_accuracy 1, valid accuracy 0.8142
Epoch 528, CIFAR-10 Batch 1:  loss 0.001447, train_accuracy 1, valid accuracy 0.806
Epoch 528, CIFAR-10 Batch 2:  loss 0.000681, train_accuracy 1, valid accuracy 0.7966
Epoch 528, CIFAR-10 Batch 3:  loss 0.000515, train_accuracy 1, valid accuracy 0.8036
Epoch 528, CIFAR-10 Batch 4:  loss 0.001651, train_accuracy 1, valid accuracy 0.8008
Epoch 528, CIFAR-10 Batch 5:  loss 0.000561, train_accuracy 1, valid accuracy 0.8096
Epoch 529, CIFAR-10 Batch 1:  loss 0.002255, train_accuracy 1, valid accuracy 0.8078
Epoch 529, CIFAR-10 Batch 2:  loss 0.001049, train_accuracy 1, valid accuracy 0.8032
Epoch 529, CIFAR-10 Batch 3:  loss 0.000111, train_accuracy 1, valid accuracy 0.8094
Epoch 529, CIFAR-10 Batch 4:  loss 0.000760, train_accuracy 1, valid accuracy 0.7938
Epoch 529, CIFAR-10 Batch 5:  loss 0.000108, train_accuracy 1, valid accuracy 0.8098
Epoch 530, CIFAR-10 Batch 1:  loss 0.001608, train_accuracy 1, valid accuracy 0.8048
Epoch 530, CIFAR-10 Batch 2:  loss 0.002136, train_accuracy 1, valid accuracy 0.8088
Epoch 530, CIFAR-10 Batch 3:  loss 0.000422, train_accuracy 1, valid accuracy 0.7992
Epoch 530, CIFAR-10 Batch 4:  loss 0.000095, train_accuracy 1, valid accuracy 0.8124
Epoch 530, CIFAR-10 Batch 5:  loss 0.000144, train_accuracy 1, valid accuracy 0.8048
Epoch 531, CIFAR-10 Batch 1:  loss 0.000151, train_accuracy 1, valid accuracy 0.8092
Epoch 531, CIFAR-10 Batch 2:  loss 0.001307, train_accuracy 1, valid accuracy 0.796
Epoch 531, CIFAR-10 Batch 3:  loss 0.000097, train_accuracy 1, valid accuracy 0.806
Epoch 531, CIFAR-10 Batch 4:  loss 0.000116, train_accuracy 1, valid accuracy 0.7968
Epoch 531, CIFAR-10 Batch 5:  loss 0.000387, train_accuracy 1, valid accuracy 0.8048
Epoch 532, CIFAR-10 Batch 1:  loss 0.000659, train_accuracy 1, valid accuracy 0.802
Epoch 532, CIFAR-10 Batch 2:  loss 0.000395, train_accuracy 1, valid accuracy 0.808
Epoch 532, CIFAR-10 Batch 3:  loss 0.000089, train_accuracy 1, valid accuracy 0.8086
Epoch 532, CIFAR-10 Batch 4:  loss 0.000157, train_accuracy 1, valid accuracy 0.803
Epoch 532, CIFAR-10 Batch 5:  loss 0.000198, train_accuracy 1, valid accuracy 0.8098
Epoch 533, CIFAR-10 Batch 1:  loss 0.000331, train_accuracy 1, valid accuracy 0.8066
Epoch 533, CIFAR-10 Batch 2:  loss 0.000061, train_accuracy 1, valid accuracy 0.8094
Epoch 533, CIFAR-10 Batch 3:  loss 0.000034, train_accuracy 1, valid accuracy 0.8048
Epoch 533, CIFAR-10 Batch 4:  loss 0.000102, train_accuracy 1, valid accuracy 0.8112
Epoch 533, CIFAR-10 Batch 5:  loss 0.001347, train_accuracy 1, valid accuracy 0.794
Epoch 534, CIFAR-10 Batch 1:  loss 0.000472, train_accuracy 1, valid accuracy 0.8006
Epoch 534, CIFAR-10 Batch 2:  loss 0.000446, train_accuracy 1, valid accuracy 0.7954
Epoch 534, CIFAR-10 Batch 3:  loss 0.000117, train_accuracy 1, valid accuracy 0.8102
Epoch 534, CIFAR-10 Batch 4:  loss 0.000063, train_accuracy 1, valid accuracy 0.8096
Epoch 534, CIFAR-10 Batch 5:  loss 0.000715, train_accuracy 1, valid accuracy 0.8022
Epoch 535, CIFAR-10 Batch 1:  loss 0.000335, train_accuracy 1, valid accuracy 0.8074
Epoch 535, CIFAR-10 Batch 2:  loss 0.002026, train_accuracy 1, valid accuracy 0.7968
Epoch 535, CIFAR-10 Batch 3:  loss 0.000144, train_accuracy 1, valid accuracy 0.8074
Epoch 535, CIFAR-10 Batch 4:  loss 0.000215, train_accuracy 1, valid accuracy 0.8018
Epoch 535, CIFAR-10 Batch 5:  loss 0.000869, train_accuracy 1, valid accuracy 0.8052
Epoch 536, CIFAR-10 Batch 1:  loss 0.000292, train_accuracy 1, valid accuracy 0.8082
Epoch 536, CIFAR-10 Batch 2:  loss 0.001238, train_accuracy 1, valid accuracy 0.7952
Epoch 536, CIFAR-10 Batch 3:  loss 0.000126, train_accuracy 1, valid accuracy 0.803
Epoch 536, CIFAR-10 Batch 4:  loss 0.000200, train_accuracy 1, valid accuracy 0.8056
Epoch 536, CIFAR-10 Batch 5:  loss 0.000455, train_accuracy 1, valid accuracy 0.8078
Epoch 537, CIFAR-10 Batch 1:  loss 0.000177, train_accuracy 1, valid accuracy 0.804
Epoch 537, CIFAR-10 Batch 2:  loss 0.000083, train_accuracy 1, valid accuracy 0.8094
Epoch 537, CIFAR-10 Batch 3:  loss 0.000343, train_accuracy 1, valid accuracy 0.8052
Epoch 537, CIFAR-10 Batch 4:  loss 0.000430, train_accuracy 1, valid accuracy 0.8026
Epoch 537, CIFAR-10 Batch 5:  loss 0.000231, train_accuracy 1, valid accuracy 0.8012
Epoch 538, CIFAR-10 Batch 1:  loss 0.000139, train_accuracy 1, valid accuracy 0.8064
Epoch 538, CIFAR-10 Batch 2:  loss 0.000113, train_accuracy 1, valid accuracy 0.8076
Epoch 538, CIFAR-10 Batch 3:  loss 0.000143, train_accuracy 1, valid accuracy 0.805
Epoch 538, CIFAR-10 Batch 4:  loss 0.000166, train_accuracy 1, valid accuracy 0.8042
Epoch 538, CIFAR-10 Batch 5:  loss 0.001362, train_accuracy 1, valid accuracy 0.8034
Epoch 539, CIFAR-10 Batch 1:  loss 0.000426, train_accuracy 1, valid accuracy 0.8108
Epoch 539, CIFAR-10 Batch 2:  loss 0.000417, train_accuracy 1, valid accuracy 0.8072
Epoch 539, CIFAR-10 Batch 3:  loss 0.000509, train_accuracy 1, valid accuracy 0.8062
Epoch 539, CIFAR-10 Batch 4:  loss 0.000148, train_accuracy 1, valid accuracy 0.8044
Epoch 539, CIFAR-10 Batch 5:  loss 0.000221, train_accuracy 1, valid accuracy 0.7982
Epoch 540, CIFAR-10 Batch 1:  loss 0.000454, train_accuracy 1, valid accuracy 0.809
Epoch 540, CIFAR-10 Batch 2:  loss 0.000541, train_accuracy 1, valid accuracy 0.8032
Epoch 540, CIFAR-10 Batch 3:  loss 0.000184, train_accuracy 1, valid accuracy 0.8006
Epoch 540, CIFAR-10 Batch 4:  loss 0.000127, train_accuracy 1, valid accuracy 0.8126
Epoch 540, CIFAR-10 Batch 5:  loss 0.000285, train_accuracy 1, valid accuracy 0.809
Epoch 541, CIFAR-10 Batch 1:  loss 0.000155, train_accuracy 1, valid accuracy 0.8082
Epoch 541, CIFAR-10 Batch 2:  loss 0.000375, train_accuracy 1, valid accuracy 0.8012
Epoch 541, CIFAR-10 Batch 3:  loss 0.000177, train_accuracy 1, valid accuracy 0.8004
Epoch 541, CIFAR-10 Batch 4:  loss 0.000232, train_accuracy 1, valid accuracy 0.8114
Epoch 541, CIFAR-10 Batch 5:  loss 0.000550, train_accuracy 1, valid accuracy 0.8022
Epoch 542, CIFAR-10 Batch 1:  loss 0.000678, train_accuracy 1, valid accuracy 0.8008
Epoch 542, CIFAR-10 Batch 2:  loss 0.000231, train_accuracy 1, valid accuracy 0.8052
Epoch 542, CIFAR-10 Batch 3:  loss 0.000297, train_accuracy 1, valid accuracy 0.8038
Epoch 542, CIFAR-10 Batch 4:  loss 0.000212, train_accuracy 1, valid accuracy 0.7966
Epoch 542, CIFAR-10 Batch 5:  loss 0.000471, train_accuracy 1, valid accuracy 0.808
Epoch 543, CIFAR-10 Batch 1:  loss 0.000323, train_accuracy 1, valid accuracy 0.811
Epoch 543, CIFAR-10 Batch 2:  loss 0.001800, train_accuracy 1, valid accuracy 0.7936
Epoch 543, CIFAR-10 Batch 3:  loss 0.000270, train_accuracy 1, valid accuracy 0.8062
Epoch 543, CIFAR-10 Batch 4:  loss 0.000122, train_accuracy 1, valid accuracy 0.8022
Epoch 543, CIFAR-10 Batch 5:  loss 0.000793, train_accuracy 1, valid accuracy 0.7966
Epoch 544, CIFAR-10 Batch 1:  loss 0.000086, train_accuracy 1, valid accuracy 0.806
Epoch 544, CIFAR-10 Batch 2:  loss 0.017978, train_accuracy 1, valid accuracy 0.7974
Epoch 544, CIFAR-10 Batch 3:  loss 0.000290, train_accuracy 1, valid accuracy 0.8038
Epoch 544, CIFAR-10 Batch 4:  loss 0.500520, train_accuracy 0.875, valid accuracy 0.6604
Epoch 544, CIFAR-10 Batch 5:  loss 0.001530, train_accuracy 1, valid accuracy 0.7932
Epoch 545, CIFAR-10 Batch 1:  loss 0.000157, train_accuracy 1, valid accuracy 0.8034
Epoch 545, CIFAR-10 Batch 2:  loss 0.000682, train_accuracy 1, valid accuracy 0.7986
Epoch 545, CIFAR-10 Batch 3:  loss 0.000213, train_accuracy 1, valid accuracy 0.8036
Epoch 545, CIFAR-10 Batch 4:  loss 0.000301, train_accuracy 1, valid accuracy 0.8052
Epoch 545, CIFAR-10 Batch 5:  loss 0.000497, train_accuracy 1, valid accuracy 0.8078
Epoch 546, CIFAR-10 Batch 1:  loss 0.001270, train_accuracy 1, valid accuracy 0.8064
Epoch 546, CIFAR-10 Batch 2:  loss 0.007971, train_accuracy 1, valid accuracy 0.796
Epoch 546, CIFAR-10 Batch 3:  loss 0.000229, train_accuracy 1, valid accuracy 0.8056
Epoch 546, CIFAR-10 Batch 4:  loss 0.000033, train_accuracy 1, valid accuracy 0.813
Epoch 546, CIFAR-10 Batch 5:  loss 0.002391, train_accuracy 1, valid accuracy 0.8114
Epoch 547, CIFAR-10 Batch 1:  loss 0.000048, train_accuracy 1, valid accuracy 0.8144
Epoch 547, CIFAR-10 Batch 2:  loss 0.001799, train_accuracy 1, valid accuracy 0.7826
Epoch 547, CIFAR-10 Batch 3:  loss 0.000081, train_accuracy 1, valid accuracy 0.8126
Epoch 547, CIFAR-10 Batch 4:  loss 0.000221, train_accuracy 1, valid accuracy 0.8032
Epoch 547, CIFAR-10 Batch 5:  loss 0.001359, train_accuracy 1, valid accuracy 0.8074
Epoch 548, CIFAR-10 Batch 1:  loss 0.000200, train_accuracy 1, valid accuracy 0.81
Epoch 548, CIFAR-10 Batch 2:  loss 0.000084, train_accuracy 1, valid accuracy 0.8106
Epoch 548, CIFAR-10 Batch 3:  loss 0.000322, train_accuracy 1, valid accuracy 0.8018
Epoch 548, CIFAR-10 Batch 4:  loss 0.000261, train_accuracy 1, valid accuracy 0.802
Epoch 548, CIFAR-10 Batch 5:  loss 0.000370, train_accuracy 1, valid accuracy 0.8092
Epoch 549, CIFAR-10 Batch 1:  loss 0.000198, train_accuracy 1, valid accuracy 0.8008
Epoch 549, CIFAR-10 Batch 2:  loss 0.003122, train_accuracy 1, valid accuracy 0.7976
Epoch 549, CIFAR-10 Batch 3:  loss 0.000602, train_accuracy 1, valid accuracy 0.8076
Epoch 549, CIFAR-10 Batch 4:  loss 0.000099, train_accuracy 1, valid accuracy 0.8078
Epoch 549, CIFAR-10 Batch 5:  loss 0.000381, train_accuracy 1, valid accuracy 0.803
Epoch 550, CIFAR-10 Batch 1:  loss 0.000317, train_accuracy 1, valid accuracy 0.8018
Epoch 550, CIFAR-10 Batch 2:  loss 0.000614, train_accuracy 1, valid accuracy 0.8096
Epoch 550, CIFAR-10 Batch 3:  loss 0.000236, train_accuracy 1, valid accuracy 0.8044
Epoch 550, CIFAR-10 Batch 4:  loss 0.000067, train_accuracy 1, valid accuracy 0.8098
Epoch 550, CIFAR-10 Batch 5:  loss 0.000112, train_accuracy 1, valid accuracy 0.8094
Epoch 551, CIFAR-10 Batch 1:  loss 0.000550, train_accuracy 1, valid accuracy 0.8062
Epoch 551, CIFAR-10 Batch 2:  loss 0.000394, train_accuracy 1, valid accuracy 0.8124
Epoch 551, CIFAR-10 Batch 3:  loss 0.000114, train_accuracy 1, valid accuracy 0.807
Epoch 551, CIFAR-10 Batch 4:  loss 0.000165, train_accuracy 1, valid accuracy 0.7972
Epoch 551, CIFAR-10 Batch 5:  loss 0.000991, train_accuracy 1, valid accuracy 0.8046
Epoch 552, CIFAR-10 Batch 1:  loss 0.000270, train_accuracy 1, valid accuracy 0.8096
Epoch 552, CIFAR-10 Batch 2:  loss 0.002111, train_accuracy 1, valid accuracy 0.7952
Epoch 552, CIFAR-10 Batch 3:  loss 0.000676, train_accuracy 1, valid accuracy 0.8038
Epoch 552, CIFAR-10 Batch 4:  loss 0.000137, train_accuracy 1, valid accuracy 0.7962
Epoch 552, CIFAR-10 Batch 5:  loss 0.002367, train_accuracy 1, valid accuracy 0.7804
Epoch 553, CIFAR-10 Batch 1:  loss 0.000701, train_accuracy 1, valid accuracy 0.81
Epoch 553, CIFAR-10 Batch 2:  loss 0.000209, train_accuracy 1, valid accuracy 0.8076
Epoch 553, CIFAR-10 Batch 3:  loss 0.000464, train_accuracy 1, valid accuracy 0.8046
Epoch 553, CIFAR-10 Batch 4:  loss 0.000327, train_accuracy 1, valid accuracy 0.7986
Epoch 553, CIFAR-10 Batch 5:  loss 0.000800, train_accuracy 1, valid accuracy 0.7934
Epoch 554, CIFAR-10 Batch 1:  loss 0.000424, train_accuracy 1, valid accuracy 0.8008
Epoch 554, CIFAR-10 Batch 2:  loss 0.000510, train_accuracy 1, valid accuracy 0.7972
Epoch 554, CIFAR-10 Batch 3:  loss 0.000445, train_accuracy 1, valid accuracy 0.8004
Epoch 554, CIFAR-10 Batch 4:  loss 0.004401, train_accuracy 1, valid accuracy 0.7886
Epoch 554, CIFAR-10 Batch 5:  loss 0.000346, train_accuracy 1, valid accuracy 0.8116
Epoch 555, CIFAR-10 Batch 1:  loss 0.000770, train_accuracy 1, valid accuracy 0.8112
Epoch 555, CIFAR-10 Batch 2:  loss 0.002207, train_accuracy 1, valid accuracy 0.7994
Epoch 555, CIFAR-10 Batch 3:  loss 0.000111, train_accuracy 1, valid accuracy 0.813
Epoch 555, CIFAR-10 Batch 4:  loss 0.000049, train_accuracy 1, valid accuracy 0.8086
Epoch 555, CIFAR-10 Batch 5:  loss 0.000193, train_accuracy 1, valid accuracy 0.8076
Epoch 556, CIFAR-10 Batch 1:  loss 0.000509, train_accuracy 1, valid accuracy 0.811
Epoch 556, CIFAR-10 Batch 2:  loss 0.000117, train_accuracy 1, valid accuracy 0.7982
Epoch 556, CIFAR-10 Batch 3:  loss 0.000331, train_accuracy 1, valid accuracy 0.7992
Epoch 556, CIFAR-10 Batch 4:  loss 0.000263, train_accuracy 1, valid accuracy 0.81
Epoch 556, CIFAR-10 Batch 5:  loss 0.000139, train_accuracy 1, valid accuracy 0.814
Epoch 557, CIFAR-10 Batch 1:  loss 0.000436, train_accuracy 1, valid accuracy 0.8016
Epoch 557, CIFAR-10 Batch 2:  loss 0.000191, train_accuracy 1, valid accuracy 0.8016
Epoch 557, CIFAR-10 Batch 3:  loss 0.000343, train_accuracy 1, valid accuracy 0.803
Epoch 557, CIFAR-10 Batch 4:  loss 0.000518, train_accuracy 1, valid accuracy 0.7996
Epoch 557, CIFAR-10 Batch 5:  loss 0.002704, train_accuracy 1, valid accuracy 0.7958
Epoch 558, CIFAR-10 Batch 1:  loss 0.000787, train_accuracy 1, valid accuracy 0.798
Epoch 558, CIFAR-10 Batch 2:  loss 0.001183, train_accuracy 1, valid accuracy 0.7892
Epoch 558, CIFAR-10 Batch 3:  loss 0.000328, train_accuracy 1, valid accuracy 0.7932
Epoch 558, CIFAR-10 Batch 4:  loss 0.000191, train_accuracy 1, valid accuracy 0.8048
Epoch 558, CIFAR-10 Batch 5:  loss 0.000540, train_accuracy 1, valid accuracy 0.8032
Epoch 559, CIFAR-10 Batch 1:  loss 0.000758, train_accuracy 1, valid accuracy 0.8022
Epoch 559, CIFAR-10 Batch 2:  loss 0.000145, train_accuracy 1, valid accuracy 0.8046
Epoch 559, CIFAR-10 Batch 3:  loss 0.001799, train_accuracy 1, valid accuracy 0.7908
Epoch 559, CIFAR-10 Batch 4:  loss 0.000518, train_accuracy 1, valid accuracy 0.7972
Epoch 559, CIFAR-10 Batch 5:  loss 0.000639, train_accuracy 1, valid accuracy 0.8076
Epoch 560, CIFAR-10 Batch 1:  loss 0.000298, train_accuracy 1, valid accuracy 0.8034
Epoch 560, CIFAR-10 Batch 2:  loss 0.000402, train_accuracy 1, valid accuracy 0.7992
Epoch 560, CIFAR-10 Batch 3:  loss 0.000209, train_accuracy 1, valid accuracy 0.815
Epoch 560, CIFAR-10 Batch 4:  loss 0.000209, train_accuracy 1, valid accuracy 0.8048
Epoch 560, CIFAR-10 Batch 5:  loss 0.000425, train_accuracy 1, valid accuracy 0.794
Epoch 561, CIFAR-10 Batch 1:  loss 0.000169, train_accuracy 1, valid accuracy 0.8116
Epoch 561, CIFAR-10 Batch 2:  loss 0.000062, train_accuracy 1, valid accuracy 0.8044
Epoch 561, CIFAR-10 Batch 3:  loss 0.000134, train_accuracy 1, valid accuracy 0.8032
Epoch 561, CIFAR-10 Batch 4:  loss 0.000114, train_accuracy 1, valid accuracy 0.808
Epoch 561, CIFAR-10 Batch 5:  loss 0.000252, train_accuracy 1, valid accuracy 0.8054
Epoch 562, CIFAR-10 Batch 1:  loss 0.000153, train_accuracy 1, valid accuracy 0.7964
Epoch 562, CIFAR-10 Batch 2:  loss 0.000141, train_accuracy 1, valid accuracy 0.7972
Epoch 562, CIFAR-10 Batch 3:  loss 0.000288, train_accuracy 1, valid accuracy 0.8016
Epoch 562, CIFAR-10 Batch 4:  loss 0.000963, train_accuracy 1, valid accuracy 0.793
Epoch 562, CIFAR-10 Batch 5:  loss 0.000287, train_accuracy 1, valid accuracy 0.8086
Epoch 563, CIFAR-10 Batch 1:  loss 0.001019, train_accuracy 1, valid accuracy 0.8048
Epoch 563, CIFAR-10 Batch 2:  loss 0.000312, train_accuracy 1, valid accuracy 0.8114
Epoch 563, CIFAR-10 Batch 3:  loss 0.000478, train_accuracy 1, valid accuracy 0.8038
Epoch 563, CIFAR-10 Batch 4:  loss 0.000184, train_accuracy 1, valid accuracy 0.7978
Epoch 563, CIFAR-10 Batch 5:  loss 0.000076, train_accuracy 1, valid accuracy 0.8102
Epoch 564, CIFAR-10 Batch 1:  loss 0.000238, train_accuracy 1, valid accuracy 0.8032
Epoch 564, CIFAR-10 Batch 2:  loss 0.000212, train_accuracy 1, valid accuracy 0.8028
Epoch 564, CIFAR-10 Batch 3:  loss 0.000714, train_accuracy 1, valid accuracy 0.7974
Epoch 564, CIFAR-10 Batch 4:  loss 0.000566, train_accuracy 1, valid accuracy 0.7994
Epoch 564, CIFAR-10 Batch 5:  loss 0.000060, train_accuracy 1, valid accuracy 0.8084
Epoch 565, CIFAR-10 Batch 1:  loss 0.001603, train_accuracy 1, valid accuracy 0.7972
Epoch 565, CIFAR-10 Batch 2:  loss 0.000180, train_accuracy 1, valid accuracy 0.7946
Epoch 565, CIFAR-10 Batch 3:  loss 0.000338, train_accuracy 1, valid accuracy 0.8042
Epoch 565, CIFAR-10 Batch 4:  loss 0.000231, train_accuracy 1, valid accuracy 0.802
Epoch 565, CIFAR-10 Batch 5:  loss 0.000098, train_accuracy 1, valid accuracy 0.807
Epoch 566, CIFAR-10 Batch 1:  loss 0.000268, train_accuracy 1, valid accuracy 0.8092
Epoch 566, CIFAR-10 Batch 2:  loss 0.000065, train_accuracy 1, valid accuracy 0.8064
Epoch 566, CIFAR-10 Batch 3:  loss 0.000129, train_accuracy 1, valid accuracy 0.8094
Epoch 566, CIFAR-10 Batch 4:  loss 0.000065, train_accuracy 1, valid accuracy 0.8026
Epoch 566, CIFAR-10 Batch 5:  loss 0.000116, train_accuracy 1, valid accuracy 0.808
Epoch 567, CIFAR-10 Batch 1:  loss 0.000158, train_accuracy 1, valid accuracy 0.8018
Epoch 567, CIFAR-10 Batch 2:  loss 0.000083, train_accuracy 1, valid accuracy 0.8068
Epoch 567, CIFAR-10 Batch 3:  loss 0.000340, train_accuracy 1, valid accuracy 0.8108
Epoch 567, CIFAR-10 Batch 4:  loss 0.000189, train_accuracy 1, valid accuracy 0.8048
Epoch 567, CIFAR-10 Batch 5:  loss 0.000147, train_accuracy 1, valid accuracy 0.8048
Epoch 568, CIFAR-10 Batch 1:  loss 0.000148, train_accuracy 1, valid accuracy 0.8038
Epoch 568, CIFAR-10 Batch 2:  loss 0.001200, train_accuracy 1, valid accuracy 0.796
Epoch 568, CIFAR-10 Batch 3:  loss 0.000235, train_accuracy 1, valid accuracy 0.8036
Epoch 568, CIFAR-10 Batch 4:  loss 0.000696, train_accuracy 1, valid accuracy 0.8028
Epoch 568, CIFAR-10 Batch 5:  loss 0.003385, train_accuracy 1, valid accuracy 0.7932
Epoch 569, CIFAR-10 Batch 1:  loss 0.000190, train_accuracy 1, valid accuracy 0.8
Epoch 569, CIFAR-10 Batch 2:  loss 0.000694, train_accuracy 1, valid accuracy 0.8062
Epoch 569, CIFAR-10 Batch 3:  loss 0.000239, train_accuracy 1, valid accuracy 0.803
Epoch 569, CIFAR-10 Batch 4:  loss 0.000157, train_accuracy 1, valid accuracy 0.81
Epoch 569, CIFAR-10 Batch 5:  loss 0.001001, train_accuracy 1, valid accuracy 0.806
Epoch 570, CIFAR-10 Batch 1:  loss 0.002764, train_accuracy 1, valid accuracy 0.7882
Epoch 570, CIFAR-10 Batch 2:  loss 0.000536, train_accuracy 1, valid accuracy 0.8
Epoch 570, CIFAR-10 Batch 3:  loss 0.001791, train_accuracy 1, valid accuracy 0.7966
Epoch 570, CIFAR-10 Batch 4:  loss 0.000469, train_accuracy 1, valid accuracy 0.8028
Epoch 570, CIFAR-10 Batch 5:  loss 0.004230, train_accuracy 1, valid accuracy 0.787
Epoch 571, CIFAR-10 Batch 1:  loss 0.000392, train_accuracy 1, valid accuracy 0.8026
Epoch 571, CIFAR-10 Batch 2:  loss 0.000342, train_accuracy 1, valid accuracy 0.795
Epoch 571, CIFAR-10 Batch 3:  loss 0.000208, train_accuracy 1, valid accuracy 0.8068
Epoch 571, CIFAR-10 Batch 4:  loss 0.000329, train_accuracy 1, valid accuracy 0.7954
Epoch 571, CIFAR-10 Batch 5:  loss 0.000117, train_accuracy 1, valid accuracy 0.801
Epoch 572, CIFAR-10 Batch 1:  loss 0.000079, train_accuracy 1, valid accuracy 0.8108
Epoch 572, CIFAR-10 Batch 2:  loss 0.000100, train_accuracy 1, valid accuracy 0.8112
Epoch 572, CIFAR-10 Batch 3:  loss 0.000162, train_accuracy 1, valid accuracy 0.8114
Epoch 572, CIFAR-10 Batch 4:  loss 0.000135, train_accuracy 1, valid accuracy 0.8094
Epoch 572, CIFAR-10 Batch 5:  loss 0.000129, train_accuracy 1, valid accuracy 0.8066
Epoch 573, CIFAR-10 Batch 1:  loss 0.000085, train_accuracy 1, valid accuracy 0.8102
Epoch 573, CIFAR-10 Batch 2:  loss 0.001554, train_accuracy 1, valid accuracy 0.7952
Epoch 573, CIFAR-10 Batch 3:  loss 0.000070, train_accuracy 1, valid accuracy 0.8008
Epoch 573, CIFAR-10 Batch 4:  loss 0.001038, train_accuracy 1, valid accuracy 0.8
Epoch 573, CIFAR-10 Batch 5:  loss 0.000721, train_accuracy 1, valid accuracy 0.8028
Epoch 574, CIFAR-10 Batch 1:  loss 0.000305, train_accuracy 1, valid accuracy 0.8038
Epoch 574, CIFAR-10 Batch 2:  loss 0.000336, train_accuracy 1, valid accuracy 0.801
Epoch 574, CIFAR-10 Batch 3:  loss 0.001490, train_accuracy 1, valid accuracy 0.7934
Epoch 574, CIFAR-10 Batch 4:  loss 0.000844, train_accuracy 1, valid accuracy 0.801
Epoch 574, CIFAR-10 Batch 5:  loss 0.000396, train_accuracy 1, valid accuracy 0.8008
Epoch 575, CIFAR-10 Batch 1:  loss 0.000117, train_accuracy 1, valid accuracy 0.8156
Epoch 575, CIFAR-10 Batch 2:  loss 0.000365, train_accuracy 1, valid accuracy 0.7984
Epoch 575, CIFAR-10 Batch 3:  loss 0.008616, train_accuracy 1, valid accuracy 0.794
Epoch 575, CIFAR-10 Batch 4:  loss 0.002653, train_accuracy 1, valid accuracy 0.7982
Epoch 575, CIFAR-10 Batch 5:  loss 0.000202, train_accuracy 1, valid accuracy 0.7988
Epoch 576, CIFAR-10 Batch 1:  loss 0.000094, train_accuracy 1, valid accuracy 0.8076
Epoch 576, CIFAR-10 Batch 2:  loss 0.000071, train_accuracy 1, valid accuracy 0.7994
Epoch 576, CIFAR-10 Batch 3:  loss 0.000101, train_accuracy 1, valid accuracy 0.8038
Epoch 576, CIFAR-10 Batch 4:  loss 0.000243, train_accuracy 1, valid accuracy 0.803
Epoch 576, CIFAR-10 Batch 5:  loss 0.000511, train_accuracy 1, valid accuracy 0.7902
Epoch 577, CIFAR-10 Batch 1:  loss 0.000051, train_accuracy 1, valid accuracy 0.8096
Epoch 577, CIFAR-10 Batch 2:  loss 0.000175, train_accuracy 1, valid accuracy 0.8136
Epoch 577, CIFAR-10 Batch 3:  loss 0.000606, train_accuracy 1, valid accuracy 0.8006
Epoch 577, CIFAR-10 Batch 4:  loss 0.000374, train_accuracy 1, valid accuracy 0.809
Epoch 577, CIFAR-10 Batch 5:  loss 0.000540, train_accuracy 1, valid accuracy 0.799
Epoch 578, CIFAR-10 Batch 1:  loss 0.000114, train_accuracy 1, valid accuracy 0.8038
Epoch 578, CIFAR-10 Batch 2:  loss 0.000062, train_accuracy 1, valid accuracy 0.8132
Epoch 578, CIFAR-10 Batch 3:  loss 0.000136, train_accuracy 1, valid accuracy 0.804
Epoch 578, CIFAR-10 Batch 4:  loss 0.001308, train_accuracy 1, valid accuracy 0.8132
Epoch 578, CIFAR-10 Batch 5:  loss 0.000346, train_accuracy 1, valid accuracy 0.7996
Epoch 579, CIFAR-10 Batch 1:  loss 0.000215, train_accuracy 1, valid accuracy 0.8108
Epoch 579, CIFAR-10 Batch 2:  loss 0.000122, train_accuracy 1, valid accuracy 0.807
Epoch 579, CIFAR-10 Batch 3:  loss 0.000113, train_accuracy 1, valid accuracy 0.8112
Epoch 579, CIFAR-10 Batch 4:  loss 0.000138, train_accuracy 1, valid accuracy 0.8068
Epoch 579, CIFAR-10 Batch 5:  loss 0.000194, train_accuracy 1, valid accuracy 0.808
Epoch 580, CIFAR-10 Batch 1:  loss 0.000415, train_accuracy 1, valid accuracy 0.8014
Epoch 580, CIFAR-10 Batch 2:  loss 0.019873, train_accuracy 1, valid accuracy 0.7578
Epoch 580, CIFAR-10 Batch 3:  loss 0.000271, train_accuracy 1, valid accuracy 0.8028
Epoch 580, CIFAR-10 Batch 4:  loss 0.001503, train_accuracy 1, valid accuracy 0.8066
Epoch 580, CIFAR-10 Batch 5:  loss 0.000117, train_accuracy 1, valid accuracy 0.8072
Epoch 581, CIFAR-10 Batch 1:  loss 0.000516, train_accuracy 1, valid accuracy 0.8012
Epoch 581, CIFAR-10 Batch 2:  loss 0.000699, train_accuracy 1, valid accuracy 0.8114
Epoch 581, CIFAR-10 Batch 3:  loss 0.001734, train_accuracy 1, valid accuracy 0.8034
Epoch 581, CIFAR-10 Batch 4:  loss 0.000718, train_accuracy 1, valid accuracy 0.8088
Epoch 581, CIFAR-10 Batch 5:  loss 0.000722, train_accuracy 1, valid accuracy 0.8066
Epoch 582, CIFAR-10 Batch 1:  loss 0.000162, train_accuracy 1, valid accuracy 0.7994
Epoch 582, CIFAR-10 Batch 2:  loss 0.000147, train_accuracy 1, valid accuracy 0.8114
Epoch 582, CIFAR-10 Batch 3:  loss 0.000234, train_accuracy 1, valid accuracy 0.807
Epoch 582, CIFAR-10 Batch 4:  loss 0.000461, train_accuracy 1, valid accuracy 0.7928
Epoch 582, CIFAR-10 Batch 5:  loss 0.000102, train_accuracy 1, valid accuracy 0.807
Epoch 583, CIFAR-10 Batch 1:  loss 0.000034, train_accuracy 1, valid accuracy 0.8086
Epoch 583, CIFAR-10 Batch 2:  loss 0.000183, train_accuracy 1, valid accuracy 0.7916
Epoch 583, CIFAR-10 Batch 3:  loss 0.000951, train_accuracy 1, valid accuracy 0.806
Epoch 583, CIFAR-10 Batch 4:  loss 0.000530, train_accuracy 1, valid accuracy 0.8018
Epoch 583, CIFAR-10 Batch 5:  loss 0.000179, train_accuracy 1, valid accuracy 0.8032
Epoch 584, CIFAR-10 Batch 1:  loss 0.000098, train_accuracy 1, valid accuracy 0.803
Epoch 584, CIFAR-10 Batch 2:  loss 0.000160, train_accuracy 1, valid accuracy 0.8044
Epoch 584, CIFAR-10 Batch 3:  loss 0.000445, train_accuracy 1, valid accuracy 0.8106
Epoch 584, CIFAR-10 Batch 4:  loss 0.000096, train_accuracy 1, valid accuracy 0.8028
Epoch 584, CIFAR-10 Batch 5:  loss 0.000050, train_accuracy 1, valid accuracy 0.8118
Epoch 585, CIFAR-10 Batch 1:  loss 0.000130, train_accuracy 1, valid accuracy 0.8088
Epoch 585, CIFAR-10 Batch 2:  loss 0.000353, train_accuracy 1, valid accuracy 0.798
Epoch 585, CIFAR-10 Batch 3:  loss 0.000217, train_accuracy 1, valid accuracy 0.8082
Epoch 585, CIFAR-10 Batch 4:  loss 0.000173, train_accuracy 1, valid accuracy 0.8054
Epoch 585, CIFAR-10 Batch 5:  loss 0.000565, train_accuracy 1, valid accuracy 0.8016
Epoch 586, CIFAR-10 Batch 1:  loss 0.000150, train_accuracy 1, valid accuracy 0.8082
Epoch 586, CIFAR-10 Batch 2:  loss 0.002231, train_accuracy 1, valid accuracy 0.7952
Epoch 586, CIFAR-10 Batch 3:  loss 0.000056, train_accuracy 1, valid accuracy 0.8104
Epoch 586, CIFAR-10 Batch 4:  loss 0.000105, train_accuracy 1, valid accuracy 0.8102
Epoch 586, CIFAR-10 Batch 5:  loss 0.000133, train_accuracy 1, valid accuracy 0.7978
Epoch 587, CIFAR-10 Batch 1:  loss 0.000253, train_accuracy 1, valid accuracy 0.8048
Epoch 587, CIFAR-10 Batch 2:  loss 0.000103, train_accuracy 1, valid accuracy 0.806
Epoch 587, CIFAR-10 Batch 3:  loss 0.000803, train_accuracy 1, valid accuracy 0.7964
Epoch 587, CIFAR-10 Batch 4:  loss 0.001621, train_accuracy 1, valid accuracy 0.7994
Epoch 587, CIFAR-10 Batch 5:  loss 0.000124, train_accuracy 1, valid accuracy 0.8058
Epoch 588, CIFAR-10 Batch 1:  loss 0.000293, train_accuracy 1, valid accuracy 0.7958
Epoch 588, CIFAR-10 Batch 2:  loss 0.001063, train_accuracy 1, valid accuracy 0.8002
Epoch 588, CIFAR-10 Batch 3:  loss 0.000528, train_accuracy 1, valid accuracy 0.7968
Epoch 588, CIFAR-10 Batch 4:  loss 0.000492, train_accuracy 1, valid accuracy 0.8048
Epoch 588, CIFAR-10 Batch 5:  loss 0.006819, train_accuracy 1, valid accuracy 0.7882
Epoch 589, CIFAR-10 Batch 1:  loss 0.000164, train_accuracy 1, valid accuracy 0.7986
Epoch 589, CIFAR-10 Batch 2:  loss 0.001509, train_accuracy 1, valid accuracy 0.8006
Epoch 589, CIFAR-10 Batch 3:  loss 0.000252, train_accuracy 1, valid accuracy 0.8088
Epoch 589, CIFAR-10 Batch 4:  loss 0.000111, train_accuracy 1, valid accuracy 0.8016
Epoch 589, CIFAR-10 Batch 5:  loss 0.001602, train_accuracy 1, valid accuracy 0.7836
Epoch 590, CIFAR-10 Batch 1:  loss 0.000049, train_accuracy 1, valid accuracy 0.8048
Epoch 590, CIFAR-10 Batch 2:  loss 0.000283, train_accuracy 1, valid accuracy 0.8006
Epoch 590, CIFAR-10 Batch 3:  loss 0.000064, train_accuracy 1, valid accuracy 0.7992
Epoch 590, CIFAR-10 Batch 4:  loss 0.000208, train_accuracy 1, valid accuracy 0.8116
Epoch 590, CIFAR-10 Batch 5:  loss 0.000403, train_accuracy 1, valid accuracy 0.8052
Epoch 591, CIFAR-10 Batch 1:  loss 0.000239, train_accuracy 1, valid accuracy 0.8056
Epoch 591, CIFAR-10 Batch 2:  loss 0.000380, train_accuracy 1, valid accuracy 0.7994
Epoch 591, CIFAR-10 Batch 3:  loss 0.000322, train_accuracy 1, valid accuracy 0.802
Epoch 591, CIFAR-10 Batch 4:  loss 0.000230, train_accuracy 1, valid accuracy 0.811
Epoch 591, CIFAR-10 Batch 5:  loss 0.000316, train_accuracy 1, valid accuracy 0.8052
Epoch 592, CIFAR-10 Batch 1:  loss 0.000176, train_accuracy 1, valid accuracy 0.8076
Epoch 592, CIFAR-10 Batch 2:  loss 0.000059, train_accuracy 1, valid accuracy 0.8132
Epoch 592, CIFAR-10 Batch 3:  loss 0.000471, train_accuracy 1, valid accuracy 0.8028
Epoch 592, CIFAR-10 Batch 4:  loss 0.000215, train_accuracy 1, valid accuracy 0.8078
Epoch 592, CIFAR-10 Batch 5:  loss 0.000151, train_accuracy 1, valid accuracy 0.8118
Epoch 593, CIFAR-10 Batch 1:  loss 0.000077, train_accuracy 1, valid accuracy 0.8054
Epoch 593, CIFAR-10 Batch 2:  loss 0.000226, train_accuracy 1, valid accuracy 0.805
Epoch 593, CIFAR-10 Batch 3:  loss 0.000529, train_accuracy 1, valid accuracy 0.8094
Epoch 593, CIFAR-10 Batch 4:  loss 0.000306, train_accuracy 1, valid accuracy 0.8074
Epoch 593, CIFAR-10 Batch 5:  loss 0.000133, train_accuracy 1, valid accuracy 0.8074
Epoch 594, CIFAR-10 Batch 1:  loss 0.000086, train_accuracy 1, valid accuracy 0.8014
Epoch 594, CIFAR-10 Batch 2:  loss 0.000257, train_accuracy 1, valid accuracy 0.797
Epoch 594, CIFAR-10 Batch 3:  loss 0.000235, train_accuracy 1, valid accuracy 0.8084
Epoch 594, CIFAR-10 Batch 4:  loss 0.000223, train_accuracy 1, valid accuracy 0.8064
Epoch 594, CIFAR-10 Batch 5:  loss 0.001470, train_accuracy 1, valid accuracy 0.7962
Epoch 595, CIFAR-10 Batch 1:  loss 0.000135, train_accuracy 1, valid accuracy 0.808
Epoch 595, CIFAR-10 Batch 2:  loss 0.000279, train_accuracy 1, valid accuracy 0.7972
Epoch 595, CIFAR-10 Batch 3:  loss 0.000079, train_accuracy 1, valid accuracy 0.8078
Epoch 595, CIFAR-10 Batch 4:  loss 0.000344, train_accuracy 1, valid accuracy 0.7984
Epoch 595, CIFAR-10 Batch 5:  loss 0.002672, train_accuracy 1, valid accuracy 0.7806
Epoch 596, CIFAR-10 Batch 1:  loss 0.000265, train_accuracy 1, valid accuracy 0.802
Epoch 596, CIFAR-10 Batch 2:  loss 0.000213, train_accuracy 1, valid accuracy 0.806
Epoch 596, CIFAR-10 Batch 3:  loss 0.001343, train_accuracy 1, valid accuracy 0.8004
Epoch 596, CIFAR-10 Batch 4:  loss 0.000478, train_accuracy 1, valid accuracy 0.8098
Epoch 596, CIFAR-10 Batch 5:  loss 0.000104, train_accuracy 1, valid accuracy 0.8088
Epoch 597, CIFAR-10 Batch 1:  loss 0.000081, train_accuracy 1, valid accuracy 0.8068
Epoch 597, CIFAR-10 Batch 2:  loss 0.000357, train_accuracy 1, valid accuracy 0.7948
Epoch 597, CIFAR-10 Batch 3:  loss 0.000628, train_accuracy 1, valid accuracy 0.8058
Epoch 597, CIFAR-10 Batch 4:  loss 0.000362, train_accuracy 1, valid accuracy 0.7976
Epoch 597, CIFAR-10 Batch 5:  loss 0.000269, train_accuracy 1, valid accuracy 0.7948
Epoch 598, CIFAR-10 Batch 1:  loss 0.000070, train_accuracy 1, valid accuracy 0.8098
Epoch 598, CIFAR-10 Batch 2:  loss 0.000346, train_accuracy 1, valid accuracy 0.8082
Epoch 598, CIFAR-10 Batch 3:  loss 0.000077, train_accuracy 1, valid accuracy 0.8024
Epoch 598, CIFAR-10 Batch 4:  loss 0.000479, train_accuracy 1, valid accuracy 0.8
Epoch 598, CIFAR-10 Batch 5:  loss 0.000262, train_accuracy 1, valid accuracy 0.807
Epoch 599, CIFAR-10 Batch 1:  loss 0.000124, train_accuracy 1, valid accuracy 0.8046
Epoch 599, CIFAR-10 Batch 2:  loss 0.000108, train_accuracy 1, valid accuracy 0.81
Epoch 599, CIFAR-10 Batch 3:  loss 0.000094, train_accuracy 1, valid accuracy 0.7984
Epoch 599, CIFAR-10 Batch 4:  loss 0.000218, train_accuracy 1, valid accuracy 0.8108
Epoch 599, CIFAR-10 Batch 5:  loss 0.000106, train_accuracy 1, valid accuracy 0.7952
Epoch 600, CIFAR-10 Batch 1:  loss 0.000316, train_accuracy 1, valid accuracy 0.805
Epoch 600, CIFAR-10 Batch 2:  loss 0.000227, train_accuracy 1, valid accuracy 0.8076
Epoch 600, CIFAR-10 Batch 3:  loss 0.007094, train_accuracy 1, valid accuracy 0.8006
Epoch 600, CIFAR-10 Batch 4:  loss 0.000157, train_accuracy 1, valid accuracy 0.805
Epoch 600, CIFAR-10 Batch 5:  loss 0.000052, train_accuracy 1, valid accuracy 0.7994
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1><p>The model has been saved to disk.</p>
<h2 id="Test-Model">Test Model<a class="anchor-link" href="#Test-Model">&#182;</a></h2><p>Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[166]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Set batch size if not already set</span>
<span class="k">try</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">batch_size</span><span class="p">:</span>
        <span class="k">pass</span>
<span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">save_model_path</span> <span class="o">=</span> <span class="s1">&#39;./image_classification&#39;</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">top_n_predictions</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">test_model</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test the saved model against the test dataset</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">&#39;preprocess_test.p&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;rb&#39;</span><span class="p">))</span>
    <span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="c1"># Load model</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">save_model_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
        <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_model_path</span><span class="p">)</span>

        <span class="c1"># Get Tensors from loaded model</span>
        <span class="n">loaded_x</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;x:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_y</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;y:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;logits:0&#39;</span><span class="p">)</span>
        <span class="n">loaded_acc</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;accuracy:0&#39;</span><span class="p">)</span>
        
        <span class="c1"># Get accuracy in batches for memory limitations</span>
        <span class="n">test_batch_acc_total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">test_batch_count</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">test_feature_batch</span><span class="p">,</span> <span class="n">test_label_batch</span> <span class="ow">in</span> <span class="n">helper</span><span class="o">.</span><span class="n">batch_features_labels</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">test_batch_acc_total</span> <span class="o">+=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">loaded_acc</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">loaded_x</span><span class="p">:</span> <span class="n">test_feature_batch</span><span class="p">,</span> <span class="n">loaded_y</span><span class="p">:</span> <span class="n">test_label_batch</span><span class="p">,</span> <span class="n">loaded_keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
            <span class="n">test_batch_count</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing Accuracy: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_batch_acc_total</span><span class="o">/</span><span class="n">test_batch_count</span><span class="p">))</span>

        <span class="c1"># Print Random Samples</span>
        <span class="n">random_test_features</span><span class="p">,</span> <span class="n">random_test_labels</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)),</span> <span class="n">n_samples</span><span class="p">)))</span>
        <span class="n">random_test_predictions</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">loaded_logits</span><span class="p">),</span> <span class="n">top_n_predictions</span><span class="p">),</span>
            <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">loaded_x</span><span class="p">:</span> <span class="n">random_test_features</span><span class="p">,</span> <span class="n">loaded_y</span><span class="p">:</span> <span class="n">random_test_labels</span><span class="p">,</span> <span class="n">loaded_keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
        <span class="n">helper</span><span class="o">.</span><span class="n">display_image_predictions</span><span class="p">(</span><span class="n">random_test_features</span><span class="p">,</span> <span class="n">random_test_labels</span><span class="p">,</span> <span class="n">random_test_predictions</span><span class="p">)</span>


<span class="n">test_model</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from ./image_classification
Testing Accuracy: 0.79580078125

</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
width=355
height=319
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-50-80%-Accuracy?">Why 50-80% Accuracy?<a class="anchor-link" href="#Why-50-80%-Accuracy?">&#182;</a></h2><p>You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores <a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130">well above 80%</a>.  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as "dlnd_image_classification.ipynb" and save it as a HTML file under "File" -&gt; "Download as".  Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
